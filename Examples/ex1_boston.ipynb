{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "from miniflow import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "X_, y_ = shuffle(X_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datasets: 506\n",
      "Features: 13\n"
     ]
    }
   ],
   "source": [
    "# Explore data\n",
    "print (\"Total datasets: {}\".format(X_.shape[0]))\n",
    "print (\"Features: {}\".format(X_.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "t = int(X_.shape[0] * 0.9)\n",
    "X_, X_test = X_[:t], X_[t:]\n",
    "y_, y_test = y_[:t], y_[t:]\n",
    "\n",
    "t = int(X_.shape[0] * 0.9)\n",
    "X_train, X_validation = X_[:t], X_[t:]\n",
    "y_train, y_validation = y_[:t], y_[t:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = X_.shape[1]\n",
    "n_output = 1\n",
    "n_hidden1 = 64\n",
    "n_hidden2 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_ = np.random.normal(0, n_hidden1**-0.5, (n_input, n_hidden1))\n",
    "b1_ = np.random.randn(n_hidden1)\n",
    "\n",
    "W2_ = np.random.normal(n_hidden1, n_hidden2)\n",
    "b2_ = np.random.randn(n_hidden2)\n",
    "\n",
    "W3_ = np.random.normal(n_hidden2, n_output)\n",
    "b3_ = np.random.randn(n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Input(), Input()  \n",
    "W1, b1 = Input(), Input()  \n",
    "W2, b2 = Input(), Input()  \n",
    "W3, b3 = Input(), Input()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "s2 = Sigmoid(l2)\n",
    "l3 = Linear(s2, W3, b3)\n",
    "cost = MSE(y, l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    X: X_train,\n",
    "    y: y_train,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_,\n",
    "    W3: W3_,\n",
    "    b3: b3_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "epochs = 5000\n",
    "lr = 0.001\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X_train.shape[0]\n",
    "steps_per_epoch = m // batch_size\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2, W3, b3]\n",
    "losses = {'train': [], 'validation': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,64) (128,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ec66efa0c1b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mforward_and_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0msgd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/minzy/works/AI/ML/DL/miniflow/miniflow.pyc\u001b[0m in \u001b[0;36mforward_and_backward\u001b[0;34m(graph, training)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_and_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/minzy/works/AI/ML/DL/miniflow/miniflow.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mWW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,64) (128,) "
     ]
    }
   ],
   "source": [
    "#Training\n",
    "for i in range(epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        X_batch, y_batch = resample(X_train, y_train, n_samples=batch_size)\n",
    "        X.value, y.value = X_batch, y_batch\n",
    "        \n",
    "        forward_and_backward(graph)\n",
    "        sgd_update(trainables, lr)\n",
    "        train_loss += graph[-1].value\n",
    "        \n",
    "    train_loss = train_loss / steps_per_epoch\n",
    "    losses['train'].append(train_loss)\n",
    "    \n",
    "    X.value, y.value = X_validation, y_validation\n",
    "    forward_and_backward(graph, training=False)\n",
    "    val_loss = graph[-1].value\n",
    "    losses['validation'].append(val_loss)\n",
    "    \n",
    "    #if (i+1) % batch_size == 0:\n",
    "    print(\"Epoch: {}, Train Loss: {:.3f}, Validation Loss: {:.3f}\".format(i+1, train_loss, val_loss))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(losses['train']))\n",
    "ax.plot(x, losses['train'], label='Train')\n",
    "ax.plot(x, losses['validation'], label='Validation')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 35.341\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "feed_dict[X] = X_test\n",
    "feed_dict[y] = y_test\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "forward_and_backward(graph, training=False)\n",
    "loss = graph[-1].value\n",
    "print(\"Test loss: {:.3f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
