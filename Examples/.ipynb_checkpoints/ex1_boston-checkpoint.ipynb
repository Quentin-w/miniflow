{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "from miniflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "X_, y_ = shuffle(X_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datasets: 506\n",
      "Features: 13\n"
     ]
    }
   ],
   "source": [
    "# Explore data\n",
    "print (\"Total datasets: {}\".format(X_.shape[0]))\n",
    "print (\"Features: {}\".format(X_.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalized data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "t = int(X_.shape[0] * 0.9)\n",
    "X_, X_test = X_[:t], X_[t:]\n",
    "y_, y_test = y_[:t], y_[t:]\n",
    "\n",
    "t = int(X_.shape[0] * 0.9)\n",
    "X_train, X_validation = X_[:t], X_[t:]\n",
    "y_train, y_validation = y_[:t], y_[t:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = X_.shape[1]\n",
    "n_output = 1\n",
    "n_hidden1 = 64\n",
    "n_hidden2 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1_ = np.random.randn(n_input, n_hidden1)\n",
    "b1_ = np.random.randn(n_hidden1)\n",
    "\n",
    "W2_ = np.random.randn(n_hidden1, n_hidden2)\n",
    "b2_ = np.random.randn(n_hidden2)\n",
    "\n",
    "W3_ = np.random.randn(n_hidden2, n_output)\n",
    "b3_ = np.random.randn(n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = Input(), Input()  \n",
    "W1, b1 = Input(), Input()  \n",
    "W2, b2 = Input(), Input()  \n",
    "W3, b3 = Input(), Input()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "s2 = Sigmoid(l2)\n",
    "l3 = Linear(s2, W3, b3)\n",
    "cost = MSE(y, l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    X: X_train,\n",
    "    y: y_train,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_,\n",
    "    W3: W3_,\n",
    "    b3: b3_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "epochs = 5000\n",
    "lr = 0.001\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = X_train.shape[0]\n",
    "steps_per_epoch = m // batch_size\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2, W3, b3]\n",
    "losses = {'train': [], 'validation': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 569.500, Validation Loss: 238.788\n",
      "Epoch: 2, Train Loss: 248.305, Validation Loss: 93.574\n",
      "Epoch: 3, Train Loss: 113.493, Validation Loss: 56.795\n",
      "Epoch: 4, Train Loss: 61.186, Validation Loss: 48.026\n",
      "Epoch: 5, Train Loss: 62.239, Validation Loss: 45.096\n",
      "Epoch: 6, Train Loss: 56.161, Validation Loss: 44.019\n",
      "Epoch: 7, Train Loss: 38.868, Validation Loss: 43.017\n",
      "Epoch: 8, Train Loss: 55.649, Validation Loss: 42.250\n",
      "Epoch: 9, Train Loss: 57.305, Validation Loss: 41.612\n",
      "Epoch: 10, Train Loss: 39.951, Validation Loss: 40.562\n",
      "Epoch: 11, Train Loss: 39.798, Validation Loss: 39.593\n",
      "Epoch: 12, Train Loss: 43.146, Validation Loss: 39.125\n",
      "Epoch: 13, Train Loss: 58.022, Validation Loss: 38.705\n",
      "Epoch: 14, Train Loss: 59.997, Validation Loss: 38.624\n",
      "Epoch: 15, Train Loss: 41.208, Validation Loss: 37.728\n",
      "Epoch: 16, Train Loss: 36.187, Validation Loss: 36.029\n",
      "Epoch: 17, Train Loss: 42.881, Validation Loss: 35.279\n",
      "Epoch: 18, Train Loss: 36.437, Validation Loss: 33.602\n",
      "Epoch: 19, Train Loss: 37.671, Validation Loss: 33.162\n",
      "Epoch: 20, Train Loss: 42.961, Validation Loss: 32.483\n",
      "Epoch: 21, Train Loss: 45.765, Validation Loss: 31.867\n",
      "Epoch: 22, Train Loss: 49.683, Validation Loss: 31.398\n",
      "Epoch: 23, Train Loss: 36.290, Validation Loss: 30.592\n",
      "Epoch: 24, Train Loss: 48.435, Validation Loss: 30.169\n",
      "Epoch: 25, Train Loss: 47.051, Validation Loss: 29.709\n",
      "Epoch: 26, Train Loss: 28.899, Validation Loss: 28.680\n",
      "Epoch: 27, Train Loss: 35.025, Validation Loss: 28.420\n",
      "Epoch: 28, Train Loss: 39.298, Validation Loss: 28.246\n",
      "Epoch: 29, Train Loss: 38.737, Validation Loss: 27.855\n",
      "Epoch: 30, Train Loss: 36.469, Validation Loss: 27.356\n",
      "Epoch: 31, Train Loss: 25.760, Validation Loss: 26.300\n",
      "Epoch: 32, Train Loss: 31.246, Validation Loss: 25.850\n",
      "Epoch: 33, Train Loss: 36.001, Validation Loss: 25.403\n",
      "Epoch: 34, Train Loss: 35.960, Validation Loss: 25.286\n",
      "Epoch: 35, Train Loss: 29.681, Validation Loss: 24.281\n",
      "Epoch: 36, Train Loss: 34.512, Validation Loss: 23.934\n",
      "Epoch: 37, Train Loss: 43.993, Validation Loss: 24.154\n",
      "Epoch: 38, Train Loss: 35.682, Validation Loss: 23.720\n",
      "Epoch: 39, Train Loss: 36.130, Validation Loss: 23.433\n",
      "Epoch: 40, Train Loss: 28.686, Validation Loss: 22.862\n",
      "Epoch: 41, Train Loss: 29.982, Validation Loss: 22.460\n",
      "Epoch: 42, Train Loss: 35.370, Validation Loss: 22.047\n",
      "Epoch: 43, Train Loss: 34.715, Validation Loss: 22.052\n",
      "Epoch: 44, Train Loss: 38.039, Validation Loss: 21.879\n",
      "Epoch: 45, Train Loss: 37.363, Validation Loss: 21.817\n",
      "Epoch: 46, Train Loss: 34.006, Validation Loss: 21.589\n",
      "Epoch: 47, Train Loss: 38.388, Validation Loss: 21.322\n",
      "Epoch: 48, Train Loss: 32.635, Validation Loss: 20.799\n",
      "Epoch: 49, Train Loss: 26.441, Validation Loss: 20.470\n",
      "Epoch: 50, Train Loss: 42.368, Validation Loss: 20.606\n",
      "Epoch: 51, Train Loss: 31.815, Validation Loss: 20.177\n",
      "Epoch: 52, Train Loss: 29.350, Validation Loss: 19.866\n",
      "Epoch: 53, Train Loss: 29.777, Validation Loss: 19.692\n",
      "Epoch: 54, Train Loss: 24.760, Validation Loss: 19.204\n",
      "Epoch: 55, Train Loss: 33.863, Validation Loss: 19.475\n",
      "Epoch: 56, Train Loss: 27.276, Validation Loss: 18.917\n",
      "Epoch: 57, Train Loss: 25.649, Validation Loss: 18.691\n",
      "Epoch: 58, Train Loss: 32.171, Validation Loss: 18.718\n",
      "Epoch: 59, Train Loss: 31.260, Validation Loss: 18.714\n",
      "Epoch: 60, Train Loss: 25.291, Validation Loss: 18.387\n",
      "Epoch: 61, Train Loss: 25.811, Validation Loss: 18.041\n",
      "Epoch: 62, Train Loss: 30.202, Validation Loss: 18.109\n",
      "Epoch: 63, Train Loss: 27.757, Validation Loss: 18.133\n",
      "Epoch: 64, Train Loss: 30.634, Validation Loss: 18.030\n",
      "Epoch: 65, Train Loss: 28.627, Validation Loss: 17.762\n",
      "Epoch: 66, Train Loss: 29.520, Validation Loss: 17.610\n",
      "Epoch: 67, Train Loss: 26.716, Validation Loss: 17.505\n",
      "Epoch: 68, Train Loss: 28.866, Validation Loss: 17.356\n",
      "Epoch: 69, Train Loss: 24.170, Validation Loss: 17.361\n",
      "Epoch: 70, Train Loss: 17.259, Validation Loss: 16.961\n",
      "Epoch: 71, Train Loss: 29.897, Validation Loss: 17.109\n",
      "Epoch: 72, Train Loss: 24.127, Validation Loss: 16.937\n",
      "Epoch: 73, Train Loss: 26.140, Validation Loss: 16.786\n",
      "Epoch: 74, Train Loss: 24.019, Validation Loss: 16.799\n",
      "Epoch: 75, Train Loss: 20.548, Validation Loss: 16.389\n",
      "Epoch: 76, Train Loss: 23.557, Validation Loss: 16.273\n",
      "Epoch: 77, Train Loss: 25.189, Validation Loss: 16.239\n",
      "Epoch: 78, Train Loss: 28.336, Validation Loss: 16.479\n",
      "Epoch: 79, Train Loss: 23.300, Validation Loss: 16.176\n",
      "Epoch: 80, Train Loss: 25.276, Validation Loss: 16.173\n",
      "Epoch: 81, Train Loss: 26.780, Validation Loss: 16.283\n",
      "Epoch: 82, Train Loss: 21.146, Validation Loss: 15.695\n",
      "Epoch: 83, Train Loss: 22.439, Validation Loss: 15.774\n",
      "Epoch: 84, Train Loss: 24.007, Validation Loss: 15.999\n",
      "Epoch: 85, Train Loss: 27.336, Validation Loss: 15.846\n",
      "Epoch: 86, Train Loss: 25.035, Validation Loss: 15.646\n",
      "Epoch: 87, Train Loss: 17.850, Validation Loss: 15.305\n",
      "Epoch: 88, Train Loss: 26.863, Validation Loss: 15.191\n",
      "Epoch: 89, Train Loss: 22.951, Validation Loss: 15.172\n",
      "Epoch: 90, Train Loss: 19.035, Validation Loss: 14.978\n",
      "Epoch: 91, Train Loss: 16.342, Validation Loss: 14.993\n",
      "Epoch: 92, Train Loss: 26.124, Validation Loss: 15.009\n",
      "Epoch: 93, Train Loss: 22.736, Validation Loss: 14.864\n",
      "Epoch: 94, Train Loss: 20.150, Validation Loss: 14.734\n",
      "Epoch: 95, Train Loss: 19.100, Validation Loss: 14.596\n",
      "Epoch: 96, Train Loss: 20.801, Validation Loss: 14.611\n",
      "Epoch: 97, Train Loss: 22.554, Validation Loss: 14.515\n",
      "Epoch: 98, Train Loss: 21.697, Validation Loss: 14.497\n",
      "Epoch: 99, Train Loss: 21.982, Validation Loss: 14.378\n",
      "Epoch: 100, Train Loss: 22.356, Validation Loss: 14.308\n",
      "Epoch: 101, Train Loss: 21.485, Validation Loss: 14.175\n",
      "Epoch: 102, Train Loss: 28.554, Validation Loss: 14.108\n",
      "Epoch: 103, Train Loss: 23.114, Validation Loss: 14.099\n",
      "Epoch: 104, Train Loss: 21.120, Validation Loss: 13.991\n",
      "Epoch: 105, Train Loss: 18.388, Validation Loss: 13.980\n",
      "Epoch: 106, Train Loss: 22.894, Validation Loss: 13.829\n",
      "Epoch: 107, Train Loss: 24.881, Validation Loss: 13.906\n",
      "Epoch: 108, Train Loss: 24.542, Validation Loss: 14.001\n",
      "Epoch: 109, Train Loss: 21.302, Validation Loss: 13.685\n",
      "Epoch: 110, Train Loss: 18.311, Validation Loss: 13.618\n",
      "Epoch: 111, Train Loss: 22.415, Validation Loss: 13.633\n",
      "Epoch: 112, Train Loss: 21.102, Validation Loss: 13.683\n",
      "Epoch: 113, Train Loss: 20.807, Validation Loss: 13.455\n",
      "Epoch: 114, Train Loss: 19.629, Validation Loss: 13.408\n",
      "Epoch: 115, Train Loss: 27.749, Validation Loss: 13.454\n",
      "Epoch: 116, Train Loss: 19.560, Validation Loss: 13.302\n",
      "Epoch: 117, Train Loss: 26.560, Validation Loss: 13.347\n",
      "Epoch: 118, Train Loss: 21.596, Validation Loss: 13.225\n",
      "Epoch: 119, Train Loss: 22.243, Validation Loss: 13.235\n",
      "Epoch: 120, Train Loss: 24.692, Validation Loss: 13.220\n",
      "Epoch: 121, Train Loss: 14.337, Validation Loss: 13.252\n",
      "Epoch: 122, Train Loss: 24.151, Validation Loss: 13.147\n",
      "Epoch: 123, Train Loss: 20.236, Validation Loss: 13.092\n",
      "Epoch: 124, Train Loss: 16.334, Validation Loss: 12.991\n",
      "Epoch: 125, Train Loss: 21.159, Validation Loss: 13.060\n",
      "Epoch: 126, Train Loss: 17.833, Validation Loss: 12.758\n",
      "Epoch: 127, Train Loss: 19.063, Validation Loss: 12.827\n",
      "Epoch: 128, Train Loss: 13.715, Validation Loss: 12.670\n",
      "Epoch: 129, Train Loss: 27.696, Validation Loss: 12.927\n",
      "Epoch: 130, Train Loss: 18.585, Validation Loss: 12.858\n",
      "Epoch: 131, Train Loss: 21.412, Validation Loss: 12.707\n",
      "Epoch: 132, Train Loss: 17.529, Validation Loss: 12.659\n",
      "Epoch: 133, Train Loss: 19.608, Validation Loss: 12.625\n",
      "Epoch: 134, Train Loss: 22.900, Validation Loss: 12.635\n",
      "Epoch: 135, Train Loss: 14.533, Validation Loss: 12.557\n",
      "Epoch: 136, Train Loss: 18.562, Validation Loss: 12.387\n",
      "Epoch: 137, Train Loss: 27.288, Validation Loss: 12.513\n",
      "Epoch: 138, Train Loss: 19.419, Validation Loss: 12.471\n",
      "Epoch: 139, Train Loss: 19.394, Validation Loss: 12.367\n",
      "Epoch: 140, Train Loss: 17.566, Validation Loss: 12.281\n",
      "Epoch: 141, Train Loss: 19.236, Validation Loss: 12.206\n",
      "Epoch: 142, Train Loss: 24.855, Validation Loss: 12.151\n",
      "Epoch: 143, Train Loss: 20.035, Validation Loss: 12.193\n",
      "Epoch: 144, Train Loss: 17.760, Validation Loss: 12.250\n",
      "Epoch: 145, Train Loss: 17.820, Validation Loss: 12.176\n",
      "Epoch: 146, Train Loss: 23.325, Validation Loss: 12.218\n",
      "Epoch: 147, Train Loss: 22.349, Validation Loss: 12.192\n",
      "Epoch: 148, Train Loss: 25.094, Validation Loss: 12.170\n",
      "Epoch: 149, Train Loss: 21.305, Validation Loss: 11.969\n",
      "Epoch: 150, Train Loss: 18.390, Validation Loss: 11.956\n",
      "Epoch: 151, Train Loss: 18.017, Validation Loss: 11.852\n",
      "Epoch: 152, Train Loss: 21.664, Validation Loss: 11.974\n",
      "Epoch: 153, Train Loss: 20.432, Validation Loss: 11.999\n",
      "Epoch: 154, Train Loss: 19.622, Validation Loss: 11.824\n",
      "Epoch: 155, Train Loss: 21.343, Validation Loss: 11.821\n",
      "Epoch: 156, Train Loss: 21.397, Validation Loss: 11.843\n",
      "Epoch: 157, Train Loss: 16.319, Validation Loss: 11.703\n",
      "Epoch: 158, Train Loss: 17.392, Validation Loss: 11.587\n",
      "Epoch: 159, Train Loss: 16.306, Validation Loss: 11.655\n",
      "Epoch: 160, Train Loss: 20.061, Validation Loss: 11.636\n",
      "Epoch: 161, Train Loss: 23.461, Validation Loss: 11.666\n",
      "Epoch: 162, Train Loss: 18.902, Validation Loss: 11.547\n",
      "Epoch: 163, Train Loss: 21.782, Validation Loss: 11.576\n",
      "Epoch: 164, Train Loss: 17.291, Validation Loss: 11.429\n",
      "Epoch: 165, Train Loss: 21.101, Validation Loss: 11.431\n",
      "Epoch: 166, Train Loss: 18.009, Validation Loss: 11.466\n",
      "Epoch: 167, Train Loss: 20.349, Validation Loss: 11.305\n",
      "Epoch: 168, Train Loss: 14.950, Validation Loss: 11.321\n",
      "Epoch: 169, Train Loss: 15.777, Validation Loss: 11.307\n",
      "Epoch: 170, Train Loss: 14.929, Validation Loss: 11.333\n",
      "Epoch: 171, Train Loss: 17.351, Validation Loss: 11.449\n",
      "Epoch: 172, Train Loss: 20.103, Validation Loss: 11.554\n",
      "Epoch: 173, Train Loss: 16.778, Validation Loss: 11.333\n",
      "Epoch: 174, Train Loss: 17.024, Validation Loss: 11.229\n",
      "Epoch: 175, Train Loss: 15.505, Validation Loss: 11.127\n",
      "Epoch: 176, Train Loss: 12.585, Validation Loss: 11.069\n",
      "Epoch: 177, Train Loss: 17.347, Validation Loss: 11.108\n",
      "Epoch: 178, Train Loss: 18.367, Validation Loss: 11.101\n",
      "Epoch: 179, Train Loss: 15.682, Validation Loss: 11.156\n",
      "Epoch: 180, Train Loss: 16.141, Validation Loss: 11.034\n",
      "Epoch: 181, Train Loss: 17.176, Validation Loss: 11.063\n",
      "Epoch: 182, Train Loss: 13.930, Validation Loss: 10.877\n",
      "Epoch: 183, Train Loss: 16.527, Validation Loss: 10.912\n",
      "Epoch: 184, Train Loss: 13.901, Validation Loss: 11.009\n",
      "Epoch: 185, Train Loss: 17.259, Validation Loss: 11.015\n",
      "Epoch: 186, Train Loss: 15.555, Validation Loss: 10.927\n",
      "Epoch: 187, Train Loss: 10.957, Validation Loss: 10.822\n",
      "Epoch: 188, Train Loss: 19.413, Validation Loss: 10.776\n",
      "Epoch: 189, Train Loss: 15.689, Validation Loss: 10.773\n",
      "Epoch: 190, Train Loss: 16.688, Validation Loss: 10.756\n",
      "Epoch: 191, Train Loss: 15.445, Validation Loss: 10.797\n",
      "Epoch: 192, Train Loss: 15.182, Validation Loss: 10.731\n",
      "Epoch: 193, Train Loss: 16.076, Validation Loss: 10.712\n",
      "Epoch: 194, Train Loss: 18.119, Validation Loss: 10.692\n",
      "Epoch: 195, Train Loss: 13.712, Validation Loss: 10.591\n",
      "Epoch: 196, Train Loss: 18.814, Validation Loss: 10.643\n",
      "Epoch: 197, Train Loss: 21.587, Validation Loss: 10.668\n",
      "Epoch: 198, Train Loss: 20.881, Validation Loss: 10.817\n",
      "Epoch: 199, Train Loss: 21.206, Validation Loss: 10.655\n",
      "Epoch: 200, Train Loss: 13.573, Validation Loss: 10.479\n",
      "Epoch: 201, Train Loss: 18.359, Validation Loss: 10.560\n",
      "Epoch: 202, Train Loss: 15.597, Validation Loss: 10.544\n",
      "Epoch: 203, Train Loss: 14.175, Validation Loss: 10.410\n",
      "Epoch: 204, Train Loss: 21.508, Validation Loss: 10.480\n",
      "Epoch: 205, Train Loss: 19.633, Validation Loss: 10.461\n",
      "Epoch: 206, Train Loss: 15.821, Validation Loss: 10.481\n",
      "Epoch: 207, Train Loss: 16.220, Validation Loss: 10.344\n",
      "Epoch: 208, Train Loss: 16.872, Validation Loss: 10.366\n",
      "Epoch: 209, Train Loss: 19.923, Validation Loss: 10.374\n",
      "Epoch: 210, Train Loss: 15.693, Validation Loss: 10.340\n",
      "Epoch: 211, Train Loss: 14.206, Validation Loss: 10.302\n",
      "Epoch: 212, Train Loss: 15.478, Validation Loss: 10.283\n",
      "Epoch: 213, Train Loss: 18.831, Validation Loss: 10.318\n",
      "Epoch: 214, Train Loss: 20.049, Validation Loss: 10.657\n",
      "Epoch: 215, Train Loss: 15.412, Validation Loss: 10.495\n",
      "Epoch: 216, Train Loss: 15.595, Validation Loss: 10.515\n",
      "Epoch: 217, Train Loss: 14.904, Validation Loss: 10.363\n",
      "Epoch: 218, Train Loss: 13.688, Validation Loss: 10.212\n",
      "Epoch: 219, Train Loss: 17.049, Validation Loss: 10.272\n",
      "Epoch: 220, Train Loss: 15.070, Validation Loss: 10.213\n",
      "Epoch: 221, Train Loss: 23.575, Validation Loss: 10.352\n",
      "Epoch: 222, Train Loss: 14.510, Validation Loss: 10.167\n",
      "Epoch: 223, Train Loss: 17.679, Validation Loss: 10.298\n",
      "Epoch: 224, Train Loss: 15.199, Validation Loss: 10.231\n",
      "Epoch: 225, Train Loss: 12.974, Validation Loss: 10.157\n",
      "Epoch: 226, Train Loss: 13.394, Validation Loss: 10.107\n",
      "Epoch: 227, Train Loss: 21.203, Validation Loss: 10.276\n",
      "Epoch: 228, Train Loss: 13.956, Validation Loss: 10.204\n",
      "Epoch: 229, Train Loss: 20.496, Validation Loss: 10.109\n",
      "Epoch: 230, Train Loss: 19.557, Validation Loss: 9.936\n",
      "Epoch: 231, Train Loss: 16.761, Validation Loss: 9.889\n",
      "Epoch: 232, Train Loss: 11.927, Validation Loss: 9.848\n",
      "Epoch: 233, Train Loss: 22.292, Validation Loss: 9.966\n",
      "Epoch: 234, Train Loss: 16.580, Validation Loss: 9.823\n",
      "Epoch: 235, Train Loss: 14.455, Validation Loss: 9.914\n",
      "Epoch: 236, Train Loss: 15.828, Validation Loss: 9.883\n",
      "Epoch: 237, Train Loss: 13.505, Validation Loss: 9.844\n",
      "Epoch: 238, Train Loss: 17.459, Validation Loss: 9.774\n",
      "Epoch: 239, Train Loss: 18.399, Validation Loss: 9.760\n",
      "Epoch: 240, Train Loss: 16.304, Validation Loss: 9.666\n",
      "Epoch: 241, Train Loss: 13.792, Validation Loss: 9.639\n",
      "Epoch: 242, Train Loss: 17.280, Validation Loss: 9.622\n",
      "Epoch: 243, Train Loss: 15.838, Validation Loss: 9.617\n",
      "Epoch: 244, Train Loss: 12.235, Validation Loss: 9.625\n",
      "Epoch: 245, Train Loss: 17.364, Validation Loss: 9.617\n",
      "Epoch: 246, Train Loss: 16.936, Validation Loss: 9.646\n",
      "Epoch: 247, Train Loss: 12.684, Validation Loss: 9.673\n",
      "Epoch: 248, Train Loss: 16.959, Validation Loss: 9.603\n",
      "Epoch: 249, Train Loss: 16.125, Validation Loss: 9.617\n",
      "Epoch: 250, Train Loss: 13.335, Validation Loss: 9.581\n",
      "Epoch: 251, Train Loss: 20.113, Validation Loss: 9.682\n",
      "Epoch: 252, Train Loss: 15.487, Validation Loss: 9.653\n",
      "Epoch: 253, Train Loss: 18.923, Validation Loss: 9.640\n",
      "Epoch: 254, Train Loss: 13.571, Validation Loss: 9.541\n",
      "Epoch: 255, Train Loss: 14.159, Validation Loss: 9.563\n",
      "Epoch: 256, Train Loss: 12.298, Validation Loss: 9.481\n",
      "Epoch: 257, Train Loss: 15.177, Validation Loss: 9.491\n",
      "Epoch: 258, Train Loss: 14.453, Validation Loss: 9.394\n",
      "Epoch: 259, Train Loss: 16.270, Validation Loss: 9.397\n",
      "Epoch: 260, Train Loss: 15.340, Validation Loss: 9.386\n",
      "Epoch: 261, Train Loss: 19.515, Validation Loss: 9.413\n",
      "Epoch: 262, Train Loss: 10.167, Validation Loss: 9.320\n",
      "Epoch: 263, Train Loss: 11.327, Validation Loss: 9.277\n",
      "Epoch: 264, Train Loss: 18.829, Validation Loss: 9.320\n",
      "Epoch: 265, Train Loss: 13.733, Validation Loss: 9.266\n",
      "Epoch: 266, Train Loss: 20.715, Validation Loss: 9.435\n",
      "Epoch: 267, Train Loss: 17.898, Validation Loss: 9.528\n",
      "Epoch: 268, Train Loss: 13.655, Validation Loss: 9.622\n",
      "Epoch: 269, Train Loss: 16.672, Validation Loss: 9.490\n",
      "Epoch: 270, Train Loss: 15.832, Validation Loss: 9.260\n",
      "Epoch: 271, Train Loss: 15.869, Validation Loss: 9.257\n",
      "Epoch: 272, Train Loss: 11.903, Validation Loss: 9.194\n",
      "Epoch: 273, Train Loss: 11.679, Validation Loss: 9.197\n",
      "Epoch: 274, Train Loss: 14.259, Validation Loss: 9.126\n",
      "Epoch: 275, Train Loss: 14.356, Validation Loss: 9.154\n",
      "Epoch: 276, Train Loss: 13.947, Validation Loss: 9.214\n",
      "Epoch: 277, Train Loss: 16.025, Validation Loss: 9.179\n",
      "Epoch: 278, Train Loss: 14.865, Validation Loss: 9.081\n",
      "Epoch: 279, Train Loss: 16.221, Validation Loss: 9.150\n",
      "Epoch: 280, Train Loss: 16.428, Validation Loss: 9.173\n",
      "Epoch: 281, Train Loss: 17.091, Validation Loss: 9.037\n",
      "Epoch: 282, Train Loss: 14.855, Validation Loss: 9.067\n",
      "Epoch: 283, Train Loss: 16.607, Validation Loss: 9.110\n",
      "Epoch: 284, Train Loss: 13.408, Validation Loss: 9.022\n",
      "Epoch: 285, Train Loss: 12.365, Validation Loss: 9.062\n",
      "Epoch: 286, Train Loss: 18.949, Validation Loss: 8.998\n",
      "Epoch: 287, Train Loss: 16.269, Validation Loss: 9.061\n",
      "Epoch: 288, Train Loss: 14.449, Validation Loss: 8.969\n",
      "Epoch: 289, Train Loss: 14.814, Validation Loss: 9.051\n",
      "Epoch: 290, Train Loss: 14.665, Validation Loss: 9.032\n",
      "Epoch: 291, Train Loss: 13.230, Validation Loss: 9.014\n",
      "Epoch: 292, Train Loss: 12.638, Validation Loss: 8.942\n",
      "Epoch: 293, Train Loss: 16.205, Validation Loss: 8.946\n",
      "Epoch: 294, Train Loss: 13.924, Validation Loss: 8.880\n",
      "Epoch: 295, Train Loss: 12.421, Validation Loss: 8.830\n",
      "Epoch: 296, Train Loss: 14.582, Validation Loss: 8.960\n",
      "Epoch: 297, Train Loss: 10.289, Validation Loss: 8.946\n",
      "Epoch: 298, Train Loss: 13.680, Validation Loss: 8.967\n",
      "Epoch: 299, Train Loss: 12.480, Validation Loss: 8.912\n",
      "Epoch: 300, Train Loss: 14.656, Validation Loss: 8.924\n",
      "Epoch: 301, Train Loss: 15.502, Validation Loss: 8.974\n",
      "Epoch: 302, Train Loss: 12.993, Validation Loss: 8.918\n",
      "Epoch: 303, Train Loss: 13.129, Validation Loss: 8.895\n",
      "Epoch: 304, Train Loss: 14.635, Validation Loss: 8.993\n",
      "Epoch: 305, Train Loss: 12.013, Validation Loss: 8.830\n",
      "Epoch: 306, Train Loss: 12.238, Validation Loss: 8.826\n",
      "Epoch: 307, Train Loss: 15.942, Validation Loss: 8.841\n",
      "Epoch: 308, Train Loss: 16.607, Validation Loss: 8.937\n",
      "Epoch: 309, Train Loss: 14.905, Validation Loss: 8.858\n",
      "Epoch: 310, Train Loss: 12.620, Validation Loss: 8.782\n",
      "Epoch: 311, Train Loss: 14.990, Validation Loss: 8.821\n",
      "Epoch: 312, Train Loss: 12.184, Validation Loss: 8.828\n",
      "Epoch: 313, Train Loss: 16.805, Validation Loss: 8.768\n",
      "Epoch: 314, Train Loss: 16.580, Validation Loss: 8.775\n",
      "Epoch: 315, Train Loss: 12.968, Validation Loss: 8.711\n",
      "Epoch: 316, Train Loss: 17.064, Validation Loss: 8.690\n",
      "Epoch: 317, Train Loss: 13.353, Validation Loss: 8.671\n",
      "Epoch: 318, Train Loss: 15.568, Validation Loss: 8.695\n",
      "Epoch: 319, Train Loss: 14.529, Validation Loss: 8.696\n",
      "Epoch: 320, Train Loss: 15.972, Validation Loss: 8.669\n",
      "Epoch: 321, Train Loss: 19.541, Validation Loss: 8.815\n",
      "Epoch: 322, Train Loss: 18.475, Validation Loss: 8.782\n",
      "Epoch: 323, Train Loss: 14.641, Validation Loss: 8.777\n",
      "Epoch: 324, Train Loss: 16.669, Validation Loss: 8.841\n",
      "Epoch: 325, Train Loss: 12.664, Validation Loss: 8.655\n",
      "Epoch: 326, Train Loss: 10.319, Validation Loss: 8.592\n",
      "Epoch: 327, Train Loss: 13.402, Validation Loss: 8.629\n",
      "Epoch: 328, Train Loss: 13.825, Validation Loss: 8.533\n",
      "Epoch: 329, Train Loss: 12.189, Validation Loss: 8.496\n",
      "Epoch: 330, Train Loss: 10.897, Validation Loss: 8.498\n",
      "Epoch: 331, Train Loss: 20.060, Validation Loss: 8.640\n",
      "Epoch: 332, Train Loss: 12.922, Validation Loss: 8.650\n",
      "Epoch: 333, Train Loss: 13.787, Validation Loss: 8.570\n",
      "Epoch: 334, Train Loss: 12.335, Validation Loss: 8.585\n",
      "Epoch: 335, Train Loss: 11.020, Validation Loss: 8.667\n",
      "Epoch: 336, Train Loss: 13.062, Validation Loss: 8.616\n",
      "Epoch: 337, Train Loss: 11.764, Validation Loss: 8.543\n",
      "Epoch: 338, Train Loss: 12.506, Validation Loss: 8.556\n",
      "Epoch: 339, Train Loss: 13.212, Validation Loss: 8.536\n",
      "Epoch: 340, Train Loss: 13.765, Validation Loss: 8.538\n",
      "Epoch: 341, Train Loss: 11.912, Validation Loss: 8.493\n",
      "Epoch: 342, Train Loss: 11.685, Validation Loss: 8.489\n",
      "Epoch: 343, Train Loss: 16.394, Validation Loss: 8.485\n",
      "Epoch: 344, Train Loss: 18.583, Validation Loss: 8.572\n",
      "Epoch: 345, Train Loss: 12.568, Validation Loss: 8.611\n",
      "Epoch: 346, Train Loss: 10.533, Validation Loss: 8.462\n",
      "Epoch: 347, Train Loss: 11.563, Validation Loss: 8.513\n",
      "Epoch: 348, Train Loss: 9.888, Validation Loss: 8.322\n",
      "Epoch: 349, Train Loss: 14.388, Validation Loss: 8.380\n",
      "Epoch: 350, Train Loss: 12.559, Validation Loss: 8.364\n",
      "Epoch: 351, Train Loss: 9.434, Validation Loss: 8.342\n",
      "Epoch: 352, Train Loss: 10.910, Validation Loss: 8.297\n",
      "Epoch: 353, Train Loss: 15.367, Validation Loss: 8.369\n",
      "Epoch: 354, Train Loss: 16.351, Validation Loss: 8.556\n",
      "Epoch: 355, Train Loss: 8.999, Validation Loss: 8.411\n",
      "Epoch: 356, Train Loss: 11.981, Validation Loss: 8.333\n",
      "Epoch: 357, Train Loss: 12.005, Validation Loss: 8.352\n",
      "Epoch: 358, Train Loss: 14.740, Validation Loss: 8.332\n",
      "Epoch: 359, Train Loss: 11.954, Validation Loss: 8.288\n",
      "Epoch: 360, Train Loss: 13.613, Validation Loss: 8.361\n",
      "Epoch: 361, Train Loss: 12.872, Validation Loss: 8.293\n",
      "Epoch: 362, Train Loss: 12.378, Validation Loss: 8.328\n",
      "Epoch: 363, Train Loss: 12.848, Validation Loss: 8.401\n",
      "Epoch: 364, Train Loss: 11.256, Validation Loss: 8.408\n",
      "Epoch: 365, Train Loss: 12.748, Validation Loss: 8.424\n",
      "Epoch: 366, Train Loss: 12.973, Validation Loss: 8.298\n",
      "Epoch: 367, Train Loss: 11.785, Validation Loss: 8.283\n",
      "Epoch: 368, Train Loss: 12.735, Validation Loss: 8.344\n",
      "Epoch: 369, Train Loss: 11.184, Validation Loss: 8.422\n",
      "Epoch: 370, Train Loss: 11.530, Validation Loss: 8.317\n",
      "Epoch: 371, Train Loss: 13.630, Validation Loss: 8.306\n",
      "Epoch: 372, Train Loss: 8.826, Validation Loss: 8.321\n",
      "Epoch: 373, Train Loss: 13.350, Validation Loss: 8.385\n",
      "Epoch: 374, Train Loss: 12.498, Validation Loss: 8.358\n",
      "Epoch: 375, Train Loss: 12.186, Validation Loss: 8.301\n",
      "Epoch: 376, Train Loss: 11.148, Validation Loss: 8.248\n",
      "Epoch: 377, Train Loss: 13.352, Validation Loss: 8.206\n",
      "Epoch: 378, Train Loss: 10.508, Validation Loss: 8.145\n",
      "Epoch: 379, Train Loss: 11.141, Validation Loss: 8.090\n",
      "Epoch: 380, Train Loss: 11.010, Validation Loss: 8.075\n",
      "Epoch: 381, Train Loss: 14.044, Validation Loss: 8.059\n",
      "Epoch: 382, Train Loss: 12.759, Validation Loss: 8.088\n",
      "Epoch: 383, Train Loss: 9.960, Validation Loss: 8.011\n",
      "Epoch: 384, Train Loss: 12.175, Validation Loss: 8.036\n",
      "Epoch: 385, Train Loss: 11.782, Validation Loss: 7.985\n",
      "Epoch: 386, Train Loss: 13.750, Validation Loss: 8.023\n",
      "Epoch: 387, Train Loss: 12.505, Validation Loss: 8.018\n",
      "Epoch: 388, Train Loss: 14.909, Validation Loss: 8.095\n",
      "Epoch: 389, Train Loss: 8.934, Validation Loss: 8.124\n",
      "Epoch: 390, Train Loss: 12.189, Validation Loss: 8.152\n",
      "Epoch: 391, Train Loss: 12.706, Validation Loss: 8.131\n",
      "Epoch: 392, Train Loss: 10.064, Validation Loss: 8.074\n",
      "Epoch: 393, Train Loss: 10.737, Validation Loss: 8.021\n",
      "Epoch: 394, Train Loss: 10.865, Validation Loss: 8.040\n",
      "Epoch: 395, Train Loss: 16.667, Validation Loss: 8.037\n",
      "Epoch: 396, Train Loss: 12.136, Validation Loss: 8.045\n",
      "Epoch: 397, Train Loss: 13.114, Validation Loss: 7.997\n",
      "Epoch: 398, Train Loss: 12.674, Validation Loss: 7.966\n",
      "Epoch: 399, Train Loss: 12.799, Validation Loss: 7.963\n",
      "Epoch: 400, Train Loss: 11.346, Validation Loss: 7.945\n",
      "Epoch: 401, Train Loss: 11.679, Validation Loss: 7.928\n",
      "Epoch: 402, Train Loss: 11.428, Validation Loss: 7.898\n",
      "Epoch: 403, Train Loss: 11.825, Validation Loss: 7.961\n",
      "Epoch: 404, Train Loss: 11.915, Validation Loss: 8.045\n",
      "Epoch: 405, Train Loss: 11.183, Validation Loss: 8.013\n",
      "Epoch: 406, Train Loss: 14.531, Validation Loss: 8.052\n",
      "Epoch: 407, Train Loss: 13.686, Validation Loss: 7.935\n",
      "Epoch: 408, Train Loss: 8.831, Validation Loss: 7.795\n",
      "Epoch: 409, Train Loss: 12.244, Validation Loss: 7.780\n",
      "Epoch: 410, Train Loss: 12.329, Validation Loss: 7.904\n",
      "Epoch: 411, Train Loss: 10.334, Validation Loss: 7.893\n",
      "Epoch: 412, Train Loss: 7.628, Validation Loss: 7.842\n",
      "Epoch: 413, Train Loss: 11.834, Validation Loss: 7.805\n",
      "Epoch: 414, Train Loss: 15.152, Validation Loss: 7.856\n",
      "Epoch: 415, Train Loss: 13.515, Validation Loss: 7.860\n",
      "Epoch: 416, Train Loss: 13.535, Validation Loss: 7.715\n",
      "Epoch: 417, Train Loss: 9.290, Validation Loss: 7.714\n",
      "Epoch: 418, Train Loss: 9.834, Validation Loss: 7.757\n",
      "Epoch: 419, Train Loss: 6.885, Validation Loss: 7.743\n",
      "Epoch: 420, Train Loss: 9.119, Validation Loss: 7.824\n",
      "Epoch: 421, Train Loss: 9.746, Validation Loss: 7.802\n",
      "Epoch: 422, Train Loss: 12.389, Validation Loss: 7.833\n",
      "Epoch: 423, Train Loss: 11.196, Validation Loss: 7.870\n",
      "Epoch: 424, Train Loss: 13.204, Validation Loss: 7.927\n",
      "Epoch: 425, Train Loss: 12.534, Validation Loss: 7.864\n",
      "Epoch: 426, Train Loss: 11.202, Validation Loss: 7.810\n",
      "Epoch: 427, Train Loss: 11.999, Validation Loss: 7.818\n",
      "Epoch: 428, Train Loss: 9.183, Validation Loss: 7.775\n",
      "Epoch: 429, Train Loss: 11.946, Validation Loss: 7.752\n",
      "Epoch: 430, Train Loss: 11.896, Validation Loss: 7.759\n",
      "Epoch: 431, Train Loss: 13.806, Validation Loss: 7.775\n",
      "Epoch: 432, Train Loss: 9.076, Validation Loss: 7.748\n",
      "Epoch: 433, Train Loss: 13.240, Validation Loss: 7.764\n",
      "Epoch: 434, Train Loss: 11.275, Validation Loss: 7.714\n",
      "Epoch: 435, Train Loss: 11.627, Validation Loss: 7.682\n",
      "Epoch: 436, Train Loss: 8.776, Validation Loss: 7.662\n",
      "Epoch: 437, Train Loss: 11.119, Validation Loss: 7.667\n",
      "Epoch: 438, Train Loss: 11.784, Validation Loss: 7.687\n",
      "Epoch: 439, Train Loss: 10.761, Validation Loss: 7.673\n",
      "Epoch: 440, Train Loss: 8.621, Validation Loss: 7.711\n",
      "Epoch: 441, Train Loss: 11.237, Validation Loss: 7.694\n",
      "Epoch: 442, Train Loss: 11.359, Validation Loss: 7.664\n",
      "Epoch: 443, Train Loss: 10.423, Validation Loss: 7.599\n",
      "Epoch: 444, Train Loss: 8.875, Validation Loss: 7.645\n",
      "Epoch: 445, Train Loss: 11.024, Validation Loss: 7.694\n",
      "Epoch: 446, Train Loss: 12.982, Validation Loss: 7.626\n",
      "Epoch: 447, Train Loss: 9.454, Validation Loss: 7.582\n",
      "Epoch: 448, Train Loss: 12.250, Validation Loss: 7.610\n",
      "Epoch: 449, Train Loss: 15.165, Validation Loss: 7.605\n",
      "Epoch: 450, Train Loss: 12.579, Validation Loss: 7.624\n",
      "Epoch: 451, Train Loss: 9.765, Validation Loss: 7.577\n",
      "Epoch: 452, Train Loss: 9.520, Validation Loss: 7.568\n",
      "Epoch: 453, Train Loss: 9.015, Validation Loss: 7.590\n",
      "Epoch: 454, Train Loss: 10.524, Validation Loss: 7.551\n",
      "Epoch: 455, Train Loss: 11.463, Validation Loss: 7.602\n",
      "Epoch: 456, Train Loss: 9.449, Validation Loss: 7.559\n",
      "Epoch: 457, Train Loss: 11.755, Validation Loss: 7.479\n",
      "Epoch: 458, Train Loss: 12.681, Validation Loss: 7.499\n",
      "Epoch: 459, Train Loss: 9.367, Validation Loss: 7.468\n",
      "Epoch: 460, Train Loss: 10.929, Validation Loss: 7.488\n",
      "Epoch: 461, Train Loss: 8.538, Validation Loss: 7.462\n",
      "Epoch: 462, Train Loss: 11.678, Validation Loss: 7.525\n",
      "Epoch: 463, Train Loss: 15.906, Validation Loss: 7.642\n",
      "Epoch: 464, Train Loss: 13.693, Validation Loss: 7.608\n",
      "Epoch: 465, Train Loss: 11.022, Validation Loss: 7.554\n",
      "Epoch: 466, Train Loss: 11.361, Validation Loss: 7.403\n",
      "Epoch: 467, Train Loss: 10.078, Validation Loss: 7.395\n",
      "Epoch: 468, Train Loss: 11.635, Validation Loss: 7.425\n",
      "Epoch: 469, Train Loss: 11.071, Validation Loss: 7.322\n",
      "Epoch: 470, Train Loss: 11.963, Validation Loss: 7.359\n",
      "Epoch: 471, Train Loss: 8.829, Validation Loss: 7.401\n",
      "Epoch: 472, Train Loss: 13.793, Validation Loss: 7.433\n",
      "Epoch: 473, Train Loss: 13.103, Validation Loss: 7.423\n",
      "Epoch: 474, Train Loss: 9.481, Validation Loss: 7.355\n",
      "Epoch: 475, Train Loss: 8.620, Validation Loss: 7.348\n",
      "Epoch: 476, Train Loss: 10.813, Validation Loss: 7.444\n",
      "Epoch: 477, Train Loss: 9.198, Validation Loss: 7.389\n",
      "Epoch: 478, Train Loss: 12.775, Validation Loss: 7.470\n",
      "Epoch: 479, Train Loss: 11.877, Validation Loss: 7.477\n",
      "Epoch: 480, Train Loss: 12.165, Validation Loss: 7.482\n",
      "Epoch: 481, Train Loss: 10.022, Validation Loss: 7.368\n",
      "Epoch: 482, Train Loss: 11.431, Validation Loss: 7.490\n",
      "Epoch: 483, Train Loss: 10.422, Validation Loss: 7.431\n",
      "Epoch: 484, Train Loss: 9.297, Validation Loss: 7.332\n",
      "Epoch: 485, Train Loss: 11.249, Validation Loss: 7.357\n",
      "Epoch: 486, Train Loss: 13.844, Validation Loss: 7.388\n",
      "Epoch: 487, Train Loss: 8.392, Validation Loss: 7.347\n",
      "Epoch: 488, Train Loss: 10.455, Validation Loss: 7.313\n",
      "Epoch: 489, Train Loss: 9.684, Validation Loss: 7.375\n",
      "Epoch: 490, Train Loss: 11.622, Validation Loss: 7.372\n",
      "Epoch: 491, Train Loss: 10.701, Validation Loss: 7.382\n",
      "Epoch: 492, Train Loss: 10.522, Validation Loss: 7.321\n",
      "Epoch: 493, Train Loss: 13.159, Validation Loss: 7.341\n",
      "Epoch: 494, Train Loss: 9.310, Validation Loss: 7.409\n",
      "Epoch: 495, Train Loss: 11.919, Validation Loss: 7.365\n",
      "Epoch: 496, Train Loss: 12.345, Validation Loss: 7.423\n",
      "Epoch: 497, Train Loss: 11.287, Validation Loss: 7.445\n",
      "Epoch: 498, Train Loss: 9.741, Validation Loss: 7.429\n",
      "Epoch: 499, Train Loss: 10.114, Validation Loss: 7.434\n",
      "Epoch: 500, Train Loss: 14.595, Validation Loss: 7.560\n",
      "Epoch: 501, Train Loss: 9.587, Validation Loss: 7.478\n",
      "Epoch: 502, Train Loss: 9.324, Validation Loss: 7.397\n",
      "Epoch: 503, Train Loss: 9.262, Validation Loss: 7.422\n",
      "Epoch: 504, Train Loss: 9.718, Validation Loss: 7.387\n",
      "Epoch: 505, Train Loss: 11.125, Validation Loss: 7.363\n",
      "Epoch: 506, Train Loss: 9.700, Validation Loss: 7.316\n",
      "Epoch: 507, Train Loss: 10.222, Validation Loss: 7.335\n",
      "Epoch: 508, Train Loss: 7.599, Validation Loss: 7.305\n",
      "Epoch: 509, Train Loss: 8.066, Validation Loss: 7.275\n",
      "Epoch: 510, Train Loss: 9.622, Validation Loss: 7.373\n",
      "Epoch: 511, Train Loss: 10.495, Validation Loss: 7.377\n",
      "Epoch: 512, Train Loss: 10.735, Validation Loss: 7.337\n",
      "Epoch: 513, Train Loss: 8.882, Validation Loss: 7.257\n",
      "Epoch: 514, Train Loss: 11.691, Validation Loss: 7.243\n",
      "Epoch: 515, Train Loss: 7.697, Validation Loss: 7.296\n",
      "Epoch: 516, Train Loss: 10.818, Validation Loss: 7.311\n",
      "Epoch: 517, Train Loss: 12.401, Validation Loss: 7.333\n",
      "Epoch: 518, Train Loss: 11.587, Validation Loss: 7.422\n",
      "Epoch: 519, Train Loss: 10.384, Validation Loss: 7.401\n",
      "Epoch: 520, Train Loss: 9.852, Validation Loss: 7.385\n",
      "Epoch: 521, Train Loss: 14.419, Validation Loss: 7.364\n",
      "Epoch: 522, Train Loss: 10.198, Validation Loss: 7.480\n",
      "Epoch: 523, Train Loss: 14.286, Validation Loss: 7.561\n",
      "Epoch: 524, Train Loss: 6.826, Validation Loss: 7.413\n",
      "Epoch: 525, Train Loss: 9.406, Validation Loss: 7.337\n",
      "Epoch: 526, Train Loss: 8.412, Validation Loss: 7.277\n",
      "Epoch: 527, Train Loss: 9.512, Validation Loss: 7.262\n",
      "Epoch: 528, Train Loss: 8.377, Validation Loss: 7.232\n",
      "Epoch: 529, Train Loss: 8.704, Validation Loss: 7.229\n",
      "Epoch: 530, Train Loss: 8.303, Validation Loss: 7.214\n",
      "Epoch: 531, Train Loss: 10.026, Validation Loss: 7.231\n",
      "Epoch: 532, Train Loss: 11.087, Validation Loss: 7.219\n",
      "Epoch: 533, Train Loss: 8.418, Validation Loss: 7.255\n",
      "Epoch: 534, Train Loss: 9.264, Validation Loss: 7.251\n",
      "Epoch: 535, Train Loss: 8.602, Validation Loss: 7.311\n",
      "Epoch: 536, Train Loss: 6.705, Validation Loss: 7.293\n",
      "Epoch: 537, Train Loss: 9.279, Validation Loss: 7.316\n",
      "Epoch: 538, Train Loss: 9.304, Validation Loss: 7.239\n",
      "Epoch: 539, Train Loss: 9.089, Validation Loss: 7.273\n",
      "Epoch: 540, Train Loss: 9.373, Validation Loss: 7.353\n",
      "Epoch: 541, Train Loss: 12.676, Validation Loss: 7.281\n",
      "Epoch: 542, Train Loss: 13.594, Validation Loss: 7.234\n",
      "Epoch: 543, Train Loss: 11.522, Validation Loss: 7.279\n",
      "Epoch: 544, Train Loss: 7.372, Validation Loss: 7.147\n",
      "Epoch: 545, Train Loss: 8.017, Validation Loss: 7.162\n",
      "Epoch: 546, Train Loss: 7.339, Validation Loss: 7.198\n",
      "Epoch: 547, Train Loss: 9.336, Validation Loss: 7.223\n",
      "Epoch: 548, Train Loss: 11.711, Validation Loss: 7.224\n",
      "Epoch: 549, Train Loss: 6.952, Validation Loss: 7.199\n",
      "Epoch: 550, Train Loss: 9.880, Validation Loss: 7.176\n",
      "Epoch: 551, Train Loss: 6.059, Validation Loss: 7.181\n",
      "Epoch: 552, Train Loss: 8.150, Validation Loss: 7.200\n",
      "Epoch: 553, Train Loss: 7.553, Validation Loss: 7.180\n",
      "Epoch: 554, Train Loss: 12.417, Validation Loss: 7.135\n",
      "Epoch: 555, Train Loss: 8.050, Validation Loss: 7.115\n",
      "Epoch: 556, Train Loss: 7.986, Validation Loss: 7.173\n",
      "Epoch: 557, Train Loss: 9.297, Validation Loss: 7.218\n",
      "Epoch: 558, Train Loss: 10.832, Validation Loss: 7.227\n",
      "Epoch: 559, Train Loss: 10.188, Validation Loss: 7.164\n",
      "Epoch: 560, Train Loss: 7.617, Validation Loss: 7.097\n",
      "Epoch: 561, Train Loss: 9.897, Validation Loss: 7.174\n",
      "Epoch: 562, Train Loss: 10.265, Validation Loss: 7.128\n",
      "Epoch: 563, Train Loss: 9.907, Validation Loss: 7.173\n",
      "Epoch: 564, Train Loss: 8.123, Validation Loss: 7.130\n",
      "Epoch: 565, Train Loss: 7.670, Validation Loss: 7.088\n",
      "Epoch: 566, Train Loss: 11.038, Validation Loss: 7.151\n",
      "Epoch: 567, Train Loss: 10.761, Validation Loss: 7.129\n",
      "Epoch: 568, Train Loss: 10.069, Validation Loss: 7.199\n",
      "Epoch: 569, Train Loss: 12.008, Validation Loss: 7.146\n",
      "Epoch: 570, Train Loss: 9.079, Validation Loss: 7.051\n",
      "Epoch: 571, Train Loss: 10.888, Validation Loss: 7.022\n",
      "Epoch: 572, Train Loss: 8.924, Validation Loss: 7.033\n",
      "Epoch: 573, Train Loss: 7.448, Validation Loss: 7.014\n",
      "Epoch: 574, Train Loss: 10.016, Validation Loss: 7.055\n",
      "Epoch: 575, Train Loss: 8.326, Validation Loss: 7.084\n",
      "Epoch: 576, Train Loss: 10.055, Validation Loss: 7.082\n",
      "Epoch: 577, Train Loss: 8.987, Validation Loss: 7.119\n",
      "Epoch: 578, Train Loss: 10.944, Validation Loss: 7.141\n",
      "Epoch: 579, Train Loss: 10.503, Validation Loss: 7.063\n",
      "Epoch: 580, Train Loss: 9.241, Validation Loss: 7.031\n",
      "Epoch: 581, Train Loss: 10.179, Validation Loss: 7.051\n",
      "Epoch: 582, Train Loss: 9.290, Validation Loss: 6.950\n",
      "Epoch: 583, Train Loss: 6.753, Validation Loss: 6.945\n",
      "Epoch: 584, Train Loss: 6.941, Validation Loss: 6.974\n",
      "Epoch: 585, Train Loss: 7.190, Validation Loss: 6.973\n",
      "Epoch: 586, Train Loss: 11.890, Validation Loss: 6.934\n",
      "Epoch: 587, Train Loss: 9.990, Validation Loss: 6.961\n",
      "Epoch: 588, Train Loss: 9.285, Validation Loss: 7.031\n",
      "Epoch: 589, Train Loss: 9.646, Validation Loss: 7.021\n",
      "Epoch: 590, Train Loss: 9.891, Validation Loss: 6.940\n",
      "Epoch: 591, Train Loss: 8.582, Validation Loss: 6.971\n",
      "Epoch: 592, Train Loss: 8.065, Validation Loss: 6.897\n",
      "Epoch: 593, Train Loss: 10.676, Validation Loss: 6.966\n",
      "Epoch: 594, Train Loss: 7.800, Validation Loss: 6.924\n",
      "Epoch: 595, Train Loss: 7.586, Validation Loss: 6.942\n",
      "Epoch: 596, Train Loss: 8.955, Validation Loss: 7.018\n",
      "Epoch: 597, Train Loss: 9.319, Validation Loss: 6.959\n",
      "Epoch: 598, Train Loss: 6.959, Validation Loss: 6.978\n",
      "Epoch: 599, Train Loss: 8.245, Validation Loss: 6.960\n",
      "Epoch: 600, Train Loss: 5.733, Validation Loss: 7.001\n",
      "Epoch: 601, Train Loss: 9.248, Validation Loss: 6.971\n",
      "Epoch: 602, Train Loss: 10.119, Validation Loss: 6.949\n",
      "Epoch: 603, Train Loss: 8.386, Validation Loss: 6.933\n",
      "Epoch: 604, Train Loss: 9.300, Validation Loss: 6.968\n",
      "Epoch: 605, Train Loss: 9.048, Validation Loss: 6.979\n",
      "Epoch: 606, Train Loss: 11.556, Validation Loss: 6.933\n",
      "Epoch: 607, Train Loss: 8.941, Validation Loss: 6.901\n",
      "Epoch: 608, Train Loss: 8.718, Validation Loss: 7.014\n",
      "Epoch: 609, Train Loss: 9.328, Validation Loss: 6.895\n",
      "Epoch: 610, Train Loss: 8.195, Validation Loss: 6.865\n",
      "Epoch: 611, Train Loss: 10.285, Validation Loss: 6.931\n",
      "Epoch: 612, Train Loss: 8.091, Validation Loss: 6.889\n",
      "Epoch: 613, Train Loss: 8.937, Validation Loss: 6.959\n",
      "Epoch: 614, Train Loss: 8.287, Validation Loss: 6.941\n",
      "Epoch: 615, Train Loss: 10.930, Validation Loss: 6.902\n",
      "Epoch: 616, Train Loss: 6.950, Validation Loss: 6.876\n",
      "Epoch: 617, Train Loss: 11.935, Validation Loss: 6.871\n",
      "Epoch: 618, Train Loss: 9.322, Validation Loss: 6.865\n",
      "Epoch: 619, Train Loss: 8.757, Validation Loss: 6.842\n",
      "Epoch: 620, Train Loss: 7.592, Validation Loss: 6.971\n",
      "Epoch: 621, Train Loss: 10.515, Validation Loss: 6.984\n",
      "Epoch: 622, Train Loss: 10.078, Validation Loss: 6.964\n",
      "Epoch: 623, Train Loss: 9.833, Validation Loss: 7.043\n",
      "Epoch: 624, Train Loss: 8.382, Validation Loss: 7.028\n",
      "Epoch: 625, Train Loss: 10.048, Validation Loss: 6.996\n",
      "Epoch: 626, Train Loss: 8.687, Validation Loss: 6.896\n",
      "Epoch: 627, Train Loss: 9.537, Validation Loss: 6.861\n",
      "Epoch: 628, Train Loss: 9.197, Validation Loss: 6.903\n",
      "Epoch: 629, Train Loss: 7.955, Validation Loss: 6.892\n",
      "Epoch: 630, Train Loss: 8.410, Validation Loss: 6.870\n",
      "Epoch: 631, Train Loss: 9.771, Validation Loss: 6.867\n",
      "Epoch: 632, Train Loss: 7.189, Validation Loss: 6.858\n",
      "Epoch: 633, Train Loss: 6.734, Validation Loss: 6.874\n",
      "Epoch: 634, Train Loss: 8.855, Validation Loss: 6.934\n",
      "Epoch: 635, Train Loss: 8.047, Validation Loss: 6.900\n",
      "Epoch: 636, Train Loss: 8.842, Validation Loss: 6.903\n",
      "Epoch: 637, Train Loss: 8.183, Validation Loss: 6.856\n",
      "Epoch: 638, Train Loss: 8.889, Validation Loss: 6.884\n",
      "Epoch: 639, Train Loss: 6.996, Validation Loss: 6.886\n",
      "Epoch: 640, Train Loss: 6.445, Validation Loss: 6.907\n",
      "Epoch: 641, Train Loss: 8.555, Validation Loss: 6.942\n",
      "Epoch: 642, Train Loss: 6.678, Validation Loss: 6.915\n",
      "Epoch: 643, Train Loss: 12.303, Validation Loss: 6.973\n",
      "Epoch: 644, Train Loss: 8.866, Validation Loss: 7.017\n",
      "Epoch: 645, Train Loss: 8.315, Validation Loss: 6.962\n",
      "Epoch: 646, Train Loss: 7.602, Validation Loss: 6.999\n",
      "Epoch: 647, Train Loss: 9.096, Validation Loss: 6.944\n",
      "Epoch: 648, Train Loss: 9.023, Validation Loss: 6.991\n",
      "Epoch: 649, Train Loss: 8.694, Validation Loss: 6.875\n",
      "Epoch: 650, Train Loss: 8.015, Validation Loss: 6.875\n",
      "Epoch: 651, Train Loss: 9.348, Validation Loss: 6.850\n",
      "Epoch: 652, Train Loss: 8.624, Validation Loss: 6.850\n",
      "Epoch: 653, Train Loss: 9.996, Validation Loss: 6.808\n",
      "Epoch: 654, Train Loss: 9.135, Validation Loss: 6.844\n",
      "Epoch: 655, Train Loss: 10.413, Validation Loss: 6.914\n",
      "Epoch: 656, Train Loss: 11.474, Validation Loss: 6.911\n",
      "Epoch: 657, Train Loss: 6.813, Validation Loss: 6.840\n",
      "Epoch: 658, Train Loss: 7.700, Validation Loss: 6.744\n",
      "Epoch: 659, Train Loss: 8.789, Validation Loss: 6.773\n",
      "Epoch: 660, Train Loss: 8.754, Validation Loss: 6.857\n",
      "Epoch: 661, Train Loss: 6.008, Validation Loss: 6.778\n",
      "Epoch: 662, Train Loss: 6.063, Validation Loss: 6.822\n",
      "Epoch: 663, Train Loss: 10.723, Validation Loss: 6.845\n",
      "Epoch: 664, Train Loss: 8.525, Validation Loss: 6.810\n",
      "Epoch: 665, Train Loss: 8.167, Validation Loss: 6.753\n",
      "Epoch: 666, Train Loss: 9.922, Validation Loss: 6.794\n",
      "Epoch: 667, Train Loss: 8.684, Validation Loss: 6.720\n",
      "Epoch: 668, Train Loss: 7.824, Validation Loss: 6.741\n",
      "Epoch: 669, Train Loss: 7.659, Validation Loss: 6.747\n",
      "Epoch: 670, Train Loss: 12.108, Validation Loss: 6.810\n",
      "Epoch: 671, Train Loss: 11.093, Validation Loss: 6.793\n",
      "Epoch: 672, Train Loss: 5.850, Validation Loss: 6.768\n",
      "Epoch: 673, Train Loss: 7.548, Validation Loss: 6.815\n",
      "Epoch: 674, Train Loss: 7.364, Validation Loss: 6.778\n",
      "Epoch: 675, Train Loss: 8.477, Validation Loss: 6.749\n",
      "Epoch: 676, Train Loss: 7.709, Validation Loss: 6.782\n",
      "Epoch: 677, Train Loss: 8.095, Validation Loss: 6.781\n",
      "Epoch: 678, Train Loss: 11.291, Validation Loss: 6.810\n",
      "Epoch: 679, Train Loss: 9.872, Validation Loss: 6.813\n",
      "Epoch: 680, Train Loss: 7.653, Validation Loss: 6.795\n",
      "Epoch: 681, Train Loss: 9.392, Validation Loss: 6.811\n",
      "Epoch: 682, Train Loss: 10.379, Validation Loss: 6.793\n",
      "Epoch: 683, Train Loss: 7.880, Validation Loss: 6.802\n",
      "Epoch: 684, Train Loss: 9.841, Validation Loss: 6.788\n",
      "Epoch: 685, Train Loss: 9.121, Validation Loss: 6.773\n",
      "Epoch: 686, Train Loss: 8.265, Validation Loss: 6.816\n",
      "Epoch: 687, Train Loss: 5.436, Validation Loss: 6.812\n",
      "Epoch: 688, Train Loss: 6.833, Validation Loss: 6.808\n",
      "Epoch: 689, Train Loss: 8.523, Validation Loss: 6.792\n",
      "Epoch: 690, Train Loss: 8.767, Validation Loss: 6.772\n",
      "Epoch: 691, Train Loss: 7.931, Validation Loss: 6.800\n",
      "Epoch: 692, Train Loss: 7.602, Validation Loss: 6.786\n",
      "Epoch: 693, Train Loss: 8.754, Validation Loss: 6.784\n",
      "Epoch: 694, Train Loss: 9.632, Validation Loss: 6.839\n",
      "Epoch: 695, Train Loss: 6.656, Validation Loss: 6.857\n",
      "Epoch: 696, Train Loss: 10.026, Validation Loss: 6.884\n",
      "Epoch: 697, Train Loss: 8.830, Validation Loss: 6.850\n",
      "Epoch: 698, Train Loss: 8.063, Validation Loss: 6.793\n",
      "Epoch: 699, Train Loss: 6.558, Validation Loss: 6.792\n",
      "Epoch: 700, Train Loss: 5.920, Validation Loss: 6.844\n",
      "Epoch: 701, Train Loss: 8.119, Validation Loss: 6.802\n",
      "Epoch: 702, Train Loss: 7.841, Validation Loss: 6.825\n",
      "Epoch: 703, Train Loss: 9.923, Validation Loss: 6.820\n",
      "Epoch: 704, Train Loss: 8.493, Validation Loss: 6.834\n",
      "Epoch: 705, Train Loss: 6.272, Validation Loss: 6.804\n",
      "Epoch: 706, Train Loss: 5.951, Validation Loss: 6.799\n",
      "Epoch: 707, Train Loss: 8.673, Validation Loss: 6.823\n",
      "Epoch: 708, Train Loss: 7.686, Validation Loss: 6.819\n",
      "Epoch: 709, Train Loss: 7.126, Validation Loss: 6.743\n",
      "Epoch: 710, Train Loss: 7.460, Validation Loss: 6.775\n",
      "Epoch: 711, Train Loss: 5.398, Validation Loss: 6.796\n",
      "Epoch: 712, Train Loss: 9.532, Validation Loss: 6.781\n",
      "Epoch: 713, Train Loss: 8.869, Validation Loss: 6.807\n",
      "Epoch: 714, Train Loss: 6.812, Validation Loss: 6.810\n",
      "Epoch: 715, Train Loss: 4.907, Validation Loss: 6.770\n",
      "Epoch: 716, Train Loss: 8.096, Validation Loss: 6.739\n",
      "Epoch: 717, Train Loss: 5.781, Validation Loss: 6.700\n",
      "Epoch: 718, Train Loss: 10.850, Validation Loss: 6.682\n",
      "Epoch: 719, Train Loss: 9.310, Validation Loss: 6.728\n",
      "Epoch: 720, Train Loss: 7.854, Validation Loss: 6.699\n",
      "Epoch: 721, Train Loss: 7.840, Validation Loss: 6.718\n",
      "Epoch: 722, Train Loss: 8.722, Validation Loss: 6.712\n",
      "Epoch: 723, Train Loss: 7.449, Validation Loss: 6.714\n",
      "Epoch: 724, Train Loss: 6.636, Validation Loss: 6.751\n",
      "Epoch: 725, Train Loss: 6.425, Validation Loss: 6.753\n",
      "Epoch: 726, Train Loss: 7.913, Validation Loss: 6.729\n",
      "Epoch: 727, Train Loss: 6.283, Validation Loss: 6.700\n",
      "Epoch: 728, Train Loss: 6.981, Validation Loss: 6.714\n",
      "Epoch: 729, Train Loss: 7.259, Validation Loss: 6.689\n",
      "Epoch: 730, Train Loss: 10.971, Validation Loss: 6.701\n",
      "Epoch: 731, Train Loss: 6.594, Validation Loss: 6.763\n",
      "Epoch: 732, Train Loss: 8.532, Validation Loss: 6.720\n",
      "Epoch: 733, Train Loss: 8.467, Validation Loss: 6.734\n",
      "Epoch: 734, Train Loss: 8.488, Validation Loss: 6.720\n",
      "Epoch: 735, Train Loss: 9.024, Validation Loss: 6.719\n",
      "Epoch: 736, Train Loss: 6.278, Validation Loss: 6.751\n",
      "Epoch: 737, Train Loss: 7.751, Validation Loss: 6.810\n",
      "Epoch: 738, Train Loss: 9.076, Validation Loss: 6.816\n",
      "Epoch: 739, Train Loss: 9.161, Validation Loss: 6.747\n",
      "Epoch: 740, Train Loss: 7.333, Validation Loss: 6.721\n",
      "Epoch: 741, Train Loss: 8.536, Validation Loss: 6.758\n",
      "Epoch: 742, Train Loss: 7.029, Validation Loss: 6.694\n",
      "Epoch: 743, Train Loss: 8.123, Validation Loss: 6.721\n",
      "Epoch: 744, Train Loss: 9.029, Validation Loss: 6.744\n",
      "Epoch: 745, Train Loss: 8.139, Validation Loss: 6.798\n",
      "Epoch: 746, Train Loss: 7.289, Validation Loss: 6.767\n",
      "Epoch: 747, Train Loss: 9.634, Validation Loss: 6.734\n",
      "Epoch: 748, Train Loss: 7.893, Validation Loss: 6.759\n",
      "Epoch: 749, Train Loss: 7.206, Validation Loss: 6.743\n",
      "Epoch: 750, Train Loss: 7.578, Validation Loss: 6.767\n",
      "Epoch: 751, Train Loss: 8.379, Validation Loss: 6.733\n",
      "Epoch: 752, Train Loss: 6.875, Validation Loss: 6.737\n",
      "Epoch: 753, Train Loss: 10.459, Validation Loss: 6.713\n",
      "Epoch: 754, Train Loss: 7.961, Validation Loss: 6.695\n",
      "Epoch: 755, Train Loss: 7.551, Validation Loss: 6.717\n",
      "Epoch: 756, Train Loss: 7.906, Validation Loss: 6.686\n",
      "Epoch: 757, Train Loss: 7.977, Validation Loss: 6.715\n",
      "Epoch: 758, Train Loss: 5.833, Validation Loss: 6.696\n",
      "Epoch: 759, Train Loss: 7.913, Validation Loss: 6.672\n",
      "Epoch: 760, Train Loss: 8.480, Validation Loss: 6.702\n",
      "Epoch: 761, Train Loss: 5.498, Validation Loss: 6.695\n",
      "Epoch: 762, Train Loss: 6.856, Validation Loss: 6.691\n",
      "Epoch: 763, Train Loss: 6.776, Validation Loss: 6.650\n",
      "Epoch: 764, Train Loss: 7.361, Validation Loss: 6.702\n",
      "Epoch: 765, Train Loss: 8.492, Validation Loss: 6.710\n",
      "Epoch: 766, Train Loss: 9.098, Validation Loss: 6.680\n",
      "Epoch: 767, Train Loss: 10.310, Validation Loss: 6.649\n",
      "Epoch: 768, Train Loss: 7.055, Validation Loss: 6.648\n",
      "Epoch: 769, Train Loss: 6.951, Validation Loss: 6.646\n",
      "Epoch: 770, Train Loss: 7.235, Validation Loss: 6.654\n",
      "Epoch: 771, Train Loss: 6.088, Validation Loss: 6.582\n",
      "Epoch: 772, Train Loss: 7.499, Validation Loss: 6.611\n",
      "Epoch: 773, Train Loss: 9.602, Validation Loss: 6.567\n",
      "Epoch: 774, Train Loss: 7.492, Validation Loss: 6.598\n",
      "Epoch: 775, Train Loss: 6.031, Validation Loss: 6.601\n",
      "Epoch: 776, Train Loss: 8.829, Validation Loss: 6.609\n",
      "Epoch: 777, Train Loss: 7.360, Validation Loss: 6.557\n",
      "Epoch: 778, Train Loss: 8.365, Validation Loss: 6.601\n",
      "Epoch: 779, Train Loss: 9.661, Validation Loss: 6.571\n",
      "Epoch: 780, Train Loss: 8.503, Validation Loss: 6.552\n",
      "Epoch: 781, Train Loss: 10.391, Validation Loss: 6.546\n",
      "Epoch: 782, Train Loss: 9.938, Validation Loss: 6.567\n",
      "Epoch: 783, Train Loss: 7.772, Validation Loss: 6.600\n",
      "Epoch: 784, Train Loss: 11.406, Validation Loss: 6.522\n",
      "Epoch: 785, Train Loss: 10.040, Validation Loss: 6.526\n",
      "Epoch: 786, Train Loss: 9.385, Validation Loss: 6.525\n",
      "Epoch: 787, Train Loss: 6.885, Validation Loss: 6.515\n",
      "Epoch: 788, Train Loss: 8.479, Validation Loss: 6.531\n",
      "Epoch: 789, Train Loss: 10.335, Validation Loss: 6.527\n",
      "Epoch: 790, Train Loss: 8.900, Validation Loss: 6.531\n",
      "Epoch: 791, Train Loss: 9.109, Validation Loss: 6.518\n",
      "Epoch: 792, Train Loss: 6.299, Validation Loss: 6.539\n",
      "Epoch: 793, Train Loss: 8.703, Validation Loss: 6.533\n",
      "Epoch: 794, Train Loss: 10.129, Validation Loss: 6.511\n",
      "Epoch: 795, Train Loss: 7.299, Validation Loss: 6.517\n",
      "Epoch: 796, Train Loss: 7.959, Validation Loss: 6.601\n",
      "Epoch: 797, Train Loss: 6.128, Validation Loss: 6.615\n",
      "Epoch: 798, Train Loss: 7.543, Validation Loss: 6.563\n",
      "Epoch: 799, Train Loss: 7.349, Validation Loss: 6.594\n",
      "Epoch: 800, Train Loss: 7.840, Validation Loss: 6.570\n",
      "Epoch: 801, Train Loss: 5.815, Validation Loss: 6.523\n",
      "Epoch: 802, Train Loss: 5.704, Validation Loss: 6.530\n",
      "Epoch: 803, Train Loss: 6.655, Validation Loss: 6.548\n",
      "Epoch: 804, Train Loss: 5.565, Validation Loss: 6.562\n",
      "Epoch: 805, Train Loss: 7.962, Validation Loss: 6.585\n",
      "Epoch: 806, Train Loss: 8.331, Validation Loss: 6.595\n",
      "Epoch: 807, Train Loss: 7.349, Validation Loss: 6.558\n",
      "Epoch: 808, Train Loss: 7.895, Validation Loss: 6.515\n",
      "Epoch: 809, Train Loss: 6.363, Validation Loss: 6.500\n",
      "Epoch: 810, Train Loss: 7.681, Validation Loss: 6.541\n",
      "Epoch: 811, Train Loss: 8.256, Validation Loss: 6.550\n",
      "Epoch: 812, Train Loss: 6.295, Validation Loss: 6.527\n",
      "Epoch: 813, Train Loss: 9.243, Validation Loss: 6.574\n",
      "Epoch: 814, Train Loss: 6.794, Validation Loss: 6.510\n",
      "Epoch: 815, Train Loss: 7.379, Validation Loss: 6.508\n",
      "Epoch: 816, Train Loss: 7.946, Validation Loss: 6.475\n",
      "Epoch: 817, Train Loss: 6.823, Validation Loss: 6.511\n",
      "Epoch: 818, Train Loss: 6.692, Validation Loss: 6.544\n",
      "Epoch: 819, Train Loss: 7.471, Validation Loss: 6.558\n",
      "Epoch: 820, Train Loss: 8.932, Validation Loss: 6.592\n",
      "Epoch: 821, Train Loss: 6.464, Validation Loss: 6.592\n",
      "Epoch: 822, Train Loss: 8.875, Validation Loss: 6.566\n",
      "Epoch: 823, Train Loss: 8.628, Validation Loss: 6.528\n",
      "Epoch: 824, Train Loss: 9.504, Validation Loss: 6.538\n",
      "Epoch: 825, Train Loss: 6.265, Validation Loss: 6.506\n",
      "Epoch: 826, Train Loss: 9.341, Validation Loss: 6.529\n",
      "Epoch: 827, Train Loss: 8.536, Validation Loss: 6.567\n",
      "Epoch: 828, Train Loss: 7.515, Validation Loss: 6.512\n",
      "Epoch: 829, Train Loss: 6.329, Validation Loss: 6.505\n",
      "Epoch: 830, Train Loss: 8.261, Validation Loss: 6.536\n",
      "Epoch: 831, Train Loss: 8.370, Validation Loss: 6.551\n",
      "Epoch: 832, Train Loss: 5.850, Validation Loss: 6.518\n",
      "Epoch: 833, Train Loss: 8.233, Validation Loss: 6.498\n",
      "Epoch: 834, Train Loss: 8.054, Validation Loss: 6.524\n",
      "Epoch: 835, Train Loss: 8.431, Validation Loss: 6.501\n",
      "Epoch: 836, Train Loss: 6.630, Validation Loss: 6.470\n",
      "Epoch: 837, Train Loss: 7.964, Validation Loss: 6.472\n",
      "Epoch: 838, Train Loss: 8.305, Validation Loss: 6.471\n",
      "Epoch: 839, Train Loss: 6.302, Validation Loss: 6.444\n",
      "Epoch: 840, Train Loss: 5.812, Validation Loss: 6.423\n",
      "Epoch: 841, Train Loss: 6.375, Validation Loss: 6.431\n",
      "Epoch: 842, Train Loss: 6.496, Validation Loss: 6.425\n",
      "Epoch: 843, Train Loss: 6.760, Validation Loss: 6.457\n",
      "Epoch: 844, Train Loss: 8.753, Validation Loss: 6.444\n",
      "Epoch: 845, Train Loss: 7.002, Validation Loss: 6.435\n",
      "Epoch: 846, Train Loss: 9.147, Validation Loss: 6.421\n",
      "Epoch: 847, Train Loss: 8.431, Validation Loss: 6.416\n",
      "Epoch: 848, Train Loss: 8.634, Validation Loss: 6.440\n",
      "Epoch: 849, Train Loss: 5.248, Validation Loss: 6.440\n",
      "Epoch: 850, Train Loss: 7.830, Validation Loss: 6.467\n",
      "Epoch: 851, Train Loss: 6.454, Validation Loss: 6.470\n",
      "Epoch: 852, Train Loss: 5.793, Validation Loss: 6.471\n",
      "Epoch: 853, Train Loss: 5.140, Validation Loss: 6.477\n",
      "Epoch: 854, Train Loss: 7.723, Validation Loss: 6.504\n",
      "Epoch: 855, Train Loss: 6.918, Validation Loss: 6.536\n",
      "Epoch: 856, Train Loss: 9.335, Validation Loss: 6.538\n",
      "Epoch: 857, Train Loss: 7.260, Validation Loss: 6.499\n",
      "Epoch: 858, Train Loss: 7.324, Validation Loss: 6.517\n",
      "Epoch: 859, Train Loss: 7.433, Validation Loss: 6.496\n",
      "Epoch: 860, Train Loss: 6.913, Validation Loss: 6.498\n",
      "Epoch: 861, Train Loss: 7.502, Validation Loss: 6.501\n",
      "Epoch: 862, Train Loss: 6.143, Validation Loss: 6.490\n",
      "Epoch: 863, Train Loss: 8.732, Validation Loss: 6.519\n",
      "Epoch: 864, Train Loss: 6.770, Validation Loss: 6.516\n",
      "Epoch: 865, Train Loss: 5.633, Validation Loss: 6.509\n",
      "Epoch: 866, Train Loss: 6.855, Validation Loss: 6.491\n",
      "Epoch: 867, Train Loss: 5.779, Validation Loss: 6.510\n",
      "Epoch: 868, Train Loss: 7.725, Validation Loss: 6.506\n",
      "Epoch: 869, Train Loss: 5.335, Validation Loss: 6.497\n",
      "Epoch: 870, Train Loss: 6.850, Validation Loss: 6.500\n",
      "Epoch: 871, Train Loss: 6.281, Validation Loss: 6.496\n",
      "Epoch: 872, Train Loss: 7.070, Validation Loss: 6.464\n",
      "Epoch: 873, Train Loss: 6.887, Validation Loss: 6.440\n",
      "Epoch: 874, Train Loss: 5.525, Validation Loss: 6.447\n",
      "Epoch: 875, Train Loss: 7.456, Validation Loss: 6.473\n",
      "Epoch: 876, Train Loss: 6.019, Validation Loss: 6.485\n",
      "Epoch: 877, Train Loss: 6.980, Validation Loss: 6.479\n",
      "Epoch: 878, Train Loss: 6.515, Validation Loss: 6.497\n",
      "Epoch: 879, Train Loss: 9.364, Validation Loss: 6.501\n",
      "Epoch: 880, Train Loss: 5.688, Validation Loss: 6.455\n",
      "Epoch: 881, Train Loss: 6.472, Validation Loss: 6.492\n",
      "Epoch: 882, Train Loss: 7.520, Validation Loss: 6.508\n",
      "Epoch: 883, Train Loss: 5.618, Validation Loss: 6.543\n",
      "Epoch: 884, Train Loss: 7.584, Validation Loss: 6.522\n",
      "Epoch: 885, Train Loss: 6.667, Validation Loss: 6.479\n",
      "Epoch: 886, Train Loss: 8.089, Validation Loss: 6.502\n",
      "Epoch: 887, Train Loss: 6.591, Validation Loss: 6.501\n",
      "Epoch: 888, Train Loss: 8.768, Validation Loss: 6.493\n",
      "Epoch: 889, Train Loss: 6.772, Validation Loss: 6.468\n",
      "Epoch: 890, Train Loss: 5.305, Validation Loss: 6.453\n",
      "Epoch: 891, Train Loss: 7.827, Validation Loss: 6.474\n",
      "Epoch: 892, Train Loss: 5.786, Validation Loss: 6.504\n",
      "Epoch: 893, Train Loss: 9.369, Validation Loss: 6.522\n",
      "Epoch: 894, Train Loss: 5.804, Validation Loss: 6.473\n",
      "Epoch: 895, Train Loss: 6.049, Validation Loss: 6.479\n",
      "Epoch: 896, Train Loss: 6.905, Validation Loss: 6.470\n",
      "Epoch: 897, Train Loss: 6.252, Validation Loss: 6.478\n",
      "Epoch: 898, Train Loss: 6.929, Validation Loss: 6.492\n",
      "Epoch: 899, Train Loss: 6.463, Validation Loss: 6.483\n",
      "Epoch: 900, Train Loss: 7.030, Validation Loss: 6.459\n",
      "Epoch: 901, Train Loss: 6.725, Validation Loss: 6.457\n",
      "Epoch: 902, Train Loss: 7.353, Validation Loss: 6.449\n",
      "Epoch: 903, Train Loss: 8.834, Validation Loss: 6.443\n",
      "Epoch: 904, Train Loss: 6.810, Validation Loss: 6.457\n",
      "Epoch: 905, Train Loss: 7.414, Validation Loss: 6.476\n",
      "Epoch: 906, Train Loss: 7.906, Validation Loss: 6.454\n",
      "Epoch: 907, Train Loss: 5.445, Validation Loss: 6.456\n",
      "Epoch: 908, Train Loss: 8.016, Validation Loss: 6.478\n",
      "Epoch: 909, Train Loss: 5.833, Validation Loss: 6.481\n",
      "Epoch: 910, Train Loss: 7.784, Validation Loss: 6.461\n",
      "Epoch: 911, Train Loss: 7.847, Validation Loss: 6.459\n",
      "Epoch: 912, Train Loss: 7.053, Validation Loss: 6.429\n",
      "Epoch: 913, Train Loss: 6.976, Validation Loss: 6.453\n",
      "Epoch: 914, Train Loss: 8.677, Validation Loss: 6.426\n",
      "Epoch: 915, Train Loss: 6.172, Validation Loss: 6.404\n",
      "Epoch: 916, Train Loss: 6.259, Validation Loss: 6.421\n",
      "Epoch: 917, Train Loss: 6.941, Validation Loss: 6.427\n",
      "Epoch: 918, Train Loss: 7.472, Validation Loss: 6.432\n",
      "Epoch: 919, Train Loss: 5.753, Validation Loss: 6.416\n",
      "Epoch: 920, Train Loss: 9.231, Validation Loss: 6.454\n",
      "Epoch: 921, Train Loss: 7.905, Validation Loss: 6.437\n",
      "Epoch: 922, Train Loss: 6.283, Validation Loss: 6.471\n",
      "Epoch: 923, Train Loss: 5.161, Validation Loss: 6.488\n",
      "Epoch: 924, Train Loss: 6.126, Validation Loss: 6.454\n",
      "Epoch: 925, Train Loss: 7.315, Validation Loss: 6.449\n",
      "Epoch: 926, Train Loss: 5.694, Validation Loss: 6.433\n",
      "Epoch: 927, Train Loss: 8.302, Validation Loss: 6.426\n",
      "Epoch: 928, Train Loss: 5.523, Validation Loss: 6.424\n",
      "Epoch: 929, Train Loss: 7.615, Validation Loss: 6.433\n",
      "Epoch: 930, Train Loss: 6.225, Validation Loss: 6.441\n",
      "Epoch: 931, Train Loss: 6.132, Validation Loss: 6.435\n",
      "Epoch: 932, Train Loss: 5.869, Validation Loss: 6.498\n",
      "Epoch: 933, Train Loss: 7.113, Validation Loss: 6.471\n",
      "Epoch: 934, Train Loss: 7.423, Validation Loss: 6.457\n",
      "Epoch: 935, Train Loss: 6.935, Validation Loss: 6.481\n",
      "Epoch: 936, Train Loss: 6.239, Validation Loss: 6.497\n",
      "Epoch: 937, Train Loss: 7.681, Validation Loss: 6.499\n",
      "Epoch: 938, Train Loss: 6.839, Validation Loss: 6.479\n",
      "Epoch: 939, Train Loss: 6.992, Validation Loss: 6.448\n",
      "Epoch: 940, Train Loss: 5.907, Validation Loss: 6.489\n",
      "Epoch: 941, Train Loss: 6.096, Validation Loss: 6.446\n",
      "Epoch: 942, Train Loss: 6.150, Validation Loss: 6.419\n",
      "Epoch: 943, Train Loss: 6.780, Validation Loss: 6.472\n",
      "Epoch: 944, Train Loss: 7.144, Validation Loss: 6.449\n",
      "Epoch: 945, Train Loss: 6.238, Validation Loss: 6.446\n",
      "Epoch: 946, Train Loss: 6.625, Validation Loss: 6.435\n",
      "Epoch: 947, Train Loss: 6.178, Validation Loss: 6.425\n",
      "Epoch: 948, Train Loss: 4.462, Validation Loss: 6.436\n",
      "Epoch: 949, Train Loss: 6.442, Validation Loss: 6.418\n",
      "Epoch: 950, Train Loss: 6.439, Validation Loss: 6.436\n",
      "Epoch: 951, Train Loss: 5.612, Validation Loss: 6.463\n",
      "Epoch: 952, Train Loss: 5.532, Validation Loss: 6.447\n",
      "Epoch: 953, Train Loss: 7.886, Validation Loss: 6.421\n",
      "Epoch: 954, Train Loss: 6.635, Validation Loss: 6.401\n",
      "Epoch: 955, Train Loss: 5.139, Validation Loss: 6.406\n",
      "Epoch: 956, Train Loss: 4.817, Validation Loss: 6.421\n",
      "Epoch: 957, Train Loss: 7.004, Validation Loss: 6.384\n",
      "Epoch: 958, Train Loss: 5.732, Validation Loss: 6.428\n",
      "Epoch: 959, Train Loss: 5.072, Validation Loss: 6.413\n",
      "Epoch: 960, Train Loss: 7.158, Validation Loss: 6.426\n",
      "Epoch: 961, Train Loss: 5.348, Validation Loss: 6.402\n",
      "Epoch: 962, Train Loss: 7.119, Validation Loss: 6.421\n",
      "Epoch: 963, Train Loss: 7.522, Validation Loss: 6.408\n",
      "Epoch: 964, Train Loss: 6.244, Validation Loss: 6.406\n",
      "Epoch: 965, Train Loss: 7.802, Validation Loss: 6.450\n",
      "Epoch: 966, Train Loss: 7.254, Validation Loss: 6.370\n",
      "Epoch: 967, Train Loss: 5.568, Validation Loss: 6.393\n",
      "Epoch: 968, Train Loss: 5.412, Validation Loss: 6.387\n",
      "Epoch: 969, Train Loss: 6.260, Validation Loss: 6.378\n",
      "Epoch: 970, Train Loss: 5.246, Validation Loss: 6.367\n",
      "Epoch: 971, Train Loss: 6.425, Validation Loss: 6.393\n",
      "Epoch: 972, Train Loss: 6.600, Validation Loss: 6.404\n",
      "Epoch: 973, Train Loss: 6.044, Validation Loss: 6.374\n",
      "Epoch: 974, Train Loss: 6.607, Validation Loss: 6.371\n",
      "Epoch: 975, Train Loss: 7.068, Validation Loss: 6.396\n",
      "Epoch: 976, Train Loss: 7.556, Validation Loss: 6.378\n",
      "Epoch: 977, Train Loss: 4.756, Validation Loss: 6.382\n",
      "Epoch: 978, Train Loss: 7.259, Validation Loss: 6.394\n",
      "Epoch: 979, Train Loss: 5.119, Validation Loss: 6.415\n",
      "Epoch: 980, Train Loss: 8.234, Validation Loss: 6.407\n",
      "Epoch: 981, Train Loss: 5.264, Validation Loss: 6.424\n",
      "Epoch: 982, Train Loss: 5.920, Validation Loss: 6.444\n",
      "Epoch: 983, Train Loss: 8.056, Validation Loss: 6.441\n",
      "Epoch: 984, Train Loss: 5.791, Validation Loss: 6.394\n",
      "Epoch: 985, Train Loss: 5.775, Validation Loss: 6.378\n",
      "Epoch: 986, Train Loss: 4.430, Validation Loss: 6.359\n",
      "Epoch: 987, Train Loss: 4.718, Validation Loss: 6.379\n",
      "Epoch: 988, Train Loss: 5.480, Validation Loss: 6.384\n",
      "Epoch: 989, Train Loss: 7.857, Validation Loss: 6.378\n",
      "Epoch: 990, Train Loss: 5.905, Validation Loss: 6.466\n",
      "Epoch: 991, Train Loss: 6.974, Validation Loss: 6.491\n",
      "Epoch: 992, Train Loss: 5.187, Validation Loss: 6.484\n",
      "Epoch: 993, Train Loss: 5.905, Validation Loss: 6.449\n",
      "Epoch: 994, Train Loss: 5.274, Validation Loss: 6.441\n",
      "Epoch: 995, Train Loss: 6.239, Validation Loss: 6.443\n",
      "Epoch: 996, Train Loss: 6.411, Validation Loss: 6.428\n",
      "Epoch: 997, Train Loss: 5.679, Validation Loss: 6.426\n",
      "Epoch: 998, Train Loss: 6.257, Validation Loss: 6.382\n",
      "Epoch: 999, Train Loss: 5.077, Validation Loss: 6.355\n",
      "Epoch: 1000, Train Loss: 5.175, Validation Loss: 6.345\n",
      "Epoch: 1001, Train Loss: 5.797, Validation Loss: 6.334\n",
      "Epoch: 1002, Train Loss: 6.666, Validation Loss: 6.330\n",
      "Epoch: 1003, Train Loss: 5.875, Validation Loss: 6.361\n",
      "Epoch: 1004, Train Loss: 5.530, Validation Loss: 6.367\n",
      "Epoch: 1005, Train Loss: 6.843, Validation Loss: 6.322\n",
      "Epoch: 1006, Train Loss: 7.201, Validation Loss: 6.328\n",
      "Epoch: 1007, Train Loss: 6.818, Validation Loss: 6.329\n",
      "Epoch: 1008, Train Loss: 6.525, Validation Loss: 6.396\n",
      "Epoch: 1009, Train Loss: 6.246, Validation Loss: 6.359\n",
      "Epoch: 1010, Train Loss: 7.247, Validation Loss: 6.382\n",
      "Epoch: 1011, Train Loss: 6.881, Validation Loss: 6.372\n",
      "Epoch: 1012, Train Loss: 7.348, Validation Loss: 6.406\n",
      "Epoch: 1013, Train Loss: 5.910, Validation Loss: 6.383\n",
      "Epoch: 1014, Train Loss: 7.493, Validation Loss: 6.322\n",
      "Epoch: 1015, Train Loss: 6.009, Validation Loss: 6.325\n",
      "Epoch: 1016, Train Loss: 6.005, Validation Loss: 6.312\n",
      "Epoch: 1017, Train Loss: 5.519, Validation Loss: 6.367\n",
      "Epoch: 1018, Train Loss: 5.266, Validation Loss: 6.358\n",
      "Epoch: 1019, Train Loss: 7.390, Validation Loss: 6.322\n",
      "Epoch: 1020, Train Loss: 7.019, Validation Loss: 6.351\n",
      "Epoch: 1021, Train Loss: 7.461, Validation Loss: 6.320\n",
      "Epoch: 1022, Train Loss: 5.770, Validation Loss: 6.341\n",
      "Epoch: 1023, Train Loss: 7.202, Validation Loss: 6.329\n",
      "Epoch: 1024, Train Loss: 6.979, Validation Loss: 6.337\n",
      "Epoch: 1025, Train Loss: 4.778, Validation Loss: 6.345\n",
      "Epoch: 1026, Train Loss: 7.458, Validation Loss: 6.342\n",
      "Epoch: 1027, Train Loss: 5.551, Validation Loss: 6.307\n",
      "Epoch: 1028, Train Loss: 6.778, Validation Loss: 6.304\n",
      "Epoch: 1029, Train Loss: 4.633, Validation Loss: 6.335\n",
      "Epoch: 1030, Train Loss: 4.916, Validation Loss: 6.335\n",
      "Epoch: 1031, Train Loss: 6.021, Validation Loss: 6.345\n",
      "Epoch: 1032, Train Loss: 5.929, Validation Loss: 6.344\n",
      "Epoch: 1033, Train Loss: 5.404, Validation Loss: 6.343\n",
      "Epoch: 1034, Train Loss: 5.229, Validation Loss: 6.339\n",
      "Epoch: 1035, Train Loss: 6.125, Validation Loss: 6.330\n",
      "Epoch: 1036, Train Loss: 5.033, Validation Loss: 6.356\n",
      "Epoch: 1037, Train Loss: 5.791, Validation Loss: 6.322\n",
      "Epoch: 1038, Train Loss: 4.223, Validation Loss: 6.343\n",
      "Epoch: 1039, Train Loss: 7.470, Validation Loss: 6.360\n",
      "Epoch: 1040, Train Loss: 7.679, Validation Loss: 6.357\n",
      "Epoch: 1041, Train Loss: 4.689, Validation Loss: 6.363\n",
      "Epoch: 1042, Train Loss: 6.419, Validation Loss: 6.340\n",
      "Epoch: 1043, Train Loss: 6.640, Validation Loss: 6.346\n",
      "Epoch: 1044, Train Loss: 6.782, Validation Loss: 6.345\n",
      "Epoch: 1045, Train Loss: 5.858, Validation Loss: 6.372\n",
      "Epoch: 1046, Train Loss: 6.324, Validation Loss: 6.315\n",
      "Epoch: 1047, Train Loss: 6.313, Validation Loss: 6.299\n",
      "Epoch: 1048, Train Loss: 5.370, Validation Loss: 6.284\n",
      "Epoch: 1049, Train Loss: 6.589, Validation Loss: 6.267\n",
      "Epoch: 1050, Train Loss: 3.777, Validation Loss: 6.282\n",
      "Epoch: 1051, Train Loss: 6.007, Validation Loss: 6.281\n",
      "Epoch: 1052, Train Loss: 7.465, Validation Loss: 6.330\n",
      "Epoch: 1053, Train Loss: 6.869, Validation Loss: 6.333\n",
      "Epoch: 1054, Train Loss: 5.454, Validation Loss: 6.338\n",
      "Epoch: 1055, Train Loss: 8.337, Validation Loss: 6.265\n",
      "Epoch: 1056, Train Loss: 5.376, Validation Loss: 6.273\n",
      "Epoch: 1057, Train Loss: 3.764, Validation Loss: 6.263\n",
      "Epoch: 1058, Train Loss: 8.462, Validation Loss: 6.312\n",
      "Epoch: 1059, Train Loss: 5.438, Validation Loss: 6.260\n",
      "Epoch: 1060, Train Loss: 6.126, Validation Loss: 6.280\n",
      "Epoch: 1061, Train Loss: 6.865, Validation Loss: 6.293\n",
      "Epoch: 1062, Train Loss: 4.934, Validation Loss: 6.290\n",
      "Epoch: 1063, Train Loss: 5.914, Validation Loss: 6.278\n",
      "Epoch: 1064, Train Loss: 6.346, Validation Loss: 6.317\n",
      "Epoch: 1065, Train Loss: 6.165, Validation Loss: 6.334\n",
      "Epoch: 1066, Train Loss: 5.401, Validation Loss: 6.274\n",
      "Epoch: 1067, Train Loss: 5.246, Validation Loss: 6.291\n",
      "Epoch: 1068, Train Loss: 6.498, Validation Loss: 6.267\n",
      "Epoch: 1069, Train Loss: 8.348, Validation Loss: 6.312\n",
      "Epoch: 1070, Train Loss: 4.884, Validation Loss: 6.279\n",
      "Epoch: 1071, Train Loss: 4.977, Validation Loss: 6.261\n",
      "Epoch: 1072, Train Loss: 6.314, Validation Loss: 6.298\n",
      "Epoch: 1073, Train Loss: 6.387, Validation Loss: 6.285\n",
      "Epoch: 1074, Train Loss: 6.641, Validation Loss: 6.285\n",
      "Epoch: 1075, Train Loss: 5.193, Validation Loss: 6.287\n",
      "Epoch: 1076, Train Loss: 6.508, Validation Loss: 6.257\n",
      "Epoch: 1077, Train Loss: 7.902, Validation Loss: 6.275\n",
      "Epoch: 1078, Train Loss: 5.224, Validation Loss: 6.304\n",
      "Epoch: 1079, Train Loss: 6.372, Validation Loss: 6.315\n",
      "Epoch: 1080, Train Loss: 5.394, Validation Loss: 6.301\n",
      "Epoch: 1081, Train Loss: 5.637, Validation Loss: 6.310\n",
      "Epoch: 1082, Train Loss: 6.998, Validation Loss: 6.361\n",
      "Epoch: 1083, Train Loss: 5.654, Validation Loss: 6.326\n",
      "Epoch: 1084, Train Loss: 5.937, Validation Loss: 6.316\n",
      "Epoch: 1085, Train Loss: 5.820, Validation Loss: 6.273\n",
      "Epoch: 1086, Train Loss: 5.246, Validation Loss: 6.287\n",
      "Epoch: 1087, Train Loss: 5.422, Validation Loss: 6.298\n",
      "Epoch: 1088, Train Loss: 4.465, Validation Loss: 6.300\n",
      "Epoch: 1089, Train Loss: 5.898, Validation Loss: 6.290\n",
      "Epoch: 1090, Train Loss: 6.781, Validation Loss: 6.275\n",
      "Epoch: 1091, Train Loss: 5.748, Validation Loss: 6.289\n",
      "Epoch: 1092, Train Loss: 5.861, Validation Loss: 6.322\n",
      "Epoch: 1093, Train Loss: 7.280, Validation Loss: 6.293\n",
      "Epoch: 1094, Train Loss: 6.646, Validation Loss: 6.275\n",
      "Epoch: 1095, Train Loss: 8.890, Validation Loss: 6.323\n",
      "Epoch: 1096, Train Loss: 6.567, Validation Loss: 6.327\n",
      "Epoch: 1097, Train Loss: 5.115, Validation Loss: 6.325\n",
      "Epoch: 1098, Train Loss: 5.423, Validation Loss: 6.317\n",
      "Epoch: 1099, Train Loss: 5.665, Validation Loss: 6.335\n",
      "Epoch: 1100, Train Loss: 5.911, Validation Loss: 6.318\n",
      "Epoch: 1101, Train Loss: 4.257, Validation Loss: 6.334\n",
      "Epoch: 1102, Train Loss: 6.592, Validation Loss: 6.349\n",
      "Epoch: 1103, Train Loss: 5.405, Validation Loss: 6.345\n",
      "Epoch: 1104, Train Loss: 4.798, Validation Loss: 6.315\n",
      "Epoch: 1105, Train Loss: 5.965, Validation Loss: 6.321\n",
      "Epoch: 1106, Train Loss: 5.776, Validation Loss: 6.314\n",
      "Epoch: 1107, Train Loss: 6.882, Validation Loss: 6.317\n",
      "Epoch: 1108, Train Loss: 6.369, Validation Loss: 6.289\n",
      "Epoch: 1109, Train Loss: 5.669, Validation Loss: 6.299\n",
      "Epoch: 1110, Train Loss: 4.866, Validation Loss: 6.280\n",
      "Epoch: 1111, Train Loss: 5.227, Validation Loss: 6.307\n",
      "Epoch: 1112, Train Loss: 8.036, Validation Loss: 6.320\n",
      "Epoch: 1113, Train Loss: 4.781, Validation Loss: 6.304\n",
      "Epoch: 1114, Train Loss: 5.758, Validation Loss: 6.303\n",
      "Epoch: 1115, Train Loss: 7.272, Validation Loss: 6.267\n",
      "Epoch: 1116, Train Loss: 5.457, Validation Loss: 6.259\n",
      "Epoch: 1117, Train Loss: 5.051, Validation Loss: 6.268\n",
      "Epoch: 1118, Train Loss: 4.774, Validation Loss: 6.276\n",
      "Epoch: 1119, Train Loss: 6.120, Validation Loss: 6.289\n",
      "Epoch: 1120, Train Loss: 6.466, Validation Loss: 6.280\n",
      "Epoch: 1121, Train Loss: 5.685, Validation Loss: 6.267\n",
      "Epoch: 1122, Train Loss: 6.672, Validation Loss: 6.286\n",
      "Epoch: 1123, Train Loss: 5.503, Validation Loss: 6.283\n",
      "Epoch: 1124, Train Loss: 4.567, Validation Loss: 6.306\n",
      "Epoch: 1125, Train Loss: 6.132, Validation Loss: 6.290\n",
      "Epoch: 1126, Train Loss: 5.908, Validation Loss: 6.315\n",
      "Epoch: 1127, Train Loss: 5.564, Validation Loss: 6.298\n",
      "Epoch: 1128, Train Loss: 4.635, Validation Loss: 6.377\n",
      "Epoch: 1129, Train Loss: 5.058, Validation Loss: 6.308\n",
      "Epoch: 1130, Train Loss: 5.327, Validation Loss: 6.262\n",
      "Epoch: 1131, Train Loss: 5.862, Validation Loss: 6.255\n",
      "Epoch: 1132, Train Loss: 4.126, Validation Loss: 6.280\n",
      "Epoch: 1133, Train Loss: 4.987, Validation Loss: 6.230\n",
      "Epoch: 1134, Train Loss: 5.235, Validation Loss: 6.251\n",
      "Epoch: 1135, Train Loss: 6.439, Validation Loss: 6.265\n",
      "Epoch: 1136, Train Loss: 5.750, Validation Loss: 6.237\n",
      "Epoch: 1137, Train Loss: 4.261, Validation Loss: 6.230\n",
      "Epoch: 1138, Train Loss: 6.231, Validation Loss: 6.264\n",
      "Epoch: 1139, Train Loss: 4.343, Validation Loss: 6.270\n",
      "Epoch: 1140, Train Loss: 4.945, Validation Loss: 6.226\n",
      "Epoch: 1141, Train Loss: 5.743, Validation Loss: 6.256\n",
      "Epoch: 1142, Train Loss: 4.796, Validation Loss: 6.241\n",
      "Epoch: 1143, Train Loss: 4.903, Validation Loss: 6.282\n",
      "Epoch: 1144, Train Loss: 7.236, Validation Loss: 6.322\n",
      "Epoch: 1145, Train Loss: 5.627, Validation Loss: 6.286\n",
      "Epoch: 1146, Train Loss: 5.150, Validation Loss: 6.299\n",
      "Epoch: 1147, Train Loss: 5.969, Validation Loss: 6.241\n",
      "Epoch: 1148, Train Loss: 7.716, Validation Loss: 6.277\n",
      "Epoch: 1149, Train Loss: 5.450, Validation Loss: 6.300\n",
      "Epoch: 1150, Train Loss: 5.390, Validation Loss: 6.273\n",
      "Epoch: 1151, Train Loss: 5.925, Validation Loss: 6.273\n",
      "Epoch: 1152, Train Loss: 5.312, Validation Loss: 6.245\n",
      "Epoch: 1153, Train Loss: 5.663, Validation Loss: 6.257\n",
      "Epoch: 1154, Train Loss: 5.623, Validation Loss: 6.284\n",
      "Epoch: 1155, Train Loss: 5.869, Validation Loss: 6.282\n",
      "Epoch: 1156, Train Loss: 5.100, Validation Loss: 6.296\n",
      "Epoch: 1157, Train Loss: 5.050, Validation Loss: 6.291\n",
      "Epoch: 1158, Train Loss: 6.463, Validation Loss: 6.298\n",
      "Epoch: 1159, Train Loss: 6.028, Validation Loss: 6.251\n",
      "Epoch: 1160, Train Loss: 7.063, Validation Loss: 6.239\n",
      "Epoch: 1161, Train Loss: 5.604, Validation Loss: 6.232\n",
      "Epoch: 1162, Train Loss: 5.799, Validation Loss: 6.228\n",
      "Epoch: 1163, Train Loss: 6.479, Validation Loss: 6.253\n",
      "Epoch: 1164, Train Loss: 4.455, Validation Loss: 6.219\n",
      "Epoch: 1165, Train Loss: 6.703, Validation Loss: 6.265\n",
      "Epoch: 1166, Train Loss: 4.814, Validation Loss: 6.269\n",
      "Epoch: 1167, Train Loss: 4.121, Validation Loss: 6.290\n",
      "Epoch: 1168, Train Loss: 5.393, Validation Loss: 6.228\n",
      "Epoch: 1169, Train Loss: 5.389, Validation Loss: 6.260\n",
      "Epoch: 1170, Train Loss: 6.017, Validation Loss: 6.292\n",
      "Epoch: 1171, Train Loss: 4.298, Validation Loss: 6.203\n",
      "Epoch: 1172, Train Loss: 4.491, Validation Loss: 6.218\n",
      "Epoch: 1173, Train Loss: 6.891, Validation Loss: 6.259\n",
      "Epoch: 1174, Train Loss: 5.072, Validation Loss: 6.215\n",
      "Epoch: 1175, Train Loss: 4.679, Validation Loss: 6.231\n",
      "Epoch: 1176, Train Loss: 5.055, Validation Loss: 6.216\n",
      "Epoch: 1177, Train Loss: 4.225, Validation Loss: 6.235\n",
      "Epoch: 1178, Train Loss: 5.122, Validation Loss: 6.237\n",
      "Epoch: 1179, Train Loss: 4.896, Validation Loss: 6.258\n",
      "Epoch: 1180, Train Loss: 6.198, Validation Loss: 6.259\n",
      "Epoch: 1181, Train Loss: 4.552, Validation Loss: 6.255\n",
      "Epoch: 1182, Train Loss: 5.339, Validation Loss: 6.245\n",
      "Epoch: 1183, Train Loss: 4.910, Validation Loss: 6.237\n",
      "Epoch: 1184, Train Loss: 5.215, Validation Loss: 6.265\n",
      "Epoch: 1185, Train Loss: 5.778, Validation Loss: 6.278\n",
      "Epoch: 1186, Train Loss: 5.076, Validation Loss: 6.244\n",
      "Epoch: 1187, Train Loss: 6.463, Validation Loss: 6.238\n",
      "Epoch: 1188, Train Loss: 4.600, Validation Loss: 6.250\n",
      "Epoch: 1189, Train Loss: 7.200, Validation Loss: 6.247\n",
      "Epoch: 1190, Train Loss: 5.870, Validation Loss: 6.231\n",
      "Epoch: 1191, Train Loss: 7.324, Validation Loss: 6.201\n",
      "Epoch: 1192, Train Loss: 4.168, Validation Loss: 6.215\n",
      "Epoch: 1193, Train Loss: 4.498, Validation Loss: 6.200\n",
      "Epoch: 1194, Train Loss: 5.013, Validation Loss: 6.199\n",
      "Epoch: 1195, Train Loss: 5.434, Validation Loss: 6.208\n",
      "Epoch: 1196, Train Loss: 4.601, Validation Loss: 6.199\n",
      "Epoch: 1197, Train Loss: 4.377, Validation Loss: 6.217\n",
      "Epoch: 1198, Train Loss: 5.516, Validation Loss: 6.205\n",
      "Epoch: 1199, Train Loss: 6.213, Validation Loss: 6.197\n",
      "Epoch: 1200, Train Loss: 5.989, Validation Loss: 6.161\n",
      "Epoch: 1201, Train Loss: 4.753, Validation Loss: 6.132\n",
      "Epoch: 1202, Train Loss: 4.631, Validation Loss: 6.141\n",
      "Epoch: 1203, Train Loss: 6.017, Validation Loss: 6.157\n",
      "Epoch: 1204, Train Loss: 4.774, Validation Loss: 6.150\n",
      "Epoch: 1205, Train Loss: 4.744, Validation Loss: 6.166\n",
      "Epoch: 1206, Train Loss: 5.069, Validation Loss: 6.194\n",
      "Epoch: 1207, Train Loss: 5.684, Validation Loss: 6.156\n",
      "Epoch: 1208, Train Loss: 5.249, Validation Loss: 6.174\n",
      "Epoch: 1209, Train Loss: 5.232, Validation Loss: 6.178\n",
      "Epoch: 1210, Train Loss: 5.634, Validation Loss: 6.207\n",
      "Epoch: 1211, Train Loss: 4.864, Validation Loss: 6.210\n",
      "Epoch: 1212, Train Loss: 4.464, Validation Loss: 6.236\n",
      "Epoch: 1213, Train Loss: 5.575, Validation Loss: 6.224\n",
      "Epoch: 1214, Train Loss: 5.110, Validation Loss: 6.240\n",
      "Epoch: 1215, Train Loss: 4.518, Validation Loss: 6.230\n",
      "Epoch: 1216, Train Loss: 5.204, Validation Loss: 6.171\n",
      "Epoch: 1217, Train Loss: 4.511, Validation Loss: 6.168\n",
      "Epoch: 1218, Train Loss: 4.483, Validation Loss: 6.190\n",
      "Epoch: 1219, Train Loss: 7.412, Validation Loss: 6.197\n",
      "Epoch: 1220, Train Loss: 5.707, Validation Loss: 6.167\n",
      "Epoch: 1221, Train Loss: 5.351, Validation Loss: 6.180\n",
      "Epoch: 1222, Train Loss: 5.317, Validation Loss: 6.188\n",
      "Epoch: 1223, Train Loss: 5.253, Validation Loss: 6.213\n",
      "Epoch: 1224, Train Loss: 4.444, Validation Loss: 6.203\n",
      "Epoch: 1225, Train Loss: 5.305, Validation Loss: 6.210\n",
      "Epoch: 1226, Train Loss: 4.562, Validation Loss: 6.200\n",
      "Epoch: 1227, Train Loss: 5.467, Validation Loss: 6.199\n",
      "Epoch: 1228, Train Loss: 5.567, Validation Loss: 6.201\n",
      "Epoch: 1229, Train Loss: 6.003, Validation Loss: 6.216\n",
      "Epoch: 1230, Train Loss: 5.039, Validation Loss: 6.210\n",
      "Epoch: 1231, Train Loss: 7.141, Validation Loss: 6.199\n",
      "Epoch: 1232, Train Loss: 5.120, Validation Loss: 6.199\n",
      "Epoch: 1233, Train Loss: 4.471, Validation Loss: 6.193\n",
      "Epoch: 1234, Train Loss: 4.548, Validation Loss: 6.194\n",
      "Epoch: 1235, Train Loss: 5.723, Validation Loss: 6.200\n",
      "Epoch: 1236, Train Loss: 4.576, Validation Loss: 6.202\n",
      "Epoch: 1237, Train Loss: 3.860, Validation Loss: 6.182\n",
      "Epoch: 1238, Train Loss: 4.695, Validation Loss: 6.215\n",
      "Epoch: 1239, Train Loss: 4.954, Validation Loss: 6.222\n",
      "Epoch: 1240, Train Loss: 5.082, Validation Loss: 6.216\n",
      "Epoch: 1241, Train Loss: 5.202, Validation Loss: 6.217\n",
      "Epoch: 1242, Train Loss: 6.174, Validation Loss: 6.221\n",
      "Epoch: 1243, Train Loss: 4.553, Validation Loss: 6.155\n",
      "Epoch: 1244, Train Loss: 4.665, Validation Loss: 6.127\n",
      "Epoch: 1245, Train Loss: 4.827, Validation Loss: 6.155\n",
      "Epoch: 1246, Train Loss: 5.124, Validation Loss: 6.221\n",
      "Epoch: 1247, Train Loss: 6.481, Validation Loss: 6.255\n",
      "Epoch: 1248, Train Loss: 5.240, Validation Loss: 6.225\n",
      "Epoch: 1249, Train Loss: 4.669, Validation Loss: 6.200\n",
      "Epoch: 1250, Train Loss: 4.111, Validation Loss: 6.216\n",
      "Epoch: 1251, Train Loss: 4.523, Validation Loss: 6.190\n",
      "Epoch: 1252, Train Loss: 5.533, Validation Loss: 6.198\n",
      "Epoch: 1253, Train Loss: 4.935, Validation Loss: 6.210\n",
      "Epoch: 1254, Train Loss: 4.410, Validation Loss: 6.204\n",
      "Epoch: 1255, Train Loss: 4.332, Validation Loss: 6.207\n",
      "Epoch: 1256, Train Loss: 6.596, Validation Loss: 6.197\n",
      "Epoch: 1257, Train Loss: 3.835, Validation Loss: 6.167\n",
      "Epoch: 1258, Train Loss: 5.241, Validation Loss: 6.197\n",
      "Epoch: 1259, Train Loss: 5.032, Validation Loss: 6.192\n",
      "Epoch: 1260, Train Loss: 4.247, Validation Loss: 6.198\n",
      "Epoch: 1261, Train Loss: 5.088, Validation Loss: 6.199\n",
      "Epoch: 1262, Train Loss: 5.190, Validation Loss: 6.211\n",
      "Epoch: 1263, Train Loss: 5.192, Validation Loss: 6.192\n",
      "Epoch: 1264, Train Loss: 4.865, Validation Loss: 6.185\n",
      "Epoch: 1265, Train Loss: 5.113, Validation Loss: 6.192\n",
      "Epoch: 1266, Train Loss: 5.729, Validation Loss: 6.299\n",
      "Epoch: 1267, Train Loss: 4.858, Validation Loss: 6.255\n",
      "Epoch: 1268, Train Loss: 5.185, Validation Loss: 6.221\n",
      "Epoch: 1269, Train Loss: 4.930, Validation Loss: 6.202\n",
      "Epoch: 1270, Train Loss: 5.381, Validation Loss: 6.262\n",
      "Epoch: 1271, Train Loss: 6.140, Validation Loss: 6.224\n",
      "Epoch: 1272, Train Loss: 4.419, Validation Loss: 6.206\n",
      "Epoch: 1273, Train Loss: 3.995, Validation Loss: 6.218\n",
      "Epoch: 1274, Train Loss: 4.946, Validation Loss: 6.261\n",
      "Epoch: 1275, Train Loss: 5.288, Validation Loss: 6.211\n",
      "Epoch: 1276, Train Loss: 5.716, Validation Loss: 6.215\n",
      "Epoch: 1277, Train Loss: 4.834, Validation Loss: 6.207\n",
      "Epoch: 1278, Train Loss: 4.412, Validation Loss: 6.177\n",
      "Epoch: 1279, Train Loss: 5.025, Validation Loss: 6.183\n",
      "Epoch: 1280, Train Loss: 6.203, Validation Loss: 6.236\n",
      "Epoch: 1281, Train Loss: 4.540, Validation Loss: 6.161\n",
      "Epoch: 1282, Train Loss: 4.469, Validation Loss: 6.148\n",
      "Epoch: 1283, Train Loss: 4.766, Validation Loss: 6.188\n",
      "Epoch: 1284, Train Loss: 4.360, Validation Loss: 6.217\n",
      "Epoch: 1285, Train Loss: 4.899, Validation Loss: 6.198\n",
      "Epoch: 1286, Train Loss: 5.878, Validation Loss: 6.156\n",
      "Epoch: 1287, Train Loss: 4.292, Validation Loss: 6.160\n",
      "Epoch: 1288, Train Loss: 5.888, Validation Loss: 6.131\n",
      "Epoch: 1289, Train Loss: 6.296, Validation Loss: 6.134\n",
      "Epoch: 1290, Train Loss: 5.468, Validation Loss: 6.147\n",
      "Epoch: 1291, Train Loss: 5.382, Validation Loss: 6.113\n",
      "Epoch: 1292, Train Loss: 4.652, Validation Loss: 6.115\n",
      "Epoch: 1293, Train Loss: 4.616, Validation Loss: 6.159\n",
      "Epoch: 1294, Train Loss: 4.472, Validation Loss: 6.148\n",
      "Epoch: 1295, Train Loss: 4.961, Validation Loss: 6.183\n",
      "Epoch: 1296, Train Loss: 4.755, Validation Loss: 6.173\n",
      "Epoch: 1297, Train Loss: 6.565, Validation Loss: 6.167\n",
      "Epoch: 1298, Train Loss: 6.468, Validation Loss: 6.165\n",
      "Epoch: 1299, Train Loss: 6.606, Validation Loss: 6.152\n",
      "Epoch: 1300, Train Loss: 5.376, Validation Loss: 6.142\n",
      "Epoch: 1301, Train Loss: 6.212, Validation Loss: 6.144\n",
      "Epoch: 1302, Train Loss: 5.917, Validation Loss: 6.166\n",
      "Epoch: 1303, Train Loss: 5.570, Validation Loss: 6.167\n",
      "Epoch: 1304, Train Loss: 4.471, Validation Loss: 6.184\n",
      "Epoch: 1305, Train Loss: 5.335, Validation Loss: 6.157\n",
      "Epoch: 1306, Train Loss: 4.737, Validation Loss: 6.149\n",
      "Epoch: 1307, Train Loss: 6.024, Validation Loss: 6.162\n",
      "Epoch: 1308, Train Loss: 3.858, Validation Loss: 6.168\n",
      "Epoch: 1309, Train Loss: 4.045, Validation Loss: 6.158\n",
      "Epoch: 1310, Train Loss: 6.349, Validation Loss: 6.174\n",
      "Epoch: 1311, Train Loss: 6.077, Validation Loss: 6.167\n",
      "Epoch: 1312, Train Loss: 4.640, Validation Loss: 6.158\n",
      "Epoch: 1313, Train Loss: 6.267, Validation Loss: 6.168\n",
      "Epoch: 1314, Train Loss: 3.862, Validation Loss: 6.167\n",
      "Epoch: 1315, Train Loss: 3.584, Validation Loss: 6.177\n",
      "Epoch: 1316, Train Loss: 5.271, Validation Loss: 6.152\n",
      "Epoch: 1317, Train Loss: 4.395, Validation Loss: 6.159\n",
      "Epoch: 1318, Train Loss: 4.118, Validation Loss: 6.175\n",
      "Epoch: 1319, Train Loss: 5.016, Validation Loss: 6.193\n",
      "Epoch: 1320, Train Loss: 6.408, Validation Loss: 6.194\n",
      "Epoch: 1321, Train Loss: 5.668, Validation Loss: 6.204\n",
      "Epoch: 1322, Train Loss: 5.228, Validation Loss: 6.214\n",
      "Epoch: 1323, Train Loss: 5.030, Validation Loss: 6.217\n",
      "Epoch: 1324, Train Loss: 4.455, Validation Loss: 6.153\n",
      "Epoch: 1325, Train Loss: 5.164, Validation Loss: 6.150\n",
      "Epoch: 1326, Train Loss: 5.390, Validation Loss: 6.148\n",
      "Epoch: 1327, Train Loss: 5.538, Validation Loss: 6.139\n",
      "Epoch: 1328, Train Loss: 4.563, Validation Loss: 6.144\n",
      "Epoch: 1329, Train Loss: 5.536, Validation Loss: 6.169\n",
      "Epoch: 1330, Train Loss: 5.532, Validation Loss: 6.172\n",
      "Epoch: 1331, Train Loss: 4.588, Validation Loss: 6.191\n",
      "Epoch: 1332, Train Loss: 4.366, Validation Loss: 6.155\n",
      "Epoch: 1333, Train Loss: 7.166, Validation Loss: 6.139\n",
      "Epoch: 1334, Train Loss: 4.491, Validation Loss: 6.131\n",
      "Epoch: 1335, Train Loss: 4.779, Validation Loss: 6.135\n",
      "Epoch: 1336, Train Loss: 4.976, Validation Loss: 6.142\n",
      "Epoch: 1337, Train Loss: 4.388, Validation Loss: 6.159\n",
      "Epoch: 1338, Train Loss: 4.649, Validation Loss: 6.127\n",
      "Epoch: 1339, Train Loss: 4.073, Validation Loss: 6.142\n",
      "Epoch: 1340, Train Loss: 5.075, Validation Loss: 6.157\n",
      "Epoch: 1341, Train Loss: 6.055, Validation Loss: 6.184\n",
      "Epoch: 1342, Train Loss: 4.143, Validation Loss: 6.145\n",
      "Epoch: 1343, Train Loss: 4.717, Validation Loss: 6.142\n",
      "Epoch: 1344, Train Loss: 4.786, Validation Loss: 6.124\n",
      "Epoch: 1345, Train Loss: 4.155, Validation Loss: 6.137\n",
      "Epoch: 1346, Train Loss: 4.605, Validation Loss: 6.125\n",
      "Epoch: 1347, Train Loss: 5.047, Validation Loss: 6.125\n",
      "Epoch: 1348, Train Loss: 3.819, Validation Loss: 6.157\n",
      "Epoch: 1349, Train Loss: 4.290, Validation Loss: 6.152\n",
      "Epoch: 1350, Train Loss: 4.502, Validation Loss: 6.163\n",
      "Epoch: 1351, Train Loss: 3.706, Validation Loss: 6.149\n",
      "Epoch: 1352, Train Loss: 6.924, Validation Loss: 6.125\n",
      "Epoch: 1353, Train Loss: 4.184, Validation Loss: 6.145\n",
      "Epoch: 1354, Train Loss: 4.985, Validation Loss: 6.164\n",
      "Epoch: 1355, Train Loss: 6.378, Validation Loss: 6.190\n",
      "Epoch: 1356, Train Loss: 3.653, Validation Loss: 6.140\n",
      "Epoch: 1357, Train Loss: 5.343, Validation Loss: 6.115\n",
      "Epoch: 1358, Train Loss: 6.234, Validation Loss: 6.134\n",
      "Epoch: 1359, Train Loss: 3.544, Validation Loss: 6.097\n",
      "Epoch: 1360, Train Loss: 4.692, Validation Loss: 6.105\n",
      "Epoch: 1361, Train Loss: 6.009, Validation Loss: 6.127\n",
      "Epoch: 1362, Train Loss: 4.306, Validation Loss: 6.114\n",
      "Epoch: 1363, Train Loss: 3.678, Validation Loss: 6.123\n",
      "Epoch: 1364, Train Loss: 5.535, Validation Loss: 6.113\n",
      "Epoch: 1365, Train Loss: 5.368, Validation Loss: 6.125\n",
      "Epoch: 1366, Train Loss: 5.157, Validation Loss: 6.110\n",
      "Epoch: 1367, Train Loss: 4.693, Validation Loss: 6.121\n",
      "Epoch: 1368, Train Loss: 5.677, Validation Loss: 6.144\n",
      "Epoch: 1369, Train Loss: 3.536, Validation Loss: 6.119\n",
      "Epoch: 1370, Train Loss: 4.631, Validation Loss: 6.135\n",
      "Epoch: 1371, Train Loss: 4.385, Validation Loss: 6.184\n",
      "Epoch: 1372, Train Loss: 4.441, Validation Loss: 6.214\n",
      "Epoch: 1373, Train Loss: 4.740, Validation Loss: 6.232\n",
      "Epoch: 1374, Train Loss: 4.944, Validation Loss: 6.193\n",
      "Epoch: 1375, Train Loss: 5.644, Validation Loss: 6.212\n",
      "Epoch: 1376, Train Loss: 4.556, Validation Loss: 6.166\n",
      "Epoch: 1377, Train Loss: 5.244, Validation Loss: 6.135\n",
      "Epoch: 1378, Train Loss: 5.057, Validation Loss: 6.161\n",
      "Epoch: 1379, Train Loss: 5.283, Validation Loss: 6.132\n",
      "Epoch: 1380, Train Loss: 4.221, Validation Loss: 6.119\n",
      "Epoch: 1381, Train Loss: 4.334, Validation Loss: 6.131\n",
      "Epoch: 1382, Train Loss: 5.053, Validation Loss: 6.106\n",
      "Epoch: 1383, Train Loss: 4.504, Validation Loss: 6.153\n",
      "Epoch: 1384, Train Loss: 4.603, Validation Loss: 6.138\n",
      "Epoch: 1385, Train Loss: 4.510, Validation Loss: 6.156\n",
      "Epoch: 1386, Train Loss: 4.782, Validation Loss: 6.153\n",
      "Epoch: 1387, Train Loss: 3.861, Validation Loss: 6.136\n",
      "Epoch: 1388, Train Loss: 6.144, Validation Loss: 6.138\n",
      "Epoch: 1389, Train Loss: 4.598, Validation Loss: 6.136\n",
      "Epoch: 1390, Train Loss: 4.196, Validation Loss: 6.114\n",
      "Epoch: 1391, Train Loss: 5.325, Validation Loss: 6.143\n",
      "Epoch: 1392, Train Loss: 4.617, Validation Loss: 6.116\n",
      "Epoch: 1393, Train Loss: 3.883, Validation Loss: 6.123\n",
      "Epoch: 1394, Train Loss: 4.677, Validation Loss: 6.124\n",
      "Epoch: 1395, Train Loss: 5.097, Validation Loss: 6.141\n",
      "Epoch: 1396, Train Loss: 6.402, Validation Loss: 6.075\n",
      "Epoch: 1397, Train Loss: 4.699, Validation Loss: 6.056\n",
      "Epoch: 1398, Train Loss: 5.052, Validation Loss: 6.075\n",
      "Epoch: 1399, Train Loss: 4.783, Validation Loss: 6.081\n",
      "Epoch: 1400, Train Loss: 5.001, Validation Loss: 6.140\n",
      "Epoch: 1401, Train Loss: 4.606, Validation Loss: 6.169\n",
      "Epoch: 1402, Train Loss: 4.930, Validation Loss: 6.181\n",
      "Epoch: 1403, Train Loss: 5.180, Validation Loss: 6.233\n",
      "Epoch: 1404, Train Loss: 4.876, Validation Loss: 6.244\n",
      "Epoch: 1405, Train Loss: 4.063, Validation Loss: 6.179\n",
      "Epoch: 1406, Train Loss: 4.889, Validation Loss: 6.144\n",
      "Epoch: 1407, Train Loss: 5.004, Validation Loss: 6.164\n",
      "Epoch: 1408, Train Loss: 4.592, Validation Loss: 6.153\n",
      "Epoch: 1409, Train Loss: 5.043, Validation Loss: 6.153\n",
      "Epoch: 1410, Train Loss: 4.792, Validation Loss: 6.130\n",
      "Epoch: 1411, Train Loss: 5.595, Validation Loss: 6.129\n",
      "Epoch: 1412, Train Loss: 4.969, Validation Loss: 6.090\n",
      "Epoch: 1413, Train Loss: 3.791, Validation Loss: 6.097\n",
      "Epoch: 1414, Train Loss: 4.749, Validation Loss: 6.134\n",
      "Epoch: 1415, Train Loss: 4.322, Validation Loss: 6.129\n",
      "Epoch: 1416, Train Loss: 5.411, Validation Loss: 6.130\n",
      "Epoch: 1417, Train Loss: 3.570, Validation Loss: 6.110\n",
      "Epoch: 1418, Train Loss: 4.942, Validation Loss: 6.150\n",
      "Epoch: 1419, Train Loss: 5.195, Validation Loss: 6.156\n",
      "Epoch: 1420, Train Loss: 5.152, Validation Loss: 6.175\n",
      "Epoch: 1421, Train Loss: 4.020, Validation Loss: 6.167\n",
      "Epoch: 1422, Train Loss: 4.896, Validation Loss: 6.182\n",
      "Epoch: 1423, Train Loss: 3.775, Validation Loss: 6.201\n",
      "Epoch: 1424, Train Loss: 5.120, Validation Loss: 6.170\n",
      "Epoch: 1425, Train Loss: 4.064, Validation Loss: 6.203\n",
      "Epoch: 1426, Train Loss: 4.757, Validation Loss: 6.183\n",
      "Epoch: 1427, Train Loss: 5.580, Validation Loss: 6.172\n",
      "Epoch: 1428, Train Loss: 4.120, Validation Loss: 6.116\n",
      "Epoch: 1429, Train Loss: 4.408, Validation Loss: 6.122\n",
      "Epoch: 1430, Train Loss: 5.975, Validation Loss: 6.143\n",
      "Epoch: 1431, Train Loss: 4.605, Validation Loss: 6.157\n",
      "Epoch: 1432, Train Loss: 4.286, Validation Loss: 6.126\n",
      "Epoch: 1433, Train Loss: 4.821, Validation Loss: 6.136\n",
      "Epoch: 1434, Train Loss: 4.578, Validation Loss: 6.185\n",
      "Epoch: 1435, Train Loss: 3.678, Validation Loss: 6.178\n",
      "Epoch: 1436, Train Loss: 5.100, Validation Loss: 6.176\n",
      "Epoch: 1437, Train Loss: 4.489, Validation Loss: 6.134\n",
      "Epoch: 1438, Train Loss: 5.636, Validation Loss: 6.191\n",
      "Epoch: 1439, Train Loss: 5.280, Validation Loss: 6.180\n",
      "Epoch: 1440, Train Loss: 4.247, Validation Loss: 6.163\n",
      "Epoch: 1441, Train Loss: 5.164, Validation Loss: 6.112\n",
      "Epoch: 1442, Train Loss: 4.834, Validation Loss: 6.097\n",
      "Epoch: 1443, Train Loss: 4.877, Validation Loss: 6.114\n",
      "Epoch: 1444, Train Loss: 4.671, Validation Loss: 6.112\n",
      "Epoch: 1445, Train Loss: 4.831, Validation Loss: 6.150\n",
      "Epoch: 1446, Train Loss: 3.576, Validation Loss: 6.131\n",
      "Epoch: 1447, Train Loss: 4.545, Validation Loss: 6.156\n",
      "Epoch: 1448, Train Loss: 5.055, Validation Loss: 6.124\n",
      "Epoch: 1449, Train Loss: 5.282, Validation Loss: 6.130\n",
      "Epoch: 1450, Train Loss: 4.115, Validation Loss: 6.146\n",
      "Epoch: 1451, Train Loss: 4.684, Validation Loss: 6.134\n",
      "Epoch: 1452, Train Loss: 4.611, Validation Loss: 6.147\n",
      "Epoch: 1453, Train Loss: 4.581, Validation Loss: 6.117\n",
      "Epoch: 1454, Train Loss: 5.621, Validation Loss: 6.172\n",
      "Epoch: 1455, Train Loss: 3.784, Validation Loss: 6.169\n",
      "Epoch: 1456, Train Loss: 4.037, Validation Loss: 6.170\n",
      "Epoch: 1457, Train Loss: 3.660, Validation Loss: 6.204\n",
      "Epoch: 1458, Train Loss: 7.539, Validation Loss: 6.204\n",
      "Epoch: 1459, Train Loss: 4.133, Validation Loss: 6.165\n",
      "Epoch: 1460, Train Loss: 5.589, Validation Loss: 6.157\n",
      "Epoch: 1461, Train Loss: 4.847, Validation Loss: 6.153\n",
      "Epoch: 1462, Train Loss: 4.358, Validation Loss: 6.129\n",
      "Epoch: 1463, Train Loss: 4.423, Validation Loss: 6.174\n",
      "Epoch: 1464, Train Loss: 3.824, Validation Loss: 6.186\n",
      "Epoch: 1465, Train Loss: 4.820, Validation Loss: 6.182\n",
      "Epoch: 1466, Train Loss: 4.607, Validation Loss: 6.204\n",
      "Epoch: 1467, Train Loss: 3.556, Validation Loss: 6.214\n",
      "Epoch: 1468, Train Loss: 4.636, Validation Loss: 6.216\n",
      "Epoch: 1469, Train Loss: 4.347, Validation Loss: 6.223\n",
      "Epoch: 1470, Train Loss: 3.723, Validation Loss: 6.247\n",
      "Epoch: 1471, Train Loss: 4.231, Validation Loss: 6.257\n",
      "Epoch: 1472, Train Loss: 4.215, Validation Loss: 6.184\n",
      "Epoch: 1473, Train Loss: 3.762, Validation Loss: 6.189\n",
      "Epoch: 1474, Train Loss: 4.277, Validation Loss: 6.201\n",
      "Epoch: 1475, Train Loss: 4.292, Validation Loss: 6.158\n",
      "Epoch: 1476, Train Loss: 4.798, Validation Loss: 6.143\n",
      "Epoch: 1477, Train Loss: 3.870, Validation Loss: 6.171\n",
      "Epoch: 1478, Train Loss: 3.849, Validation Loss: 6.138\n",
      "Epoch: 1479, Train Loss: 4.942, Validation Loss: 6.139\n",
      "Epoch: 1480, Train Loss: 4.923, Validation Loss: 6.146\n",
      "Epoch: 1481, Train Loss: 3.774, Validation Loss: 6.146\n",
      "Epoch: 1482, Train Loss: 4.246, Validation Loss: 6.178\n",
      "Epoch: 1483, Train Loss: 5.152, Validation Loss: 6.174\n",
      "Epoch: 1484, Train Loss: 3.992, Validation Loss: 6.213\n",
      "Epoch: 1485, Train Loss: 3.934, Validation Loss: 6.165\n",
      "Epoch: 1486, Train Loss: 3.995, Validation Loss: 6.161\n",
      "Epoch: 1487, Train Loss: 4.069, Validation Loss: 6.147\n",
      "Epoch: 1488, Train Loss: 5.105, Validation Loss: 6.140\n",
      "Epoch: 1489, Train Loss: 4.502, Validation Loss: 6.162\n",
      "Epoch: 1490, Train Loss: 4.077, Validation Loss: 6.112\n",
      "Epoch: 1491, Train Loss: 6.107, Validation Loss: 6.098\n",
      "Epoch: 1492, Train Loss: 3.536, Validation Loss: 6.130\n",
      "Epoch: 1493, Train Loss: 4.268, Validation Loss: 6.097\n",
      "Epoch: 1494, Train Loss: 5.777, Validation Loss: 6.145\n",
      "Epoch: 1495, Train Loss: 4.111, Validation Loss: 6.102\n",
      "Epoch: 1496, Train Loss: 4.247, Validation Loss: 6.085\n",
      "Epoch: 1497, Train Loss: 3.994, Validation Loss: 6.093\n",
      "Epoch: 1498, Train Loss: 3.986, Validation Loss: 6.117\n",
      "Epoch: 1499, Train Loss: 3.286, Validation Loss: 6.084\n",
      "Epoch: 1500, Train Loss: 4.003, Validation Loss: 6.082\n",
      "Epoch: 1501, Train Loss: 5.895, Validation Loss: 6.096\n",
      "Epoch: 1502, Train Loss: 4.420, Validation Loss: 6.124\n",
      "Epoch: 1503, Train Loss: 3.610, Validation Loss: 6.122\n",
      "Epoch: 1504, Train Loss: 4.174, Validation Loss: 6.121\n",
      "Epoch: 1505, Train Loss: 5.033, Validation Loss: 6.129\n",
      "Epoch: 1506, Train Loss: 3.931, Validation Loss: 6.153\n",
      "Epoch: 1507, Train Loss: 4.522, Validation Loss: 6.165\n",
      "Epoch: 1508, Train Loss: 3.884, Validation Loss: 6.191\n",
      "Epoch: 1509, Train Loss: 4.466, Validation Loss: 6.171\n",
      "Epoch: 1510, Train Loss: 5.061, Validation Loss: 6.162\n",
      "Epoch: 1511, Train Loss: 4.566, Validation Loss: 6.200\n",
      "Epoch: 1512, Train Loss: 5.890, Validation Loss: 6.166\n",
      "Epoch: 1513, Train Loss: 5.112, Validation Loss: 6.145\n",
      "Epoch: 1514, Train Loss: 4.743, Validation Loss: 6.132\n",
      "Epoch: 1515, Train Loss: 3.739, Validation Loss: 6.122\n",
      "Epoch: 1516, Train Loss: 4.195, Validation Loss: 6.118\n",
      "Epoch: 1517, Train Loss: 3.568, Validation Loss: 6.076\n",
      "Epoch: 1518, Train Loss: 4.156, Validation Loss: 6.092\n",
      "Epoch: 1519, Train Loss: 4.188, Validation Loss: 6.085\n",
      "Epoch: 1520, Train Loss: 4.841, Validation Loss: 6.129\n",
      "Epoch: 1521, Train Loss: 4.468, Validation Loss: 6.127\n",
      "Epoch: 1522, Train Loss: 3.466, Validation Loss: 6.115\n",
      "Epoch: 1523, Train Loss: 4.882, Validation Loss: 6.084\n",
      "Epoch: 1524, Train Loss: 4.418, Validation Loss: 6.103\n",
      "Epoch: 1525, Train Loss: 5.172, Validation Loss: 6.093\n",
      "Epoch: 1526, Train Loss: 4.117, Validation Loss: 6.115\n",
      "Epoch: 1527, Train Loss: 3.529, Validation Loss: 6.110\n",
      "Epoch: 1528, Train Loss: 3.530, Validation Loss: 6.096\n",
      "Epoch: 1529, Train Loss: 5.450, Validation Loss: 6.100\n",
      "Epoch: 1530, Train Loss: 3.369, Validation Loss: 6.084\n",
      "Epoch: 1531, Train Loss: 4.365, Validation Loss: 6.095\n",
      "Epoch: 1532, Train Loss: 4.558, Validation Loss: 6.073\n",
      "Epoch: 1533, Train Loss: 4.349, Validation Loss: 6.103\n",
      "Epoch: 1534, Train Loss: 3.900, Validation Loss: 6.117\n",
      "Epoch: 1535, Train Loss: 5.308, Validation Loss: 6.103\n",
      "Epoch: 1536, Train Loss: 3.179, Validation Loss: 6.073\n",
      "Epoch: 1537, Train Loss: 3.528, Validation Loss: 6.058\n",
      "Epoch: 1538, Train Loss: 4.136, Validation Loss: 6.076\n",
      "Epoch: 1539, Train Loss: 3.849, Validation Loss: 6.098\n",
      "Epoch: 1540, Train Loss: 4.280, Validation Loss: 6.118\n",
      "Epoch: 1541, Train Loss: 4.620, Validation Loss: 6.134\n",
      "Epoch: 1542, Train Loss: 4.120, Validation Loss: 6.120\n",
      "Epoch: 1543, Train Loss: 4.069, Validation Loss: 6.147\n",
      "Epoch: 1544, Train Loss: 5.212, Validation Loss: 6.135\n",
      "Epoch: 1545, Train Loss: 4.782, Validation Loss: 6.071\n",
      "Epoch: 1546, Train Loss: 4.215, Validation Loss: 6.087\n",
      "Epoch: 1547, Train Loss: 4.503, Validation Loss: 6.110\n",
      "Epoch: 1548, Train Loss: 3.754, Validation Loss: 6.137\n",
      "Epoch: 1549, Train Loss: 3.977, Validation Loss: 6.139\n",
      "Epoch: 1550, Train Loss: 5.365, Validation Loss: 6.128\n",
      "Epoch: 1551, Train Loss: 5.255, Validation Loss: 6.091\n",
      "Epoch: 1552, Train Loss: 4.414, Validation Loss: 6.063\n",
      "Epoch: 1553, Train Loss: 4.675, Validation Loss: 6.062\n",
      "Epoch: 1554, Train Loss: 4.194, Validation Loss: 6.059\n",
      "Epoch: 1555, Train Loss: 4.136, Validation Loss: 6.059\n",
      "Epoch: 1556, Train Loss: 5.102, Validation Loss: 6.063\n",
      "Epoch: 1557, Train Loss: 4.185, Validation Loss: 6.080\n",
      "Epoch: 1558, Train Loss: 3.306, Validation Loss: 6.111\n",
      "Epoch: 1559, Train Loss: 4.988, Validation Loss: 6.123\n",
      "Epoch: 1560, Train Loss: 4.528, Validation Loss: 6.094\n",
      "Epoch: 1561, Train Loss: 4.670, Validation Loss: 6.123\n",
      "Epoch: 1562, Train Loss: 3.605, Validation Loss: 6.128\n",
      "Epoch: 1563, Train Loss: 3.977, Validation Loss: 6.123\n",
      "Epoch: 1564, Train Loss: 4.927, Validation Loss: 6.112\n",
      "Epoch: 1565, Train Loss: 3.482, Validation Loss: 6.078\n",
      "Epoch: 1566, Train Loss: 4.411, Validation Loss: 6.093\n",
      "Epoch: 1567, Train Loss: 4.732, Validation Loss: 6.061\n",
      "Epoch: 1568, Train Loss: 6.160, Validation Loss: 6.071\n",
      "Epoch: 1569, Train Loss: 5.185, Validation Loss: 6.069\n",
      "Epoch: 1570, Train Loss: 4.001, Validation Loss: 6.077\n",
      "Epoch: 1571, Train Loss: 4.582, Validation Loss: 6.087\n",
      "Epoch: 1572, Train Loss: 5.103, Validation Loss: 6.119\n",
      "Epoch: 1573, Train Loss: 4.778, Validation Loss: 6.158\n",
      "Epoch: 1574, Train Loss: 3.655, Validation Loss: 6.158\n",
      "Epoch: 1575, Train Loss: 5.827, Validation Loss: 6.146\n",
      "Epoch: 1576, Train Loss: 5.146, Validation Loss: 6.143\n",
      "Epoch: 1577, Train Loss: 4.306, Validation Loss: 6.168\n",
      "Epoch: 1578, Train Loss: 4.190, Validation Loss: 6.159\n",
      "Epoch: 1579, Train Loss: 4.802, Validation Loss: 6.198\n",
      "Epoch: 1580, Train Loss: 4.099, Validation Loss: 6.148\n",
      "Epoch: 1581, Train Loss: 5.152, Validation Loss: 6.167\n",
      "Epoch: 1582, Train Loss: 3.579, Validation Loss: 6.135\n",
      "Epoch: 1583, Train Loss: 5.367, Validation Loss: 6.127\n",
      "Epoch: 1584, Train Loss: 5.992, Validation Loss: 6.109\n",
      "Epoch: 1585, Train Loss: 3.711, Validation Loss: 6.106\n",
      "Epoch: 1586, Train Loss: 5.701, Validation Loss: 6.107\n",
      "Epoch: 1587, Train Loss: 4.499, Validation Loss: 6.129\n",
      "Epoch: 1588, Train Loss: 4.325, Validation Loss: 6.124\n",
      "Epoch: 1589, Train Loss: 3.672, Validation Loss: 6.134\n",
      "Epoch: 1590, Train Loss: 3.875, Validation Loss: 6.146\n",
      "Epoch: 1591, Train Loss: 4.871, Validation Loss: 6.176\n",
      "Epoch: 1592, Train Loss: 5.209, Validation Loss: 6.154\n",
      "Epoch: 1593, Train Loss: 3.975, Validation Loss: 6.141\n",
      "Epoch: 1594, Train Loss: 4.080, Validation Loss: 6.105\n",
      "Epoch: 1595, Train Loss: 4.975, Validation Loss: 6.111\n",
      "Epoch: 1596, Train Loss: 4.543, Validation Loss: 6.125\n",
      "Epoch: 1597, Train Loss: 3.638, Validation Loss: 6.078\n",
      "Epoch: 1598, Train Loss: 3.990, Validation Loss: 6.081\n",
      "Epoch: 1599, Train Loss: 3.337, Validation Loss: 6.095\n",
      "Epoch: 1600, Train Loss: 3.797, Validation Loss: 6.142\n",
      "Epoch: 1601, Train Loss: 4.804, Validation Loss: 6.092\n",
      "Epoch: 1602, Train Loss: 3.433, Validation Loss: 6.131\n",
      "Epoch: 1603, Train Loss: 4.329, Validation Loss: 6.122\n",
      "Epoch: 1604, Train Loss: 3.800, Validation Loss: 6.096\n",
      "Epoch: 1605, Train Loss: 4.768, Validation Loss: 6.073\n",
      "Epoch: 1606, Train Loss: 3.042, Validation Loss: 6.066\n",
      "Epoch: 1607, Train Loss: 3.696, Validation Loss: 6.108\n",
      "Epoch: 1608, Train Loss: 3.796, Validation Loss: 6.100\n",
      "Epoch: 1609, Train Loss: 3.555, Validation Loss: 6.069\n",
      "Epoch: 1610, Train Loss: 4.303, Validation Loss: 6.054\n",
      "Epoch: 1611, Train Loss: 3.448, Validation Loss: 6.095\n",
      "Epoch: 1612, Train Loss: 3.603, Validation Loss: 6.101\n",
      "Epoch: 1613, Train Loss: 4.567, Validation Loss: 6.111\n",
      "Epoch: 1614, Train Loss: 3.771, Validation Loss: 6.135\n",
      "Epoch: 1615, Train Loss: 4.678, Validation Loss: 6.091\n",
      "Epoch: 1616, Train Loss: 3.575, Validation Loss: 6.092\n",
      "Epoch: 1617, Train Loss: 4.094, Validation Loss: 6.100\n",
      "Epoch: 1618, Train Loss: 4.603, Validation Loss: 6.096\n",
      "Epoch: 1619, Train Loss: 3.831, Validation Loss: 6.077\n",
      "Epoch: 1620, Train Loss: 4.390, Validation Loss: 6.067\n",
      "Epoch: 1621, Train Loss: 3.829, Validation Loss: 6.081\n",
      "Epoch: 1622, Train Loss: 4.687, Validation Loss: 6.063\n",
      "Epoch: 1623, Train Loss: 5.186, Validation Loss: 6.086\n",
      "Epoch: 1624, Train Loss: 4.327, Validation Loss: 6.081\n",
      "Epoch: 1625, Train Loss: 4.598, Validation Loss: 6.096\n",
      "Epoch: 1626, Train Loss: 4.361, Validation Loss: 6.065\n",
      "Epoch: 1627, Train Loss: 6.035, Validation Loss: 6.057\n",
      "Epoch: 1628, Train Loss: 4.376, Validation Loss: 6.133\n",
      "Epoch: 1629, Train Loss: 4.217, Validation Loss: 6.068\n",
      "Epoch: 1630, Train Loss: 4.438, Validation Loss: 6.065\n",
      "Epoch: 1631, Train Loss: 3.994, Validation Loss: 6.080\n",
      "Epoch: 1632, Train Loss: 4.027, Validation Loss: 6.052\n",
      "Epoch: 1633, Train Loss: 5.409, Validation Loss: 6.031\n",
      "Epoch: 1634, Train Loss: 4.645, Validation Loss: 6.042\n",
      "Epoch: 1635, Train Loss: 4.781, Validation Loss: 6.025\n",
      "Epoch: 1636, Train Loss: 5.436, Validation Loss: 5.999\n",
      "Epoch: 1637, Train Loss: 4.126, Validation Loss: 5.999\n",
      "Epoch: 1638, Train Loss: 3.636, Validation Loss: 5.987\n",
      "Epoch: 1639, Train Loss: 4.140, Validation Loss: 6.018\n",
      "Epoch: 1640, Train Loss: 5.103, Validation Loss: 6.014\n",
      "Epoch: 1641, Train Loss: 4.073, Validation Loss: 6.036\n",
      "Epoch: 1642, Train Loss: 3.315, Validation Loss: 6.045\n",
      "Epoch: 1643, Train Loss: 4.566, Validation Loss: 6.030\n",
      "Epoch: 1644, Train Loss: 4.857, Validation Loss: 6.038\n",
      "Epoch: 1645, Train Loss: 4.372, Validation Loss: 6.087\n",
      "Epoch: 1646, Train Loss: 5.294, Validation Loss: 6.060\n",
      "Epoch: 1647, Train Loss: 3.467, Validation Loss: 6.067\n",
      "Epoch: 1648, Train Loss: 3.975, Validation Loss: 6.090\n",
      "Epoch: 1649, Train Loss: 4.049, Validation Loss: 6.072\n",
      "Epoch: 1650, Train Loss: 3.708, Validation Loss: 6.094\n",
      "Epoch: 1651, Train Loss: 4.110, Validation Loss: 6.056\n",
      "Epoch: 1652, Train Loss: 3.805, Validation Loss: 6.055\n",
      "Epoch: 1653, Train Loss: 3.299, Validation Loss: 6.038\n",
      "Epoch: 1654, Train Loss: 3.501, Validation Loss: 6.039\n",
      "Epoch: 1655, Train Loss: 4.077, Validation Loss: 6.074\n",
      "Epoch: 1656, Train Loss: 4.272, Validation Loss: 6.062\n",
      "Epoch: 1657, Train Loss: 3.821, Validation Loss: 6.055\n",
      "Epoch: 1658, Train Loss: 4.150, Validation Loss: 6.022\n",
      "Epoch: 1659, Train Loss: 3.683, Validation Loss: 6.028\n",
      "Epoch: 1660, Train Loss: 3.466, Validation Loss: 6.054\n",
      "Epoch: 1661, Train Loss: 2.932, Validation Loss: 6.075\n",
      "Epoch: 1662, Train Loss: 4.239, Validation Loss: 6.109\n",
      "Epoch: 1663, Train Loss: 4.075, Validation Loss: 6.066\n",
      "Epoch: 1664, Train Loss: 6.067, Validation Loss: 6.076\n",
      "Epoch: 1665, Train Loss: 4.574, Validation Loss: 6.066\n",
      "Epoch: 1666, Train Loss: 3.788, Validation Loss: 6.077\n",
      "Epoch: 1667, Train Loss: 4.112, Validation Loss: 6.052\n",
      "Epoch: 1668, Train Loss: 3.677, Validation Loss: 6.072\n",
      "Epoch: 1669, Train Loss: 3.216, Validation Loss: 6.060\n",
      "Epoch: 1670, Train Loss: 3.625, Validation Loss: 6.068\n",
      "Epoch: 1671, Train Loss: 5.075, Validation Loss: 6.092\n",
      "Epoch: 1672, Train Loss: 4.499, Validation Loss: 6.108\n",
      "Epoch: 1673, Train Loss: 3.595, Validation Loss: 6.118\n",
      "Epoch: 1674, Train Loss: 4.854, Validation Loss: 6.113\n",
      "Epoch: 1675, Train Loss: 3.460, Validation Loss: 6.141\n",
      "Epoch: 1676, Train Loss: 3.592, Validation Loss: 6.149\n",
      "Epoch: 1677, Train Loss: 4.771, Validation Loss: 6.100\n",
      "Epoch: 1678, Train Loss: 3.191, Validation Loss: 6.135\n",
      "Epoch: 1679, Train Loss: 5.152, Validation Loss: 6.159\n",
      "Epoch: 1680, Train Loss: 4.288, Validation Loss: 6.150\n",
      "Epoch: 1681, Train Loss: 4.516, Validation Loss: 6.155\n",
      "Epoch: 1682, Train Loss: 5.637, Validation Loss: 6.072\n",
      "Epoch: 1683, Train Loss: 3.380, Validation Loss: 6.094\n",
      "Epoch: 1684, Train Loss: 4.047, Validation Loss: 6.087\n",
      "Epoch: 1685, Train Loss: 3.723, Validation Loss: 6.096\n",
      "Epoch: 1686, Train Loss: 3.349, Validation Loss: 6.076\n",
      "Epoch: 1687, Train Loss: 3.410, Validation Loss: 6.106\n",
      "Epoch: 1688, Train Loss: 4.123, Validation Loss: 6.101\n",
      "Epoch: 1689, Train Loss: 6.001, Validation Loss: 6.072\n",
      "Epoch: 1690, Train Loss: 4.282, Validation Loss: 6.052\n",
      "Epoch: 1691, Train Loss: 4.605, Validation Loss: 6.047\n",
      "Epoch: 1692, Train Loss: 3.709, Validation Loss: 6.038\n",
      "Epoch: 1693, Train Loss: 3.743, Validation Loss: 6.058\n",
      "Epoch: 1694, Train Loss: 3.572, Validation Loss: 6.062\n",
      "Epoch: 1695, Train Loss: 3.236, Validation Loss: 6.055\n",
      "Epoch: 1696, Train Loss: 3.753, Validation Loss: 6.042\n",
      "Epoch: 1697, Train Loss: 3.919, Validation Loss: 6.030\n",
      "Epoch: 1698, Train Loss: 3.095, Validation Loss: 6.042\n",
      "Epoch: 1699, Train Loss: 3.693, Validation Loss: 6.033\n",
      "Epoch: 1700, Train Loss: 4.373, Validation Loss: 6.061\n",
      "Epoch: 1701, Train Loss: 3.382, Validation Loss: 6.048\n",
      "Epoch: 1702, Train Loss: 2.867, Validation Loss: 6.055\n",
      "Epoch: 1703, Train Loss: 4.451, Validation Loss: 6.099\n",
      "Epoch: 1704, Train Loss: 3.742, Validation Loss: 6.103\n",
      "Epoch: 1705, Train Loss: 3.107, Validation Loss: 6.126\n",
      "Epoch: 1706, Train Loss: 3.649, Validation Loss: 6.141\n",
      "Epoch: 1707, Train Loss: 4.047, Validation Loss: 6.146\n",
      "Epoch: 1708, Train Loss: 3.672, Validation Loss: 6.107\n",
      "Epoch: 1709, Train Loss: 3.802, Validation Loss: 6.102\n",
      "Epoch: 1710, Train Loss: 3.826, Validation Loss: 6.077\n",
      "Epoch: 1711, Train Loss: 3.240, Validation Loss: 6.058\n",
      "Epoch: 1712, Train Loss: 4.102, Validation Loss: 6.069\n",
      "Epoch: 1713, Train Loss: 4.842, Validation Loss: 6.055\n",
      "Epoch: 1714, Train Loss: 3.920, Validation Loss: 6.040\n",
      "Epoch: 1715, Train Loss: 3.914, Validation Loss: 6.043\n",
      "Epoch: 1716, Train Loss: 4.174, Validation Loss: 6.039\n",
      "Epoch: 1717, Train Loss: 3.554, Validation Loss: 6.045\n",
      "Epoch: 1718, Train Loss: 3.670, Validation Loss: 6.039\n",
      "Epoch: 1719, Train Loss: 3.569, Validation Loss: 6.053\n",
      "Epoch: 1720, Train Loss: 3.814, Validation Loss: 6.088\n",
      "Epoch: 1721, Train Loss: 4.755, Validation Loss: 6.061\n",
      "Epoch: 1722, Train Loss: 4.082, Validation Loss: 6.046\n",
      "Epoch: 1723, Train Loss: 4.305, Validation Loss: 6.024\n",
      "Epoch: 1724, Train Loss: 3.822, Validation Loss: 6.016\n",
      "Epoch: 1725, Train Loss: 4.636, Validation Loss: 6.050\n",
      "Epoch: 1726, Train Loss: 2.926, Validation Loss: 6.018\n",
      "Epoch: 1727, Train Loss: 3.966, Validation Loss: 6.038\n",
      "Epoch: 1728, Train Loss: 3.907, Validation Loss: 6.039\n",
      "Epoch: 1729, Train Loss: 3.252, Validation Loss: 6.019\n",
      "Epoch: 1730, Train Loss: 3.000, Validation Loss: 5.999\n",
      "Epoch: 1731, Train Loss: 3.676, Validation Loss: 6.018\n",
      "Epoch: 1732, Train Loss: 4.203, Validation Loss: 5.989\n",
      "Epoch: 1733, Train Loss: 3.601, Validation Loss: 6.007\n",
      "Epoch: 1734, Train Loss: 2.794, Validation Loss: 6.014\n",
      "Epoch: 1735, Train Loss: 4.060, Validation Loss: 6.029\n",
      "Epoch: 1736, Train Loss: 3.703, Validation Loss: 6.036\n",
      "Epoch: 1737, Train Loss: 3.413, Validation Loss: 6.022\n",
      "Epoch: 1738, Train Loss: 3.451, Validation Loss: 6.005\n",
      "Epoch: 1739, Train Loss: 2.838, Validation Loss: 6.016\n",
      "Epoch: 1740, Train Loss: 3.111, Validation Loss: 6.046\n",
      "Epoch: 1741, Train Loss: 4.033, Validation Loss: 6.052\n",
      "Epoch: 1742, Train Loss: 4.931, Validation Loss: 6.049\n",
      "Epoch: 1743, Train Loss: 3.951, Validation Loss: 6.037\n",
      "Epoch: 1744, Train Loss: 4.123, Validation Loss: 6.038\n",
      "Epoch: 1745, Train Loss: 3.746, Validation Loss: 6.046\n",
      "Epoch: 1746, Train Loss: 4.140, Validation Loss: 6.024\n",
      "Epoch: 1747, Train Loss: 3.665, Validation Loss: 6.025\n",
      "Epoch: 1748, Train Loss: 4.021, Validation Loss: 6.015\n",
      "Epoch: 1749, Train Loss: 3.626, Validation Loss: 6.020\n",
      "Epoch: 1750, Train Loss: 3.710, Validation Loss: 6.022\n",
      "Epoch: 1751, Train Loss: 3.198, Validation Loss: 6.006\n",
      "Epoch: 1752, Train Loss: 3.500, Validation Loss: 6.012\n",
      "Epoch: 1753, Train Loss: 5.452, Validation Loss: 5.998\n",
      "Epoch: 1754, Train Loss: 3.673, Validation Loss: 6.014\n",
      "Epoch: 1755, Train Loss: 4.108, Validation Loss: 6.010\n",
      "Epoch: 1756, Train Loss: 3.476, Validation Loss: 6.024\n",
      "Epoch: 1757, Train Loss: 3.555, Validation Loss: 6.046\n",
      "Epoch: 1758, Train Loss: 4.533, Validation Loss: 6.034\n",
      "Epoch: 1759, Train Loss: 3.896, Validation Loss: 6.010\n",
      "Epoch: 1760, Train Loss: 3.348, Validation Loss: 5.986\n",
      "Epoch: 1761, Train Loss: 4.293, Validation Loss: 6.009\n",
      "Epoch: 1762, Train Loss: 3.268, Validation Loss: 6.006\n",
      "Epoch: 1763, Train Loss: 3.842, Validation Loss: 5.991\n",
      "Epoch: 1764, Train Loss: 4.212, Validation Loss: 6.008\n",
      "Epoch: 1765, Train Loss: 2.897, Validation Loss: 6.048\n",
      "Epoch: 1766, Train Loss: 3.320, Validation Loss: 6.022\n",
      "Epoch: 1767, Train Loss: 3.487, Validation Loss: 6.020\n",
      "Epoch: 1768, Train Loss: 4.364, Validation Loss: 6.081\n",
      "Epoch: 1769, Train Loss: 3.166, Validation Loss: 6.099\n",
      "Epoch: 1770, Train Loss: 4.645, Validation Loss: 6.071\n",
      "Epoch: 1771, Train Loss: 3.090, Validation Loss: 6.020\n",
      "Epoch: 1772, Train Loss: 3.449, Validation Loss: 6.019\n",
      "Epoch: 1773, Train Loss: 4.904, Validation Loss: 6.016\n",
      "Epoch: 1774, Train Loss: 3.399, Validation Loss: 5.998\n",
      "Epoch: 1775, Train Loss: 4.217, Validation Loss: 6.010\n",
      "Epoch: 1776, Train Loss: 3.584, Validation Loss: 6.048\n",
      "Epoch: 1777, Train Loss: 3.437, Validation Loss: 6.042\n",
      "Epoch: 1778, Train Loss: 3.718, Validation Loss: 6.034\n",
      "Epoch: 1779, Train Loss: 3.043, Validation Loss: 6.066\n",
      "Epoch: 1780, Train Loss: 3.405, Validation Loss: 6.079\n",
      "Epoch: 1781, Train Loss: 3.132, Validation Loss: 6.104\n",
      "Epoch: 1782, Train Loss: 3.098, Validation Loss: 6.113\n",
      "Epoch: 1783, Train Loss: 3.668, Validation Loss: 6.112\n",
      "Epoch: 1784, Train Loss: 3.374, Validation Loss: 6.106\n",
      "Epoch: 1785, Train Loss: 2.825, Validation Loss: 6.124\n",
      "Epoch: 1786, Train Loss: 3.647, Validation Loss: 6.117\n",
      "Epoch: 1787, Train Loss: 3.272, Validation Loss: 6.107\n",
      "Epoch: 1788, Train Loss: 3.476, Validation Loss: 6.080\n",
      "Epoch: 1789, Train Loss: 3.651, Validation Loss: 6.059\n",
      "Epoch: 1790, Train Loss: 4.016, Validation Loss: 6.038\n",
      "Epoch: 1791, Train Loss: 3.791, Validation Loss: 6.042\n",
      "Epoch: 1792, Train Loss: 3.839, Validation Loss: 6.028\n",
      "Epoch: 1793, Train Loss: 4.002, Validation Loss: 6.011\n",
      "Epoch: 1794, Train Loss: 3.796, Validation Loss: 5.984\n",
      "Epoch: 1795, Train Loss: 3.331, Validation Loss: 5.994\n",
      "Epoch: 1796, Train Loss: 4.954, Validation Loss: 6.020\n",
      "Epoch: 1797, Train Loss: 4.316, Validation Loss: 5.995\n",
      "Epoch: 1798, Train Loss: 2.924, Validation Loss: 6.022\n",
      "Epoch: 1799, Train Loss: 3.804, Validation Loss: 6.070\n",
      "Epoch: 1800, Train Loss: 3.429, Validation Loss: 6.078\n",
      "Epoch: 1801, Train Loss: 3.213, Validation Loss: 6.081\n",
      "Epoch: 1802, Train Loss: 3.434, Validation Loss: 6.079\n",
      "Epoch: 1803, Train Loss: 4.101, Validation Loss: 6.100\n",
      "Epoch: 1804, Train Loss: 3.555, Validation Loss: 6.085\n",
      "Epoch: 1805, Train Loss: 3.811, Validation Loss: 6.060\n",
      "Epoch: 1806, Train Loss: 3.648, Validation Loss: 6.066\n",
      "Epoch: 1807, Train Loss: 3.905, Validation Loss: 6.043\n",
      "Epoch: 1808, Train Loss: 3.977, Validation Loss: 6.025\n",
      "Epoch: 1809, Train Loss: 3.712, Validation Loss: 6.004\n",
      "Epoch: 1810, Train Loss: 3.373, Validation Loss: 6.000\n",
      "Epoch: 1811, Train Loss: 3.454, Validation Loss: 6.020\n",
      "Epoch: 1812, Train Loss: 3.607, Validation Loss: 6.018\n",
      "Epoch: 1813, Train Loss: 3.467, Validation Loss: 6.034\n",
      "Epoch: 1814, Train Loss: 3.951, Validation Loss: 6.024\n",
      "Epoch: 1815, Train Loss: 3.143, Validation Loss: 6.012\n",
      "Epoch: 1816, Train Loss: 3.554, Validation Loss: 6.020\n",
      "Epoch: 1817, Train Loss: 3.255, Validation Loss: 6.028\n",
      "Epoch: 1818, Train Loss: 3.890, Validation Loss: 6.021\n",
      "Epoch: 1819, Train Loss: 4.361, Validation Loss: 6.011\n",
      "Epoch: 1820, Train Loss: 2.998, Validation Loss: 5.961\n",
      "Epoch: 1821, Train Loss: 3.799, Validation Loss: 6.018\n",
      "Epoch: 1822, Train Loss: 2.932, Validation Loss: 6.016\n",
      "Epoch: 1823, Train Loss: 4.376, Validation Loss: 6.011\n",
      "Epoch: 1824, Train Loss: 3.775, Validation Loss: 6.008\n",
      "Epoch: 1825, Train Loss: 4.502, Validation Loss: 6.027\n",
      "Epoch: 1826, Train Loss: 4.511, Validation Loss: 6.044\n",
      "Epoch: 1827, Train Loss: 4.042, Validation Loss: 6.097\n",
      "Epoch: 1828, Train Loss: 3.096, Validation Loss: 6.108\n",
      "Epoch: 1829, Train Loss: 3.220, Validation Loss: 6.053\n",
      "Epoch: 1830, Train Loss: 4.169, Validation Loss: 6.051\n",
      "Epoch: 1831, Train Loss: 3.499, Validation Loss: 6.093\n",
      "Epoch: 1832, Train Loss: 3.878, Validation Loss: 6.090\n",
      "Epoch: 1833, Train Loss: 3.762, Validation Loss: 6.122\n",
      "Epoch: 1834, Train Loss: 3.731, Validation Loss: 6.109\n",
      "Epoch: 1835, Train Loss: 3.754, Validation Loss: 6.095\n",
      "Epoch: 1836, Train Loss: 3.005, Validation Loss: 6.102\n",
      "Epoch: 1837, Train Loss: 3.328, Validation Loss: 6.127\n",
      "Epoch: 1838, Train Loss: 3.921, Validation Loss: 6.128\n",
      "Epoch: 1839, Train Loss: 3.706, Validation Loss: 6.118\n",
      "Epoch: 1840, Train Loss: 3.411, Validation Loss: 6.103\n",
      "Epoch: 1841, Train Loss: 4.887, Validation Loss: 6.097\n",
      "Epoch: 1842, Train Loss: 3.045, Validation Loss: 6.068\n",
      "Epoch: 1843, Train Loss: 4.243, Validation Loss: 6.077\n",
      "Epoch: 1844, Train Loss: 4.536, Validation Loss: 6.086\n",
      "Epoch: 1845, Train Loss: 2.764, Validation Loss: 6.054\n",
      "Epoch: 1846, Train Loss: 3.152, Validation Loss: 6.058\n",
      "Epoch: 1847, Train Loss: 3.286, Validation Loss: 6.055\n",
      "Epoch: 1848, Train Loss: 3.779, Validation Loss: 6.040\n",
      "Epoch: 1849, Train Loss: 4.609, Validation Loss: 6.000\n",
      "Epoch: 1850, Train Loss: 3.723, Validation Loss: 6.046\n",
      "Epoch: 1851, Train Loss: 3.601, Validation Loss: 6.048\n",
      "Epoch: 1852, Train Loss: 4.544, Validation Loss: 6.098\n",
      "Epoch: 1853, Train Loss: 3.611, Validation Loss: 6.089\n",
      "Epoch: 1854, Train Loss: 3.796, Validation Loss: 6.106\n",
      "Epoch: 1855, Train Loss: 3.082, Validation Loss: 6.132\n",
      "Epoch: 1856, Train Loss: 4.233, Validation Loss: 6.114\n",
      "Epoch: 1857, Train Loss: 4.129, Validation Loss: 6.122\n",
      "Epoch: 1858, Train Loss: 3.042, Validation Loss: 6.078\n",
      "Epoch: 1859, Train Loss: 4.422, Validation Loss: 6.027\n",
      "Epoch: 1860, Train Loss: 3.374, Validation Loss: 6.057\n",
      "Epoch: 1861, Train Loss: 3.680, Validation Loss: 6.076\n",
      "Epoch: 1862, Train Loss: 3.559, Validation Loss: 6.050\n",
      "Epoch: 1863, Train Loss: 3.748, Validation Loss: 6.067\n",
      "Epoch: 1864, Train Loss: 4.456, Validation Loss: 6.080\n",
      "Epoch: 1865, Train Loss: 4.127, Validation Loss: 6.038\n",
      "Epoch: 1866, Train Loss: 3.550, Validation Loss: 6.033\n",
      "Epoch: 1867, Train Loss: 3.330, Validation Loss: 6.067\n",
      "Epoch: 1868, Train Loss: 3.715, Validation Loss: 6.087\n",
      "Epoch: 1869, Train Loss: 3.975, Validation Loss: 6.112\n",
      "Epoch: 1870, Train Loss: 3.923, Validation Loss: 6.042\n",
      "Epoch: 1871, Train Loss: 3.968, Validation Loss: 6.050\n",
      "Epoch: 1872, Train Loss: 3.265, Validation Loss: 6.046\n",
      "Epoch: 1873, Train Loss: 2.799, Validation Loss: 6.019\n",
      "Epoch: 1874, Train Loss: 3.154, Validation Loss: 6.018\n",
      "Epoch: 1875, Train Loss: 4.271, Validation Loss: 6.023\n",
      "Epoch: 1876, Train Loss: 2.930, Validation Loss: 6.046\n",
      "Epoch: 1877, Train Loss: 3.557, Validation Loss: 6.052\n",
      "Epoch: 1878, Train Loss: 4.406, Validation Loss: 6.043\n",
      "Epoch: 1879, Train Loss: 3.261, Validation Loss: 6.050\n",
      "Epoch: 1880, Train Loss: 3.274, Validation Loss: 6.048\n",
      "Epoch: 1881, Train Loss: 4.804, Validation Loss: 6.053\n",
      "Epoch: 1882, Train Loss: 3.815, Validation Loss: 6.061\n",
      "Epoch: 1883, Train Loss: 3.341, Validation Loss: 6.026\n",
      "Epoch: 1884, Train Loss: 3.209, Validation Loss: 6.059\n",
      "Epoch: 1885, Train Loss: 3.412, Validation Loss: 6.052\n",
      "Epoch: 1886, Train Loss: 3.369, Validation Loss: 6.083\n",
      "Epoch: 1887, Train Loss: 3.216, Validation Loss: 6.098\n",
      "Epoch: 1888, Train Loss: 3.826, Validation Loss: 6.115\n",
      "Epoch: 1889, Train Loss: 3.546, Validation Loss: 6.099\n",
      "Epoch: 1890, Train Loss: 3.472, Validation Loss: 6.091\n",
      "Epoch: 1891, Train Loss: 4.368, Validation Loss: 6.080\n",
      "Epoch: 1892, Train Loss: 3.886, Validation Loss: 6.125\n",
      "Epoch: 1893, Train Loss: 4.342, Validation Loss: 6.088\n",
      "Epoch: 1894, Train Loss: 2.773, Validation Loss: 6.055\n",
      "Epoch: 1895, Train Loss: 3.334, Validation Loss: 6.063\n",
      "Epoch: 1896, Train Loss: 4.008, Validation Loss: 6.060\n",
      "Epoch: 1897, Train Loss: 4.375, Validation Loss: 6.047\n",
      "Epoch: 1898, Train Loss: 3.392, Validation Loss: 6.064\n",
      "Epoch: 1899, Train Loss: 2.876, Validation Loss: 6.076\n",
      "Epoch: 1900, Train Loss: 2.873, Validation Loss: 6.043\n",
      "Epoch: 1901, Train Loss: 3.678, Validation Loss: 6.037\n",
      "Epoch: 1902, Train Loss: 4.044, Validation Loss: 6.023\n",
      "Epoch: 1903, Train Loss: 3.311, Validation Loss: 5.990\n",
      "Epoch: 1904, Train Loss: 3.647, Validation Loss: 6.011\n",
      "Epoch: 1905, Train Loss: 2.837, Validation Loss: 6.016\n",
      "Epoch: 1906, Train Loss: 2.893, Validation Loss: 6.046\n",
      "Epoch: 1907, Train Loss: 3.579, Validation Loss: 6.065\n",
      "Epoch: 1908, Train Loss: 3.777, Validation Loss: 6.114\n",
      "Epoch: 1909, Train Loss: 3.862, Validation Loss: 6.131\n",
      "Epoch: 1910, Train Loss: 3.077, Validation Loss: 6.083\n",
      "Epoch: 1911, Train Loss: 3.182, Validation Loss: 6.108\n",
      "Epoch: 1912, Train Loss: 3.811, Validation Loss: 6.120\n",
      "Epoch: 1913, Train Loss: 4.505, Validation Loss: 6.104\n",
      "Epoch: 1914, Train Loss: 3.196, Validation Loss: 6.079\n",
      "Epoch: 1915, Train Loss: 3.796, Validation Loss: 6.073\n",
      "Epoch: 1916, Train Loss: 3.551, Validation Loss: 6.048\n",
      "Epoch: 1917, Train Loss: 4.535, Validation Loss: 6.071\n",
      "Epoch: 1918, Train Loss: 4.188, Validation Loss: 6.029\n",
      "Epoch: 1919, Train Loss: 4.085, Validation Loss: 6.036\n",
      "Epoch: 1920, Train Loss: 3.021, Validation Loss: 6.023\n",
      "Epoch: 1921, Train Loss: 3.471, Validation Loss: 6.033\n",
      "Epoch: 1922, Train Loss: 3.250, Validation Loss: 6.060\n",
      "Epoch: 1923, Train Loss: 3.270, Validation Loss: 6.058\n",
      "Epoch: 1924, Train Loss: 3.137, Validation Loss: 6.048\n",
      "Epoch: 1925, Train Loss: 3.586, Validation Loss: 6.032\n",
      "Epoch: 1926, Train Loss: 4.174, Validation Loss: 6.007\n",
      "Epoch: 1927, Train Loss: 3.869, Validation Loss: 5.991\n",
      "Epoch: 1928, Train Loss: 2.712, Validation Loss: 5.984\n",
      "Epoch: 1929, Train Loss: 4.106, Validation Loss: 5.976\n",
      "Epoch: 1930, Train Loss: 3.905, Validation Loss: 6.018\n",
      "Epoch: 1931, Train Loss: 3.792, Validation Loss: 6.038\n",
      "Epoch: 1932, Train Loss: 3.873, Validation Loss: 6.053\n",
      "Epoch: 1933, Train Loss: 2.998, Validation Loss: 6.013\n",
      "Epoch: 1934, Train Loss: 4.271, Validation Loss: 5.996\n",
      "Epoch: 1935, Train Loss: 4.307, Validation Loss: 5.998\n",
      "Epoch: 1936, Train Loss: 3.720, Validation Loss: 5.994\n",
      "Epoch: 1937, Train Loss: 3.618, Validation Loss: 5.999\n",
      "Epoch: 1938, Train Loss: 3.267, Validation Loss: 5.991\n",
      "Epoch: 1939, Train Loss: 3.285, Validation Loss: 5.977\n",
      "Epoch: 1940, Train Loss: 3.514, Validation Loss: 6.011\n",
      "Epoch: 1941, Train Loss: 3.442, Validation Loss: 6.018\n",
      "Epoch: 1942, Train Loss: 3.433, Validation Loss: 6.027\n",
      "Epoch: 1943, Train Loss: 3.928, Validation Loss: 6.015\n",
      "Epoch: 1944, Train Loss: 3.208, Validation Loss: 6.059\n",
      "Epoch: 1945, Train Loss: 3.591, Validation Loss: 6.077\n",
      "Epoch: 1946, Train Loss: 3.734, Validation Loss: 6.064\n",
      "Epoch: 1947, Train Loss: 3.353, Validation Loss: 6.066\n",
      "Epoch: 1948, Train Loss: 4.045, Validation Loss: 6.057\n",
      "Epoch: 1949, Train Loss: 4.202, Validation Loss: 6.016\n",
      "Epoch: 1950, Train Loss: 3.744, Validation Loss: 6.020\n",
      "Epoch: 1951, Train Loss: 4.257, Validation Loss: 5.999\n",
      "Epoch: 1952, Train Loss: 3.392, Validation Loss: 6.032\n",
      "Epoch: 1953, Train Loss: 3.284, Validation Loss: 6.035\n",
      "Epoch: 1954, Train Loss: 2.945, Validation Loss: 6.019\n",
      "Epoch: 1955, Train Loss: 3.433, Validation Loss: 6.034\n",
      "Epoch: 1956, Train Loss: 2.892, Validation Loss: 6.055\n",
      "Epoch: 1957, Train Loss: 4.861, Validation Loss: 6.073\n",
      "Epoch: 1958, Train Loss: 3.234, Validation Loss: 6.080\n",
      "Epoch: 1959, Train Loss: 3.865, Validation Loss: 6.054\n",
      "Epoch: 1960, Train Loss: 4.862, Validation Loss: 6.051\n",
      "Epoch: 1961, Train Loss: 3.532, Validation Loss: 6.021\n",
      "Epoch: 1962, Train Loss: 4.045, Validation Loss: 6.032\n",
      "Epoch: 1963, Train Loss: 2.558, Validation Loss: 6.023\n",
      "Epoch: 1964, Train Loss: 3.529, Validation Loss: 6.053\n",
      "Epoch: 1965, Train Loss: 3.362, Validation Loss: 6.060\n",
      "Epoch: 1966, Train Loss: 3.711, Validation Loss: 6.086\n",
      "Epoch: 1967, Train Loss: 3.659, Validation Loss: 6.037\n",
      "Epoch: 1968, Train Loss: 2.822, Validation Loss: 6.013\n",
      "Epoch: 1969, Train Loss: 3.323, Validation Loss: 6.039\n",
      "Epoch: 1970, Train Loss: 2.607, Validation Loss: 6.027\n",
      "Epoch: 1971, Train Loss: 3.833, Validation Loss: 6.054\n",
      "Epoch: 1972, Train Loss: 3.139, Validation Loss: 6.034\n",
      "Epoch: 1973, Train Loss: 3.712, Validation Loss: 6.032\n",
      "Epoch: 1974, Train Loss: 2.975, Validation Loss: 6.004\n",
      "Epoch: 1975, Train Loss: 2.901, Validation Loss: 6.067\n",
      "Epoch: 1976, Train Loss: 4.099, Validation Loss: 6.068\n",
      "Epoch: 1977, Train Loss: 3.588, Validation Loss: 6.036\n",
      "Epoch: 1978, Train Loss: 2.669, Validation Loss: 6.032\n",
      "Epoch: 1979, Train Loss: 3.436, Validation Loss: 6.021\n",
      "Epoch: 1980, Train Loss: 3.581, Validation Loss: 6.043\n",
      "Epoch: 1981, Train Loss: 4.306, Validation Loss: 6.042\n",
      "Epoch: 1982, Train Loss: 3.371, Validation Loss: 6.038\n",
      "Epoch: 1983, Train Loss: 3.314, Validation Loss: 6.020\n",
      "Epoch: 1984, Train Loss: 3.022, Validation Loss: 6.016\n",
      "Epoch: 1985, Train Loss: 3.394, Validation Loss: 6.016\n",
      "Epoch: 1986, Train Loss: 4.294, Validation Loss: 6.022\n",
      "Epoch: 1987, Train Loss: 3.179, Validation Loss: 6.038\n",
      "Epoch: 1988, Train Loss: 3.323, Validation Loss: 6.061\n",
      "Epoch: 1989, Train Loss: 3.541, Validation Loss: 6.034\n",
      "Epoch: 1990, Train Loss: 4.179, Validation Loss: 6.074\n",
      "Epoch: 1991, Train Loss: 3.530, Validation Loss: 6.045\n",
      "Epoch: 1992, Train Loss: 3.173, Validation Loss: 6.036\n",
      "Epoch: 1993, Train Loss: 3.392, Validation Loss: 6.061\n",
      "Epoch: 1994, Train Loss: 3.850, Validation Loss: 6.048\n",
      "Epoch: 1995, Train Loss: 3.269, Validation Loss: 6.036\n",
      "Epoch: 1996, Train Loss: 3.099, Validation Loss: 6.048\n",
      "Epoch: 1997, Train Loss: 4.586, Validation Loss: 6.061\n",
      "Epoch: 1998, Train Loss: 2.958, Validation Loss: 6.045\n",
      "Epoch: 1999, Train Loss: 3.629, Validation Loss: 6.061\n",
      "Epoch: 2000, Train Loss: 3.782, Validation Loss: 6.075\n",
      "Epoch: 2001, Train Loss: 4.190, Validation Loss: 6.062\n",
      "Epoch: 2002, Train Loss: 3.533, Validation Loss: 6.089\n",
      "Epoch: 2003, Train Loss: 4.224, Validation Loss: 6.084\n",
      "Epoch: 2004, Train Loss: 3.779, Validation Loss: 6.044\n",
      "Epoch: 2005, Train Loss: 3.531, Validation Loss: 6.066\n",
      "Epoch: 2006, Train Loss: 2.952, Validation Loss: 6.070\n",
      "Epoch: 2007, Train Loss: 2.990, Validation Loss: 6.104\n",
      "Epoch: 2008, Train Loss: 3.025, Validation Loss: 6.084\n",
      "Epoch: 2009, Train Loss: 4.677, Validation Loss: 6.117\n",
      "Epoch: 2010, Train Loss: 3.593, Validation Loss: 6.108\n",
      "Epoch: 2011, Train Loss: 4.015, Validation Loss: 6.149\n",
      "Epoch: 2012, Train Loss: 3.221, Validation Loss: 6.113\n",
      "Epoch: 2013, Train Loss: 3.174, Validation Loss: 6.131\n",
      "Epoch: 2014, Train Loss: 3.644, Validation Loss: 6.140\n",
      "Epoch: 2015, Train Loss: 2.935, Validation Loss: 6.147\n",
      "Epoch: 2016, Train Loss: 2.693, Validation Loss: 6.122\n",
      "Epoch: 2017, Train Loss: 3.344, Validation Loss: 6.095\n",
      "Epoch: 2018, Train Loss: 3.515, Validation Loss: 6.102\n",
      "Epoch: 2019, Train Loss: 3.409, Validation Loss: 6.070\n",
      "Epoch: 2020, Train Loss: 3.050, Validation Loss: 6.075\n",
      "Epoch: 2021, Train Loss: 2.689, Validation Loss: 6.083\n",
      "Epoch: 2022, Train Loss: 2.880, Validation Loss: 6.125\n",
      "Epoch: 2023, Train Loss: 3.776, Validation Loss: 6.147\n",
      "Epoch: 2024, Train Loss: 3.449, Validation Loss: 6.108\n",
      "Epoch: 2025, Train Loss: 3.206, Validation Loss: 6.113\n",
      "Epoch: 2026, Train Loss: 2.571, Validation Loss: 6.125\n",
      "Epoch: 2027, Train Loss: 3.398, Validation Loss: 6.106\n",
      "Epoch: 2028, Train Loss: 3.116, Validation Loss: 6.095\n",
      "Epoch: 2029, Train Loss: 3.115, Validation Loss: 6.057\n",
      "Epoch: 2030, Train Loss: 2.852, Validation Loss: 6.068\n",
      "Epoch: 2031, Train Loss: 4.037, Validation Loss: 6.038\n",
      "Epoch: 2032, Train Loss: 2.906, Validation Loss: 6.029\n",
      "Epoch: 2033, Train Loss: 3.857, Validation Loss: 6.010\n",
      "Epoch: 2034, Train Loss: 3.652, Validation Loss: 6.053\n",
      "Epoch: 2035, Train Loss: 3.944, Validation Loss: 6.029\n",
      "Epoch: 2036, Train Loss: 4.246, Validation Loss: 6.051\n",
      "Epoch: 2037, Train Loss: 3.471, Validation Loss: 6.082\n",
      "Epoch: 2038, Train Loss: 4.362, Validation Loss: 6.076\n",
      "Epoch: 2039, Train Loss: 4.165, Validation Loss: 6.091\n",
      "Epoch: 2040, Train Loss: 2.994, Validation Loss: 6.051\n",
      "Epoch: 2041, Train Loss: 3.046, Validation Loss: 6.062\n",
      "Epoch: 2042, Train Loss: 3.937, Validation Loss: 6.080\n",
      "Epoch: 2043, Train Loss: 3.591, Validation Loss: 6.113\n",
      "Epoch: 2044, Train Loss: 3.645, Validation Loss: 6.089\n",
      "Epoch: 2045, Train Loss: 2.982, Validation Loss: 6.103\n",
      "Epoch: 2046, Train Loss: 3.768, Validation Loss: 6.129\n",
      "Epoch: 2047, Train Loss: 3.113, Validation Loss: 6.130\n",
      "Epoch: 2048, Train Loss: 2.411, Validation Loss: 6.145\n",
      "Epoch: 2049, Train Loss: 3.614, Validation Loss: 6.135\n",
      "Epoch: 2050, Train Loss: 3.057, Validation Loss: 6.130\n",
      "Epoch: 2051, Train Loss: 3.342, Validation Loss: 6.103\n",
      "Epoch: 2052, Train Loss: 3.913, Validation Loss: 6.088\n",
      "Epoch: 2053, Train Loss: 3.508, Validation Loss: 6.117\n",
      "Epoch: 2054, Train Loss: 4.432, Validation Loss: 6.143\n",
      "Epoch: 2055, Train Loss: 3.608, Validation Loss: 6.129\n",
      "Epoch: 2056, Train Loss: 4.352, Validation Loss: 6.082\n",
      "Epoch: 2057, Train Loss: 3.895, Validation Loss: 6.031\n",
      "Epoch: 2058, Train Loss: 3.257, Validation Loss: 6.033\n",
      "Epoch: 2059, Train Loss: 2.926, Validation Loss: 6.032\n",
      "Epoch: 2060, Train Loss: 4.347, Validation Loss: 6.034\n",
      "Epoch: 2061, Train Loss: 3.224, Validation Loss: 6.025\n",
      "Epoch: 2062, Train Loss: 3.592, Validation Loss: 6.026\n",
      "Epoch: 2063, Train Loss: 3.503, Validation Loss: 6.048\n",
      "Epoch: 2064, Train Loss: 3.180, Validation Loss: 6.034\n",
      "Epoch: 2065, Train Loss: 2.886, Validation Loss: 6.011\n",
      "Epoch: 2066, Train Loss: 2.955, Validation Loss: 6.006\n",
      "Epoch: 2067, Train Loss: 4.279, Validation Loss: 6.042\n",
      "Epoch: 2068, Train Loss: 4.296, Validation Loss: 6.046\n",
      "Epoch: 2069, Train Loss: 2.451, Validation Loss: 6.042\n",
      "Epoch: 2070, Train Loss: 3.405, Validation Loss: 6.031\n",
      "Epoch: 2071, Train Loss: 3.577, Validation Loss: 6.002\n",
      "Epoch: 2072, Train Loss: 3.495, Validation Loss: 5.987\n",
      "Epoch: 2073, Train Loss: 3.033, Validation Loss: 5.986\n",
      "Epoch: 2074, Train Loss: 2.782, Validation Loss: 5.990\n",
      "Epoch: 2075, Train Loss: 3.767, Validation Loss: 6.013\n",
      "Epoch: 2076, Train Loss: 3.291, Validation Loss: 6.023\n",
      "Epoch: 2077, Train Loss: 3.748, Validation Loss: 5.997\n",
      "Epoch: 2078, Train Loss: 3.569, Validation Loss: 5.999\n",
      "Epoch: 2079, Train Loss: 3.814, Validation Loss: 5.995\n",
      "Epoch: 2080, Train Loss: 3.526, Validation Loss: 5.973\n",
      "Epoch: 2081, Train Loss: 2.919, Validation Loss: 5.954\n",
      "Epoch: 2082, Train Loss: 3.000, Validation Loss: 5.977\n",
      "Epoch: 2083, Train Loss: 3.699, Validation Loss: 5.990\n",
      "Epoch: 2084, Train Loss: 3.622, Validation Loss: 6.031\n",
      "Epoch: 2085, Train Loss: 3.566, Validation Loss: 6.010\n",
      "Epoch: 2086, Train Loss: 3.467, Validation Loss: 5.984\n",
      "Epoch: 2087, Train Loss: 2.827, Validation Loss: 5.996\n",
      "Epoch: 2088, Train Loss: 3.170, Validation Loss: 6.006\n",
      "Epoch: 2089, Train Loss: 2.389, Validation Loss: 6.025\n",
      "Epoch: 2090, Train Loss: 3.240, Validation Loss: 6.036\n",
      "Epoch: 2091, Train Loss: 3.541, Validation Loss: 6.039\n",
      "Epoch: 2092, Train Loss: 3.722, Validation Loss: 6.037\n",
      "Epoch: 2093, Train Loss: 3.071, Validation Loss: 6.016\n",
      "Epoch: 2094, Train Loss: 3.012, Validation Loss: 6.018\n",
      "Epoch: 2095, Train Loss: 4.005, Validation Loss: 6.021\n",
      "Epoch: 2096, Train Loss: 2.781, Validation Loss: 6.039\n",
      "Epoch: 2097, Train Loss: 3.561, Validation Loss: 6.019\n",
      "Epoch: 2098, Train Loss: 3.335, Validation Loss: 5.990\n",
      "Epoch: 2099, Train Loss: 3.413, Validation Loss: 5.990\n",
      "Epoch: 2100, Train Loss: 3.020, Validation Loss: 6.034\n",
      "Epoch: 2101, Train Loss: 2.493, Validation Loss: 6.026\n",
      "Epoch: 2102, Train Loss: 2.400, Validation Loss: 6.018\n",
      "Epoch: 2103, Train Loss: 4.414, Validation Loss: 6.007\n",
      "Epoch: 2104, Train Loss: 3.169, Validation Loss: 6.014\n",
      "Epoch: 2105, Train Loss: 3.591, Validation Loss: 5.991\n",
      "Epoch: 2106, Train Loss: 3.670, Validation Loss: 5.982\n",
      "Epoch: 2107, Train Loss: 3.274, Validation Loss: 5.985\n",
      "Epoch: 2108, Train Loss: 2.988, Validation Loss: 6.016\n",
      "Epoch: 2109, Train Loss: 3.394, Validation Loss: 6.036\n",
      "Epoch: 2110, Train Loss: 3.079, Validation Loss: 6.026\n",
      "Epoch: 2111, Train Loss: 2.671, Validation Loss: 6.012\n",
      "Epoch: 2112, Train Loss: 3.805, Validation Loss: 6.005\n",
      "Epoch: 2113, Train Loss: 3.462, Validation Loss: 6.045\n",
      "Epoch: 2114, Train Loss: 3.674, Validation Loss: 6.039\n",
      "Epoch: 2115, Train Loss: 3.057, Validation Loss: 6.110\n",
      "Epoch: 2116, Train Loss: 3.611, Validation Loss: 6.092\n",
      "Epoch: 2117, Train Loss: 3.965, Validation Loss: 6.081\n",
      "Epoch: 2118, Train Loss: 3.591, Validation Loss: 6.046\n",
      "Epoch: 2119, Train Loss: 3.455, Validation Loss: 6.030\n",
      "Epoch: 2120, Train Loss: 3.572, Validation Loss: 6.061\n",
      "Epoch: 2121, Train Loss: 3.406, Validation Loss: 6.058\n",
      "Epoch: 2122, Train Loss: 3.202, Validation Loss: 6.067\n",
      "Epoch: 2123, Train Loss: 2.965, Validation Loss: 6.055\n",
      "Epoch: 2124, Train Loss: 2.728, Validation Loss: 6.044\n",
      "Epoch: 2125, Train Loss: 3.049, Validation Loss: 6.038\n",
      "Epoch: 2126, Train Loss: 3.045, Validation Loss: 6.039\n",
      "Epoch: 2127, Train Loss: 3.313, Validation Loss: 6.049\n",
      "Epoch: 2128, Train Loss: 2.730, Validation Loss: 6.077\n",
      "Epoch: 2129, Train Loss: 2.846, Validation Loss: 6.092\n",
      "Epoch: 2130, Train Loss: 3.038, Validation Loss: 6.084\n",
      "Epoch: 2131, Train Loss: 2.793, Validation Loss: 6.079\n",
      "Epoch: 2132, Train Loss: 3.223, Validation Loss: 6.071\n",
      "Epoch: 2133, Train Loss: 2.901, Validation Loss: 6.062\n",
      "Epoch: 2134, Train Loss: 3.415, Validation Loss: 6.054\n",
      "Epoch: 2135, Train Loss: 2.968, Validation Loss: 6.063\n",
      "Epoch: 2136, Train Loss: 2.830, Validation Loss: 6.046\n",
      "Epoch: 2137, Train Loss: 2.946, Validation Loss: 6.057\n",
      "Epoch: 2138, Train Loss: 3.615, Validation Loss: 6.088\n",
      "Epoch: 2139, Train Loss: 3.536, Validation Loss: 6.091\n",
      "Epoch: 2140, Train Loss: 3.260, Validation Loss: 6.074\n",
      "Epoch: 2141, Train Loss: 4.016, Validation Loss: 6.059\n",
      "Epoch: 2142, Train Loss: 3.870, Validation Loss: 6.079\n",
      "Epoch: 2143, Train Loss: 2.939, Validation Loss: 6.037\n",
      "Epoch: 2144, Train Loss: 3.707, Validation Loss: 6.015\n",
      "Epoch: 2145, Train Loss: 3.704, Validation Loss: 6.030\n",
      "Epoch: 2146, Train Loss: 2.814, Validation Loss: 6.022\n",
      "Epoch: 2147, Train Loss: 3.309, Validation Loss: 6.017\n",
      "Epoch: 2148, Train Loss: 3.851, Validation Loss: 6.007\n",
      "Epoch: 2149, Train Loss: 3.012, Validation Loss: 6.020\n",
      "Epoch: 2150, Train Loss: 3.549, Validation Loss: 5.984\n",
      "Epoch: 2151, Train Loss: 2.443, Validation Loss: 6.021\n",
      "Epoch: 2152, Train Loss: 3.900, Validation Loss: 6.027\n",
      "Epoch: 2153, Train Loss: 2.823, Validation Loss: 6.028\n",
      "Epoch: 2154, Train Loss: 2.501, Validation Loss: 6.041\n",
      "Epoch: 2155, Train Loss: 3.193, Validation Loss: 6.050\n",
      "Epoch: 2156, Train Loss: 3.951, Validation Loss: 6.075\n",
      "Epoch: 2157, Train Loss: 3.499, Validation Loss: 6.083\n",
      "Epoch: 2158, Train Loss: 3.208, Validation Loss: 6.090\n",
      "Epoch: 2159, Train Loss: 3.725, Validation Loss: 6.058\n",
      "Epoch: 2160, Train Loss: 3.932, Validation Loss: 6.064\n",
      "Epoch: 2161, Train Loss: 3.028, Validation Loss: 6.055\n",
      "Epoch: 2162, Train Loss: 3.340, Validation Loss: 6.102\n",
      "Epoch: 2163, Train Loss: 3.636, Validation Loss: 6.076\n",
      "Epoch: 2164, Train Loss: 3.425, Validation Loss: 6.034\n",
      "Epoch: 2165, Train Loss: 3.663, Validation Loss: 6.026\n",
      "Epoch: 2166, Train Loss: 3.260, Validation Loss: 6.010\n",
      "Epoch: 2167, Train Loss: 3.998, Validation Loss: 6.044\n",
      "Epoch: 2168, Train Loss: 3.683, Validation Loss: 6.022\n",
      "Epoch: 2169, Train Loss: 3.488, Validation Loss: 6.009\n",
      "Epoch: 2170, Train Loss: 3.561, Validation Loss: 6.041\n",
      "Epoch: 2171, Train Loss: 3.269, Validation Loss: 6.039\n",
      "Epoch: 2172, Train Loss: 2.991, Validation Loss: 6.038\n",
      "Epoch: 2173, Train Loss: 2.792, Validation Loss: 6.053\n",
      "Epoch: 2174, Train Loss: 2.972, Validation Loss: 6.054\n",
      "Epoch: 2175, Train Loss: 3.339, Validation Loss: 6.082\n",
      "Epoch: 2176, Train Loss: 2.692, Validation Loss: 6.096\n",
      "Epoch: 2177, Train Loss: 3.623, Validation Loss: 6.120\n",
      "Epoch: 2178, Train Loss: 3.536, Validation Loss: 6.114\n",
      "Epoch: 2179, Train Loss: 3.173, Validation Loss: 6.093\n",
      "Epoch: 2180, Train Loss: 3.297, Validation Loss: 6.151\n",
      "Epoch: 2181, Train Loss: 2.520, Validation Loss: 6.058\n",
      "Epoch: 2182, Train Loss: 3.519, Validation Loss: 6.079\n",
      "Epoch: 2183, Train Loss: 3.123, Validation Loss: 6.060\n",
      "Epoch: 2184, Train Loss: 2.869, Validation Loss: 6.068\n",
      "Epoch: 2185, Train Loss: 4.330, Validation Loss: 6.049\n",
      "Epoch: 2186, Train Loss: 2.853, Validation Loss: 6.061\n",
      "Epoch: 2187, Train Loss: 2.964, Validation Loss: 6.072\n",
      "Epoch: 2188, Train Loss: 3.042, Validation Loss: 6.075\n",
      "Epoch: 2189, Train Loss: 3.495, Validation Loss: 6.115\n",
      "Epoch: 2190, Train Loss: 2.976, Validation Loss: 6.129\n",
      "Epoch: 2191, Train Loss: 3.633, Validation Loss: 6.170\n",
      "Epoch: 2192, Train Loss: 2.844, Validation Loss: 6.132\n",
      "Epoch: 2193, Train Loss: 2.868, Validation Loss: 6.172\n",
      "Epoch: 2194, Train Loss: 3.564, Validation Loss: 6.193\n",
      "Epoch: 2195, Train Loss: 3.187, Validation Loss: 6.156\n",
      "Epoch: 2196, Train Loss: 3.354, Validation Loss: 6.142\n",
      "Epoch: 2197, Train Loss: 3.828, Validation Loss: 6.159\n",
      "Epoch: 2198, Train Loss: 3.564, Validation Loss: 6.110\n",
      "Epoch: 2199, Train Loss: 3.712, Validation Loss: 6.071\n",
      "Epoch: 2200, Train Loss: 3.033, Validation Loss: 6.059\n",
      "Epoch: 2201, Train Loss: 2.784, Validation Loss: 6.042\n",
      "Epoch: 2202, Train Loss: 2.897, Validation Loss: 6.051\n",
      "Epoch: 2203, Train Loss: 3.416, Validation Loss: 6.070\n",
      "Epoch: 2204, Train Loss: 2.712, Validation Loss: 6.032\n",
      "Epoch: 2205, Train Loss: 2.771, Validation Loss: 6.037\n",
      "Epoch: 2206, Train Loss: 2.558, Validation Loss: 6.018\n",
      "Epoch: 2207, Train Loss: 3.033, Validation Loss: 6.027\n",
      "Epoch: 2208, Train Loss: 3.765, Validation Loss: 6.032\n",
      "Epoch: 2209, Train Loss: 4.155, Validation Loss: 6.033\n",
      "Epoch: 2210, Train Loss: 3.182, Validation Loss: 6.008\n",
      "Epoch: 2211, Train Loss: 3.484, Validation Loss: 6.042\n",
      "Epoch: 2212, Train Loss: 2.865, Validation Loss: 6.052\n",
      "Epoch: 2213, Train Loss: 3.205, Validation Loss: 6.063\n",
      "Epoch: 2214, Train Loss: 3.146, Validation Loss: 6.062\n",
      "Epoch: 2215, Train Loss: 3.610, Validation Loss: 6.073\n",
      "Epoch: 2216, Train Loss: 3.962, Validation Loss: 6.085\n",
      "Epoch: 2217, Train Loss: 3.490, Validation Loss: 6.072\n",
      "Epoch: 2218, Train Loss: 3.355, Validation Loss: 6.073\n",
      "Epoch: 2219, Train Loss: 3.759, Validation Loss: 6.102\n",
      "Epoch: 2220, Train Loss: 4.040, Validation Loss: 6.131\n",
      "Epoch: 2221, Train Loss: 2.590, Validation Loss: 6.114\n",
      "Epoch: 2222, Train Loss: 2.758, Validation Loss: 6.082\n",
      "Epoch: 2223, Train Loss: 2.996, Validation Loss: 6.056\n",
      "Epoch: 2224, Train Loss: 3.124, Validation Loss: 6.056\n",
      "Epoch: 2225, Train Loss: 3.472, Validation Loss: 6.045\n",
      "Epoch: 2226, Train Loss: 3.126, Validation Loss: 6.052\n",
      "Epoch: 2227, Train Loss: 3.167, Validation Loss: 6.070\n",
      "Epoch: 2228, Train Loss: 3.015, Validation Loss: 6.043\n",
      "Epoch: 2229, Train Loss: 3.334, Validation Loss: 6.015\n",
      "Epoch: 2230, Train Loss: 2.796, Validation Loss: 6.023\n",
      "Epoch: 2231, Train Loss: 3.461, Validation Loss: 6.030\n",
      "Epoch: 2232, Train Loss: 2.453, Validation Loss: 6.008\n",
      "Epoch: 2233, Train Loss: 2.560, Validation Loss: 6.026\n",
      "Epoch: 2234, Train Loss: 3.863, Validation Loss: 6.054\n",
      "Epoch: 2235, Train Loss: 3.560, Validation Loss: 6.028\n",
      "Epoch: 2236, Train Loss: 3.508, Validation Loss: 6.061\n",
      "Epoch: 2237, Train Loss: 3.400, Validation Loss: 6.047\n",
      "Epoch: 2238, Train Loss: 2.653, Validation Loss: 6.023\n",
      "Epoch: 2239, Train Loss: 3.561, Validation Loss: 6.111\n",
      "Epoch: 2240, Train Loss: 3.780, Validation Loss: 6.084\n",
      "Epoch: 2241, Train Loss: 3.197, Validation Loss: 6.074\n",
      "Epoch: 2242, Train Loss: 3.777, Validation Loss: 6.058\n",
      "Epoch: 2243, Train Loss: 3.108, Validation Loss: 6.058\n",
      "Epoch: 2244, Train Loss: 3.461, Validation Loss: 6.048\n",
      "Epoch: 2245, Train Loss: 3.296, Validation Loss: 6.021\n",
      "Epoch: 2246, Train Loss: 3.476, Validation Loss: 6.039\n",
      "Epoch: 2247, Train Loss: 3.064, Validation Loss: 6.074\n",
      "Epoch: 2248, Train Loss: 2.759, Validation Loss: 6.033\n",
      "Epoch: 2249, Train Loss: 2.662, Validation Loss: 6.021\n",
      "Epoch: 2250, Train Loss: 2.806, Validation Loss: 6.026\n",
      "Epoch: 2251, Train Loss: 3.058, Validation Loss: 6.025\n",
      "Epoch: 2252, Train Loss: 3.800, Validation Loss: 6.061\n",
      "Epoch: 2253, Train Loss: 3.596, Validation Loss: 6.036\n",
      "Epoch: 2254, Train Loss: 2.862, Validation Loss: 6.049\n",
      "Epoch: 2255, Train Loss: 2.888, Validation Loss: 6.051\n",
      "Epoch: 2256, Train Loss: 3.443, Validation Loss: 6.001\n",
      "Epoch: 2257, Train Loss: 3.144, Validation Loss: 6.011\n",
      "Epoch: 2258, Train Loss: 4.079, Validation Loss: 6.074\n",
      "Epoch: 2259, Train Loss: 2.941, Validation Loss: 6.052\n",
      "Epoch: 2260, Train Loss: 3.322, Validation Loss: 6.034\n",
      "Epoch: 2261, Train Loss: 2.846, Validation Loss: 5.998\n",
      "Epoch: 2262, Train Loss: 3.075, Validation Loss: 6.023\n",
      "Epoch: 2263, Train Loss: 3.873, Validation Loss: 6.003\n",
      "Epoch: 2264, Train Loss: 2.817, Validation Loss: 6.018\n",
      "Epoch: 2265, Train Loss: 2.586, Validation Loss: 5.986\n",
      "Epoch: 2266, Train Loss: 3.317, Validation Loss: 5.944\n",
      "Epoch: 2267, Train Loss: 2.390, Validation Loss: 5.975\n",
      "Epoch: 2268, Train Loss: 3.098, Validation Loss: 5.956\n",
      "Epoch: 2269, Train Loss: 3.612, Validation Loss: 5.965\n",
      "Epoch: 2270, Train Loss: 2.789, Validation Loss: 5.972\n",
      "Epoch: 2271, Train Loss: 3.051, Validation Loss: 5.992\n",
      "Epoch: 2272, Train Loss: 3.221, Validation Loss: 6.016\n",
      "Epoch: 2273, Train Loss: 3.724, Validation Loss: 5.993\n",
      "Epoch: 2274, Train Loss: 2.757, Validation Loss: 5.982\n",
      "Epoch: 2275, Train Loss: 3.794, Validation Loss: 6.004\n",
      "Epoch: 2276, Train Loss: 2.789, Validation Loss: 5.966\n",
      "Epoch: 2277, Train Loss: 3.149, Validation Loss: 5.942\n",
      "Epoch: 2278, Train Loss: 2.945, Validation Loss: 5.984\n",
      "Epoch: 2279, Train Loss: 2.371, Validation Loss: 5.992\n",
      "Epoch: 2280, Train Loss: 3.095, Validation Loss: 6.008\n",
      "Epoch: 2281, Train Loss: 3.072, Validation Loss: 6.019\n",
      "Epoch: 2282, Train Loss: 3.481, Validation Loss: 5.999\n",
      "Epoch: 2283, Train Loss: 2.838, Validation Loss: 5.991\n",
      "Epoch: 2284, Train Loss: 2.683, Validation Loss: 5.995\n",
      "Epoch: 2285, Train Loss: 3.313, Validation Loss: 5.993\n",
      "Epoch: 2286, Train Loss: 2.776, Validation Loss: 5.985\n",
      "Epoch: 2287, Train Loss: 2.348, Validation Loss: 6.010\n",
      "Epoch: 2288, Train Loss: 3.152, Validation Loss: 6.040\n",
      "Epoch: 2289, Train Loss: 3.075, Validation Loss: 6.032\n",
      "Epoch: 2290, Train Loss: 3.008, Validation Loss: 6.024\n",
      "Epoch: 2291, Train Loss: 2.937, Validation Loss: 6.039\n",
      "Epoch: 2292, Train Loss: 2.941, Validation Loss: 6.019\n",
      "Epoch: 2293, Train Loss: 3.365, Validation Loss: 5.969\n",
      "Epoch: 2294, Train Loss: 3.154, Validation Loss: 5.978\n",
      "Epoch: 2295, Train Loss: 3.765, Validation Loss: 5.955\n",
      "Epoch: 2296, Train Loss: 3.196, Validation Loss: 6.012\n",
      "Epoch: 2297, Train Loss: 3.084, Validation Loss: 6.023\n",
      "Epoch: 2298, Train Loss: 2.705, Validation Loss: 6.007\n",
      "Epoch: 2299, Train Loss: 3.390, Validation Loss: 6.027\n",
      "Epoch: 2300, Train Loss: 2.995, Validation Loss: 5.986\n",
      "Epoch: 2301, Train Loss: 3.474, Validation Loss: 6.044\n",
      "Epoch: 2302, Train Loss: 2.946, Validation Loss: 5.998\n",
      "Epoch: 2303, Train Loss: 3.062, Validation Loss: 6.005\n",
      "Epoch: 2304, Train Loss: 2.482, Validation Loss: 5.976\n",
      "Epoch: 2305, Train Loss: 3.143, Validation Loss: 5.989\n",
      "Epoch: 2306, Train Loss: 2.704, Validation Loss: 5.988\n",
      "Epoch: 2307, Train Loss: 2.723, Validation Loss: 5.965\n",
      "Epoch: 2308, Train Loss: 3.350, Validation Loss: 5.981\n",
      "Epoch: 2309, Train Loss: 2.773, Validation Loss: 5.981\n",
      "Epoch: 2310, Train Loss: 3.208, Validation Loss: 6.001\n",
      "Epoch: 2311, Train Loss: 3.200, Validation Loss: 6.003\n",
      "Epoch: 2312, Train Loss: 2.962, Validation Loss: 6.029\n",
      "Epoch: 2313, Train Loss: 2.897, Validation Loss: 6.057\n",
      "Epoch: 2314, Train Loss: 3.231, Validation Loss: 6.018\n",
      "Epoch: 2315, Train Loss: 2.419, Validation Loss: 6.028\n",
      "Epoch: 2316, Train Loss: 2.772, Validation Loss: 6.057\n",
      "Epoch: 2317, Train Loss: 3.062, Validation Loss: 5.999\n",
      "Epoch: 2318, Train Loss: 2.828, Validation Loss: 6.042\n",
      "Epoch: 2319, Train Loss: 3.360, Validation Loss: 6.068\n",
      "Epoch: 2320, Train Loss: 4.298, Validation Loss: 6.079\n",
      "Epoch: 2321, Train Loss: 2.842, Validation Loss: 6.035\n",
      "Epoch: 2322, Train Loss: 3.243, Validation Loss: 6.035\n",
      "Epoch: 2323, Train Loss: 3.637, Validation Loss: 6.005\n",
      "Epoch: 2324, Train Loss: 2.428, Validation Loss: 5.997\n",
      "Epoch: 2325, Train Loss: 3.226, Validation Loss: 6.040\n",
      "Epoch: 2326, Train Loss: 2.945, Validation Loss: 6.100\n",
      "Epoch: 2327, Train Loss: 3.261, Validation Loss: 6.072\n",
      "Epoch: 2328, Train Loss: 2.853, Validation Loss: 6.068\n",
      "Epoch: 2329, Train Loss: 3.307, Validation Loss: 6.062\n",
      "Epoch: 2330, Train Loss: 3.314, Validation Loss: 6.027\n",
      "Epoch: 2331, Train Loss: 3.350, Validation Loss: 6.032\n",
      "Epoch: 2332, Train Loss: 3.545, Validation Loss: 6.000\n",
      "Epoch: 2333, Train Loss: 2.834, Validation Loss: 5.996\n",
      "Epoch: 2334, Train Loss: 2.973, Validation Loss: 6.006\n",
      "Epoch: 2335, Train Loss: 2.845, Validation Loss: 6.040\n",
      "Epoch: 2336, Train Loss: 3.105, Validation Loss: 6.025\n",
      "Epoch: 2337, Train Loss: 3.014, Validation Loss: 5.988\n",
      "Epoch: 2338, Train Loss: 3.427, Validation Loss: 5.975\n",
      "Epoch: 2339, Train Loss: 2.796, Validation Loss: 5.996\n",
      "Epoch: 2340, Train Loss: 3.354, Validation Loss: 5.993\n",
      "Epoch: 2341, Train Loss: 2.738, Validation Loss: 6.011\n",
      "Epoch: 2342, Train Loss: 3.235, Validation Loss: 5.985\n",
      "Epoch: 2343, Train Loss: 3.276, Validation Loss: 5.967\n",
      "Epoch: 2344, Train Loss: 3.246, Validation Loss: 5.962\n",
      "Epoch: 2345, Train Loss: 3.094, Validation Loss: 5.975\n",
      "Epoch: 2346, Train Loss: 2.479, Validation Loss: 5.986\n",
      "Epoch: 2347, Train Loss: 3.484, Validation Loss: 5.991\n",
      "Epoch: 2348, Train Loss: 3.145, Validation Loss: 5.958\n",
      "Epoch: 2349, Train Loss: 2.668, Validation Loss: 5.986\n",
      "Epoch: 2350, Train Loss: 3.331, Validation Loss: 6.004\n",
      "Epoch: 2351, Train Loss: 3.234, Validation Loss: 5.985\n",
      "Epoch: 2352, Train Loss: 2.698, Validation Loss: 5.984\n",
      "Epoch: 2353, Train Loss: 2.485, Validation Loss: 5.997\n",
      "Epoch: 2354, Train Loss: 3.883, Validation Loss: 5.993\n",
      "Epoch: 2355, Train Loss: 3.390, Validation Loss: 5.996\n",
      "Epoch: 2356, Train Loss: 3.359, Validation Loss: 5.960\n",
      "Epoch: 2357, Train Loss: 3.472, Validation Loss: 5.966\n",
      "Epoch: 2358, Train Loss: 3.322, Validation Loss: 5.974\n",
      "Epoch: 2359, Train Loss: 2.512, Validation Loss: 5.965\n",
      "Epoch: 2360, Train Loss: 3.323, Validation Loss: 5.972\n",
      "Epoch: 2361, Train Loss: 3.165, Validation Loss: 5.978\n",
      "Epoch: 2362, Train Loss: 2.875, Validation Loss: 5.967\n",
      "Epoch: 2363, Train Loss: 2.955, Validation Loss: 5.952\n",
      "Epoch: 2364, Train Loss: 3.133, Validation Loss: 5.933\n",
      "Epoch: 2365, Train Loss: 2.954, Validation Loss: 5.940\n",
      "Epoch: 2366, Train Loss: 3.188, Validation Loss: 5.955\n",
      "Epoch: 2367, Train Loss: 3.410, Validation Loss: 5.951\n",
      "Epoch: 2368, Train Loss: 2.620, Validation Loss: 5.966\n",
      "Epoch: 2369, Train Loss: 2.493, Validation Loss: 5.982\n",
      "Epoch: 2370, Train Loss: 3.497, Validation Loss: 5.960\n",
      "Epoch: 2371, Train Loss: 2.885, Validation Loss: 5.980\n",
      "Epoch: 2372, Train Loss: 2.925, Validation Loss: 6.014\n",
      "Epoch: 2373, Train Loss: 2.497, Validation Loss: 5.955\n",
      "Epoch: 2374, Train Loss: 2.941, Validation Loss: 5.927\n",
      "Epoch: 2375, Train Loss: 2.349, Validation Loss: 5.931\n",
      "Epoch: 2376, Train Loss: 2.352, Validation Loss: 5.931\n",
      "Epoch: 2377, Train Loss: 2.680, Validation Loss: 5.937\n",
      "Epoch: 2378, Train Loss: 2.859, Validation Loss: 5.916\n",
      "Epoch: 2379, Train Loss: 2.605, Validation Loss: 5.910\n",
      "Epoch: 2380, Train Loss: 2.918, Validation Loss: 5.940\n",
      "Epoch: 2381, Train Loss: 3.099, Validation Loss: 5.973\n",
      "Epoch: 2382, Train Loss: 2.660, Validation Loss: 5.956\n",
      "Epoch: 2383, Train Loss: 3.382, Validation Loss: 5.966\n",
      "Epoch: 2384, Train Loss: 2.650, Validation Loss: 5.937\n",
      "Epoch: 2385, Train Loss: 3.696, Validation Loss: 5.945\n",
      "Epoch: 2386, Train Loss: 3.177, Validation Loss: 5.967\n",
      "Epoch: 2387, Train Loss: 2.946, Validation Loss: 5.968\n",
      "Epoch: 2388, Train Loss: 3.775, Validation Loss: 5.966\n",
      "Epoch: 2389, Train Loss: 3.434, Validation Loss: 5.975\n",
      "Epoch: 2390, Train Loss: 3.818, Validation Loss: 5.952\n",
      "Epoch: 2391, Train Loss: 2.998, Validation Loss: 5.974\n",
      "Epoch: 2392, Train Loss: 2.535, Validation Loss: 5.964\n",
      "Epoch: 2393, Train Loss: 2.989, Validation Loss: 5.945\n",
      "Epoch: 2394, Train Loss: 3.064, Validation Loss: 5.928\n",
      "Epoch: 2395, Train Loss: 2.197, Validation Loss: 5.942\n",
      "Epoch: 2396, Train Loss: 2.264, Validation Loss: 5.910\n",
      "Epoch: 2397, Train Loss: 2.333, Validation Loss: 5.908\n",
      "Epoch: 2398, Train Loss: 3.375, Validation Loss: 5.930\n",
      "Epoch: 2399, Train Loss: 2.495, Validation Loss: 5.941\n",
      "Epoch: 2400, Train Loss: 3.068, Validation Loss: 5.924\n",
      "Epoch: 2401, Train Loss: 2.785, Validation Loss: 5.943\n",
      "Epoch: 2402, Train Loss: 3.200, Validation Loss: 5.895\n",
      "Epoch: 2403, Train Loss: 2.545, Validation Loss: 5.918\n",
      "Epoch: 2404, Train Loss: 2.459, Validation Loss: 5.933\n",
      "Epoch: 2405, Train Loss: 3.391, Validation Loss: 5.902\n",
      "Epoch: 2406, Train Loss: 3.084, Validation Loss: 5.875\n",
      "Epoch: 2407, Train Loss: 3.235, Validation Loss: 5.902\n",
      "Epoch: 2408, Train Loss: 2.590, Validation Loss: 5.916\n",
      "Epoch: 2409, Train Loss: 3.344, Validation Loss: 5.877\n",
      "Epoch: 2410, Train Loss: 3.260, Validation Loss: 5.886\n",
      "Epoch: 2411, Train Loss: 2.913, Validation Loss: 5.910\n",
      "Epoch: 2412, Train Loss: 3.736, Validation Loss: 5.924\n",
      "Epoch: 2413, Train Loss: 2.548, Validation Loss: 5.962\n",
      "Epoch: 2414, Train Loss: 2.839, Validation Loss: 5.911\n",
      "Epoch: 2415, Train Loss: 2.712, Validation Loss: 5.952\n",
      "Epoch: 2416, Train Loss: 3.215, Validation Loss: 5.957\n",
      "Epoch: 2417, Train Loss: 3.444, Validation Loss: 5.962\n",
      "Epoch: 2418, Train Loss: 3.847, Validation Loss: 5.943\n",
      "Epoch: 2419, Train Loss: 2.851, Validation Loss: 5.937\n",
      "Epoch: 2420, Train Loss: 3.143, Validation Loss: 5.934\n",
      "Epoch: 2421, Train Loss: 3.187, Validation Loss: 5.951\n",
      "Epoch: 2422, Train Loss: 2.976, Validation Loss: 5.969\n",
      "Epoch: 2423, Train Loss: 3.427, Validation Loss: 5.956\n",
      "Epoch: 2424, Train Loss: 2.470, Validation Loss: 5.943\n",
      "Epoch: 2425, Train Loss: 2.784, Validation Loss: 5.936\n",
      "Epoch: 2426, Train Loss: 2.566, Validation Loss: 5.962\n",
      "Epoch: 2427, Train Loss: 3.638, Validation Loss: 6.001\n",
      "Epoch: 2428, Train Loss: 3.262, Validation Loss: 5.997\n",
      "Epoch: 2429, Train Loss: 2.968, Validation Loss: 5.974\n",
      "Epoch: 2430, Train Loss: 2.454, Validation Loss: 5.979\n",
      "Epoch: 2431, Train Loss: 2.802, Validation Loss: 5.970\n",
      "Epoch: 2432, Train Loss: 3.229, Validation Loss: 5.959\n",
      "Epoch: 2433, Train Loss: 2.751, Validation Loss: 5.942\n",
      "Epoch: 2434, Train Loss: 2.501, Validation Loss: 5.983\n",
      "Epoch: 2435, Train Loss: 3.441, Validation Loss: 5.973\n",
      "Epoch: 2436, Train Loss: 2.406, Validation Loss: 5.956\n",
      "Epoch: 2437, Train Loss: 2.729, Validation Loss: 5.989\n",
      "Epoch: 2438, Train Loss: 3.567, Validation Loss: 5.937\n",
      "Epoch: 2439, Train Loss: 3.006, Validation Loss: 5.953\n",
      "Epoch: 2440, Train Loss: 4.417, Validation Loss: 5.975\n",
      "Epoch: 2441, Train Loss: 3.626, Validation Loss: 6.015\n",
      "Epoch: 2442, Train Loss: 3.228, Validation Loss: 5.992\n",
      "Epoch: 2443, Train Loss: 2.452, Validation Loss: 5.975\n",
      "Epoch: 2444, Train Loss: 2.631, Validation Loss: 5.983\n",
      "Epoch: 2445, Train Loss: 2.259, Validation Loss: 6.021\n",
      "Epoch: 2446, Train Loss: 2.574, Validation Loss: 5.996\n",
      "Epoch: 2447, Train Loss: 2.699, Validation Loss: 6.021\n",
      "Epoch: 2448, Train Loss: 2.489, Validation Loss: 6.022\n",
      "Epoch: 2449, Train Loss: 2.976, Validation Loss: 6.028\n",
      "Epoch: 2450, Train Loss: 3.325, Validation Loss: 6.076\n",
      "Epoch: 2451, Train Loss: 2.814, Validation Loss: 6.072\n",
      "Epoch: 2452, Train Loss: 3.148, Validation Loss: 6.066\n",
      "Epoch: 2453, Train Loss: 2.201, Validation Loss: 6.064\n",
      "Epoch: 2454, Train Loss: 3.536, Validation Loss: 5.991\n",
      "Epoch: 2455, Train Loss: 3.444, Validation Loss: 5.995\n",
      "Epoch: 2456, Train Loss: 2.869, Validation Loss: 6.009\n",
      "Epoch: 2457, Train Loss: 3.354, Validation Loss: 5.996\n",
      "Epoch: 2458, Train Loss: 2.434, Validation Loss: 5.993\n",
      "Epoch: 2459, Train Loss: 2.563, Validation Loss: 5.996\n",
      "Epoch: 2460, Train Loss: 3.512, Validation Loss: 6.040\n",
      "Epoch: 2461, Train Loss: 2.937, Validation Loss: 6.059\n",
      "Epoch: 2462, Train Loss: 3.690, Validation Loss: 6.020\n",
      "Epoch: 2463, Train Loss: 2.722, Validation Loss: 6.017\n",
      "Epoch: 2464, Train Loss: 3.052, Validation Loss: 5.977\n",
      "Epoch: 2465, Train Loss: 2.962, Validation Loss: 6.005\n",
      "Epoch: 2466, Train Loss: 3.070, Validation Loss: 6.029\n",
      "Epoch: 2467, Train Loss: 2.387, Validation Loss: 6.019\n",
      "Epoch: 2468, Train Loss: 2.627, Validation Loss: 6.011\n",
      "Epoch: 2469, Train Loss: 2.764, Validation Loss: 6.011\n",
      "Epoch: 2470, Train Loss: 3.009, Validation Loss: 5.998\n",
      "Epoch: 2471, Train Loss: 3.265, Validation Loss: 5.968\n",
      "Epoch: 2472, Train Loss: 2.716, Validation Loss: 5.935\n",
      "Epoch: 2473, Train Loss: 3.029, Validation Loss: 5.925\n",
      "Epoch: 2474, Train Loss: 2.794, Validation Loss: 5.960\n",
      "Epoch: 2475, Train Loss: 2.975, Validation Loss: 5.979\n",
      "Epoch: 2476, Train Loss: 3.213, Validation Loss: 5.952\n",
      "Epoch: 2477, Train Loss: 2.561, Validation Loss: 5.952\n",
      "Epoch: 2478, Train Loss: 2.300, Validation Loss: 5.950\n",
      "Epoch: 2479, Train Loss: 2.980, Validation Loss: 5.935\n",
      "Epoch: 2480, Train Loss: 2.881, Validation Loss: 5.930\n",
      "Epoch: 2481, Train Loss: 2.780, Validation Loss: 5.947\n",
      "Epoch: 2482, Train Loss: 2.335, Validation Loss: 5.973\n",
      "Epoch: 2483, Train Loss: 3.140, Validation Loss: 5.972\n",
      "Epoch: 2484, Train Loss: 3.074, Validation Loss: 5.954\n",
      "Epoch: 2485, Train Loss: 2.777, Validation Loss: 5.986\n",
      "Epoch: 2486, Train Loss: 2.719, Validation Loss: 5.975\n",
      "Epoch: 2487, Train Loss: 2.479, Validation Loss: 5.961\n",
      "Epoch: 2488, Train Loss: 2.852, Validation Loss: 5.988\n",
      "Epoch: 2489, Train Loss: 2.566, Validation Loss: 5.969\n",
      "Epoch: 2490, Train Loss: 2.418, Validation Loss: 5.993\n",
      "Epoch: 2491, Train Loss: 2.349, Validation Loss: 5.962\n",
      "Epoch: 2492, Train Loss: 2.739, Validation Loss: 5.974\n",
      "Epoch: 2493, Train Loss: 3.231, Validation Loss: 6.038\n",
      "Epoch: 2494, Train Loss: 2.585, Validation Loss: 6.011\n",
      "Epoch: 2495, Train Loss: 2.716, Validation Loss: 6.007\n",
      "Epoch: 2496, Train Loss: 3.178, Validation Loss: 5.991\n",
      "Epoch: 2497, Train Loss: 3.101, Validation Loss: 5.989\n",
      "Epoch: 2498, Train Loss: 2.664, Validation Loss: 6.036\n",
      "Epoch: 2499, Train Loss: 3.161, Validation Loss: 6.058\n",
      "Epoch: 2500, Train Loss: 2.638, Validation Loss: 6.028\n",
      "Epoch: 2501, Train Loss: 3.574, Validation Loss: 5.988\n",
      "Epoch: 2502, Train Loss: 2.686, Validation Loss: 5.982\n",
      "Epoch: 2503, Train Loss: 3.111, Validation Loss: 6.018\n",
      "Epoch: 2504, Train Loss: 2.834, Validation Loss: 6.013\n",
      "Epoch: 2505, Train Loss: 3.250, Validation Loss: 5.991\n",
      "Epoch: 2506, Train Loss: 3.039, Validation Loss: 5.970\n",
      "Epoch: 2507, Train Loss: 3.197, Validation Loss: 5.976\n",
      "Epoch: 2508, Train Loss: 2.887, Validation Loss: 5.960\n",
      "Epoch: 2509, Train Loss: 2.936, Validation Loss: 5.985\n",
      "Epoch: 2510, Train Loss: 3.256, Validation Loss: 5.969\n",
      "Epoch: 2511, Train Loss: 2.617, Validation Loss: 5.921\n",
      "Epoch: 2512, Train Loss: 2.716, Validation Loss: 5.887\n",
      "Epoch: 2513, Train Loss: 3.386, Validation Loss: 5.902\n",
      "Epoch: 2514, Train Loss: 3.191, Validation Loss: 5.915\n",
      "Epoch: 2515, Train Loss: 2.491, Validation Loss: 5.945\n",
      "Epoch: 2516, Train Loss: 2.353, Validation Loss: 5.952\n",
      "Epoch: 2517, Train Loss: 2.481, Validation Loss: 5.960\n",
      "Epoch: 2518, Train Loss: 2.842, Validation Loss: 5.971\n",
      "Epoch: 2519, Train Loss: 2.545, Validation Loss: 5.966\n",
      "Epoch: 2520, Train Loss: 3.262, Validation Loss: 5.969\n",
      "Epoch: 2521, Train Loss: 3.158, Validation Loss: 5.969\n",
      "Epoch: 2522, Train Loss: 3.357, Validation Loss: 5.947\n",
      "Epoch: 2523, Train Loss: 3.229, Validation Loss: 5.941\n",
      "Epoch: 2524, Train Loss: 2.923, Validation Loss: 5.935\n",
      "Epoch: 2525, Train Loss: 2.144, Validation Loss: 5.949\n",
      "Epoch: 2526, Train Loss: 2.953, Validation Loss: 5.961\n",
      "Epoch: 2527, Train Loss: 3.236, Validation Loss: 5.983\n",
      "Epoch: 2528, Train Loss: 2.551, Validation Loss: 6.000\n",
      "Epoch: 2529, Train Loss: 3.066, Validation Loss: 5.976\n",
      "Epoch: 2530, Train Loss: 2.980, Validation Loss: 5.954\n",
      "Epoch: 2531, Train Loss: 3.055, Validation Loss: 5.966\n",
      "Epoch: 2532, Train Loss: 2.819, Validation Loss: 5.970\n",
      "Epoch: 2533, Train Loss: 2.829, Validation Loss: 5.985\n",
      "Epoch: 2534, Train Loss: 2.476, Validation Loss: 5.967\n",
      "Epoch: 2535, Train Loss: 2.628, Validation Loss: 5.961\n",
      "Epoch: 2536, Train Loss: 2.346, Validation Loss: 5.980\n",
      "Epoch: 2537, Train Loss: 3.317, Validation Loss: 6.010\n",
      "Epoch: 2538, Train Loss: 2.808, Validation Loss: 5.969\n",
      "Epoch: 2539, Train Loss: 2.767, Validation Loss: 5.954\n",
      "Epoch: 2540, Train Loss: 3.201, Validation Loss: 5.964\n",
      "Epoch: 2541, Train Loss: 3.575, Validation Loss: 5.967\n",
      "Epoch: 2542, Train Loss: 2.621, Validation Loss: 5.964\n",
      "Epoch: 2543, Train Loss: 3.127, Validation Loss: 5.991\n",
      "Epoch: 2544, Train Loss: 2.411, Validation Loss: 5.962\n",
      "Epoch: 2545, Train Loss: 2.309, Validation Loss: 5.996\n",
      "Epoch: 2546, Train Loss: 2.736, Validation Loss: 5.955\n",
      "Epoch: 2547, Train Loss: 3.212, Validation Loss: 5.950\n",
      "Epoch: 2548, Train Loss: 2.377, Validation Loss: 5.963\n",
      "Epoch: 2549, Train Loss: 2.171, Validation Loss: 5.935\n",
      "Epoch: 2550, Train Loss: 2.823, Validation Loss: 5.963\n",
      "Epoch: 2551, Train Loss: 3.374, Validation Loss: 5.961\n",
      "Epoch: 2552, Train Loss: 3.182, Validation Loss: 5.940\n",
      "Epoch: 2553, Train Loss: 2.938, Validation Loss: 5.938\n",
      "Epoch: 2554, Train Loss: 2.817, Validation Loss: 5.939\n",
      "Epoch: 2555, Train Loss: 2.929, Validation Loss: 5.952\n",
      "Epoch: 2556, Train Loss: 3.094, Validation Loss: 5.971\n",
      "Epoch: 2557, Train Loss: 3.495, Validation Loss: 6.029\n",
      "Epoch: 2558, Train Loss: 3.012, Validation Loss: 5.996\n",
      "Epoch: 2559, Train Loss: 2.846, Validation Loss: 5.997\n",
      "Epoch: 2560, Train Loss: 2.520, Validation Loss: 5.983\n",
      "Epoch: 2561, Train Loss: 3.074, Validation Loss: 5.990\n",
      "Epoch: 2562, Train Loss: 2.614, Validation Loss: 5.973\n",
      "Epoch: 2563, Train Loss: 2.727, Validation Loss: 5.991\n",
      "Epoch: 2564, Train Loss: 3.174, Validation Loss: 5.997\n",
      "Epoch: 2565, Train Loss: 2.629, Validation Loss: 5.965\n",
      "Epoch: 2566, Train Loss: 2.968, Validation Loss: 6.005\n",
      "Epoch: 2567, Train Loss: 2.848, Validation Loss: 6.006\n",
      "Epoch: 2568, Train Loss: 2.556, Validation Loss: 5.995\n",
      "Epoch: 2569, Train Loss: 2.833, Validation Loss: 5.997\n",
      "Epoch: 2570, Train Loss: 3.110, Validation Loss: 5.997\n",
      "Epoch: 2571, Train Loss: 2.670, Validation Loss: 5.974\n",
      "Epoch: 2572, Train Loss: 3.102, Validation Loss: 6.040\n",
      "Epoch: 2573, Train Loss: 3.310, Validation Loss: 6.045\n",
      "Epoch: 2574, Train Loss: 3.077, Validation Loss: 6.024\n",
      "Epoch: 2575, Train Loss: 2.434, Validation Loss: 6.013\n",
      "Epoch: 2576, Train Loss: 2.379, Validation Loss: 5.990\n",
      "Epoch: 2577, Train Loss: 3.722, Validation Loss: 5.955\n",
      "Epoch: 2578, Train Loss: 2.854, Validation Loss: 5.968\n",
      "Epoch: 2579, Train Loss: 2.948, Validation Loss: 5.934\n",
      "Epoch: 2580, Train Loss: 2.877, Validation Loss: 5.948\n",
      "Epoch: 2581, Train Loss: 3.006, Validation Loss: 5.929\n",
      "Epoch: 2582, Train Loss: 2.472, Validation Loss: 5.901\n",
      "Epoch: 2583, Train Loss: 2.605, Validation Loss: 5.924\n",
      "Epoch: 2584, Train Loss: 2.686, Validation Loss: 5.965\n",
      "Epoch: 2585, Train Loss: 2.453, Validation Loss: 5.975\n",
      "Epoch: 2586, Train Loss: 3.745, Validation Loss: 5.969\n",
      "Epoch: 2587, Train Loss: 3.294, Validation Loss: 5.947\n",
      "Epoch: 2588, Train Loss: 2.924, Validation Loss: 5.903\n",
      "Epoch: 2589, Train Loss: 2.693, Validation Loss: 5.908\n",
      "Epoch: 2590, Train Loss: 3.248, Validation Loss: 5.945\n",
      "Epoch: 2591, Train Loss: 2.853, Validation Loss: 5.906\n",
      "Epoch: 2592, Train Loss: 2.145, Validation Loss: 5.894\n",
      "Epoch: 2593, Train Loss: 2.983, Validation Loss: 5.861\n",
      "Epoch: 2594, Train Loss: 2.569, Validation Loss: 5.874\n",
      "Epoch: 2595, Train Loss: 2.433, Validation Loss: 5.873\n",
      "Epoch: 2596, Train Loss: 2.684, Validation Loss: 5.898\n",
      "Epoch: 2597, Train Loss: 2.767, Validation Loss: 5.931\n",
      "Epoch: 2598, Train Loss: 3.939, Validation Loss: 5.949\n",
      "Epoch: 2599, Train Loss: 3.058, Validation Loss: 5.943\n",
      "Epoch: 2600, Train Loss: 2.530, Validation Loss: 5.977\n",
      "Epoch: 2601, Train Loss: 2.611, Validation Loss: 5.961\n",
      "Epoch: 2602, Train Loss: 2.670, Validation Loss: 5.997\n",
      "Epoch: 2603, Train Loss: 3.028, Validation Loss: 5.983\n",
      "Epoch: 2604, Train Loss: 3.210, Validation Loss: 5.964\n",
      "Epoch: 2605, Train Loss: 2.374, Validation Loss: 5.961\n",
      "Epoch: 2606, Train Loss: 2.640, Validation Loss: 5.990\n",
      "Epoch: 2607, Train Loss: 2.443, Validation Loss: 5.981\n",
      "Epoch: 2608, Train Loss: 3.147, Validation Loss: 5.998\n",
      "Epoch: 2609, Train Loss: 2.740, Validation Loss: 5.987\n",
      "Epoch: 2610, Train Loss: 2.424, Validation Loss: 6.035\n",
      "Epoch: 2611, Train Loss: 2.731, Validation Loss: 6.014\n",
      "Epoch: 2612, Train Loss: 2.526, Validation Loss: 6.024\n",
      "Epoch: 2613, Train Loss: 2.540, Validation Loss: 6.018\n",
      "Epoch: 2614, Train Loss: 2.850, Validation Loss: 5.980\n",
      "Epoch: 2615, Train Loss: 2.853, Validation Loss: 5.984\n",
      "Epoch: 2616, Train Loss: 2.659, Validation Loss: 6.006\n",
      "Epoch: 2617, Train Loss: 2.330, Validation Loss: 5.977\n",
      "Epoch: 2618, Train Loss: 2.665, Validation Loss: 6.007\n",
      "Epoch: 2619, Train Loss: 2.837, Validation Loss: 5.998\n",
      "Epoch: 2620, Train Loss: 2.594, Validation Loss: 5.997\n",
      "Epoch: 2621, Train Loss: 2.856, Validation Loss: 5.980\n",
      "Epoch: 2622, Train Loss: 2.636, Validation Loss: 5.985\n",
      "Epoch: 2623, Train Loss: 2.732, Validation Loss: 5.939\n",
      "Epoch: 2624, Train Loss: 2.576, Validation Loss: 5.958\n",
      "Epoch: 2625, Train Loss: 2.236, Validation Loss: 5.977\n",
      "Epoch: 2626, Train Loss: 2.382, Validation Loss: 5.973\n",
      "Epoch: 2627, Train Loss: 2.378, Validation Loss: 5.972\n",
      "Epoch: 2628, Train Loss: 2.364, Validation Loss: 5.978\n",
      "Epoch: 2629, Train Loss: 3.263, Validation Loss: 5.995\n",
      "Epoch: 2630, Train Loss: 3.102, Validation Loss: 5.989\n",
      "Epoch: 2631, Train Loss: 2.481, Validation Loss: 6.015\n",
      "Epoch: 2632, Train Loss: 2.205, Validation Loss: 6.045\n",
      "Epoch: 2633, Train Loss: 3.059, Validation Loss: 6.042\n",
      "Epoch: 2634, Train Loss: 3.157, Validation Loss: 6.023\n",
      "Epoch: 2635, Train Loss: 2.692, Validation Loss: 6.018\n",
      "Epoch: 2636, Train Loss: 2.419, Validation Loss: 6.020\n",
      "Epoch: 2637, Train Loss: 2.548, Validation Loss: 6.015\n",
      "Epoch: 2638, Train Loss: 2.714, Validation Loss: 6.030\n",
      "Epoch: 2639, Train Loss: 2.518, Validation Loss: 6.030\n",
      "Epoch: 2640, Train Loss: 2.349, Validation Loss: 6.039\n",
      "Epoch: 2641, Train Loss: 2.827, Validation Loss: 6.048\n",
      "Epoch: 2642, Train Loss: 2.643, Validation Loss: 6.027\n",
      "Epoch: 2643, Train Loss: 2.512, Validation Loss: 6.009\n",
      "Epoch: 2644, Train Loss: 2.690, Validation Loss: 5.998\n",
      "Epoch: 2645, Train Loss: 2.552, Validation Loss: 5.989\n",
      "Epoch: 2646, Train Loss: 2.625, Validation Loss: 6.006\n",
      "Epoch: 2647, Train Loss: 2.817, Validation Loss: 6.015\n",
      "Epoch: 2648, Train Loss: 3.523, Validation Loss: 6.002\n",
      "Epoch: 2649, Train Loss: 2.888, Validation Loss: 6.012\n",
      "Epoch: 2650, Train Loss: 3.311, Validation Loss: 6.039\n",
      "Epoch: 2651, Train Loss: 2.417, Validation Loss: 6.039\n",
      "Epoch: 2652, Train Loss: 3.227, Validation Loss: 6.018\n",
      "Epoch: 2653, Train Loss: 2.541, Validation Loss: 5.994\n",
      "Epoch: 2654, Train Loss: 2.251, Validation Loss: 5.981\n",
      "Epoch: 2655, Train Loss: 2.853, Validation Loss: 6.003\n",
      "Epoch: 2656, Train Loss: 2.407, Validation Loss: 5.953\n",
      "Epoch: 2657, Train Loss: 3.384, Validation Loss: 5.989\n",
      "Epoch: 2658, Train Loss: 2.431, Validation Loss: 5.968\n",
      "Epoch: 2659, Train Loss: 3.409, Validation Loss: 5.968\n",
      "Epoch: 2660, Train Loss: 2.540, Validation Loss: 5.965\n",
      "Epoch: 2661, Train Loss: 2.393, Validation Loss: 5.991\n",
      "Epoch: 2662, Train Loss: 3.245, Validation Loss: 6.049\n",
      "Epoch: 2663, Train Loss: 2.455, Validation Loss: 6.023\n",
      "Epoch: 2664, Train Loss: 3.001, Validation Loss: 6.046\n",
      "Epoch: 2665, Train Loss: 2.442, Validation Loss: 6.039\n",
      "Epoch: 2666, Train Loss: 2.249, Validation Loss: 5.993\n",
      "Epoch: 2667, Train Loss: 2.706, Validation Loss: 6.007\n",
      "Epoch: 2668, Train Loss: 2.790, Validation Loss: 6.026\n",
      "Epoch: 2669, Train Loss: 2.874, Validation Loss: 6.015\n",
      "Epoch: 2670, Train Loss: 2.348, Validation Loss: 6.033\n",
      "Epoch: 2671, Train Loss: 3.253, Validation Loss: 5.970\n",
      "Epoch: 2672, Train Loss: 2.715, Validation Loss: 5.985\n",
      "Epoch: 2673, Train Loss: 2.794, Validation Loss: 5.973\n",
      "Epoch: 2674, Train Loss: 2.220, Validation Loss: 5.963\n",
      "Epoch: 2675, Train Loss: 3.297, Validation Loss: 5.910\n",
      "Epoch: 2676, Train Loss: 2.865, Validation Loss: 5.935\n",
      "Epoch: 2677, Train Loss: 2.745, Validation Loss: 5.913\n",
      "Epoch: 2678, Train Loss: 2.441, Validation Loss: 5.910\n",
      "Epoch: 2679, Train Loss: 2.713, Validation Loss: 5.938\n",
      "Epoch: 2680, Train Loss: 2.553, Validation Loss: 5.920\n",
      "Epoch: 2681, Train Loss: 2.795, Validation Loss: 5.936\n",
      "Epoch: 2682, Train Loss: 2.179, Validation Loss: 5.907\n",
      "Epoch: 2683, Train Loss: 2.059, Validation Loss: 5.902\n",
      "Epoch: 2684, Train Loss: 3.894, Validation Loss: 5.872\n",
      "Epoch: 2685, Train Loss: 3.089, Validation Loss: 5.922\n",
      "Epoch: 2686, Train Loss: 2.789, Validation Loss: 5.916\n",
      "Epoch: 2687, Train Loss: 2.179, Validation Loss: 5.909\n",
      "Epoch: 2688, Train Loss: 3.483, Validation Loss: 5.954\n",
      "Epoch: 2689, Train Loss: 2.547, Validation Loss: 5.971\n",
      "Epoch: 2690, Train Loss: 2.739, Validation Loss: 5.963\n",
      "Epoch: 2691, Train Loss: 3.093, Validation Loss: 5.934\n",
      "Epoch: 2692, Train Loss: 2.455, Validation Loss: 5.928\n",
      "Epoch: 2693, Train Loss: 2.786, Validation Loss: 5.923\n",
      "Epoch: 2694, Train Loss: 2.441, Validation Loss: 5.937\n",
      "Epoch: 2695, Train Loss: 2.461, Validation Loss: 5.908\n",
      "Epoch: 2696, Train Loss: 2.387, Validation Loss: 5.897\n",
      "Epoch: 2697, Train Loss: 2.531, Validation Loss: 5.917\n",
      "Epoch: 2698, Train Loss: 2.311, Validation Loss: 5.911\n",
      "Epoch: 2699, Train Loss: 2.965, Validation Loss: 5.899\n",
      "Epoch: 2700, Train Loss: 2.630, Validation Loss: 5.882\n",
      "Epoch: 2701, Train Loss: 3.121, Validation Loss: 5.878\n",
      "Epoch: 2702, Train Loss: 2.736, Validation Loss: 5.857\n",
      "Epoch: 2703, Train Loss: 2.850, Validation Loss: 5.898\n",
      "Epoch: 2704, Train Loss: 2.898, Validation Loss: 5.906\n",
      "Epoch: 2705, Train Loss: 3.083, Validation Loss: 5.921\n",
      "Epoch: 2706, Train Loss: 3.001, Validation Loss: 5.940\n",
      "Epoch: 2707, Train Loss: 2.434, Validation Loss: 5.885\n",
      "Epoch: 2708, Train Loss: 2.935, Validation Loss: 5.889\n",
      "Epoch: 2709, Train Loss: 2.102, Validation Loss: 5.880\n",
      "Epoch: 2710, Train Loss: 2.654, Validation Loss: 5.902\n",
      "Epoch: 2711, Train Loss: 2.942, Validation Loss: 5.917\n",
      "Epoch: 2712, Train Loss: 2.761, Validation Loss: 5.898\n",
      "Epoch: 2713, Train Loss: 2.635, Validation Loss: 5.897\n",
      "Epoch: 2714, Train Loss: 2.721, Validation Loss: 5.912\n",
      "Epoch: 2715, Train Loss: 2.761, Validation Loss: 5.898\n",
      "Epoch: 2716, Train Loss: 2.254, Validation Loss: 5.900\n",
      "Epoch: 2717, Train Loss: 3.053, Validation Loss: 5.906\n",
      "Epoch: 2718, Train Loss: 2.991, Validation Loss: 5.904\n",
      "Epoch: 2719, Train Loss: 2.599, Validation Loss: 5.880\n",
      "Epoch: 2720, Train Loss: 3.332, Validation Loss: 5.896\n",
      "Epoch: 2721, Train Loss: 3.344, Validation Loss: 5.894\n",
      "Epoch: 2722, Train Loss: 2.852, Validation Loss: 5.889\n",
      "Epoch: 2723, Train Loss: 2.863, Validation Loss: 5.872\n",
      "Epoch: 2724, Train Loss: 3.437, Validation Loss: 5.870\n",
      "Epoch: 2725, Train Loss: 2.485, Validation Loss: 5.889\n",
      "Epoch: 2726, Train Loss: 3.110, Validation Loss: 5.894\n",
      "Epoch: 2727, Train Loss: 2.879, Validation Loss: 5.939\n",
      "Epoch: 2728, Train Loss: 2.389, Validation Loss: 5.943\n",
      "Epoch: 2729, Train Loss: 3.453, Validation Loss: 5.946\n",
      "Epoch: 2730, Train Loss: 2.822, Validation Loss: 5.971\n",
      "Epoch: 2731, Train Loss: 2.634, Validation Loss: 5.946\n",
      "Epoch: 2732, Train Loss: 3.388, Validation Loss: 5.928\n",
      "Epoch: 2733, Train Loss: 2.695, Validation Loss: 5.919\n",
      "Epoch: 2734, Train Loss: 2.622, Validation Loss: 5.919\n",
      "Epoch: 2735, Train Loss: 2.800, Validation Loss: 5.933\n",
      "Epoch: 2736, Train Loss: 3.031, Validation Loss: 5.926\n",
      "Epoch: 2737, Train Loss: 2.759, Validation Loss: 5.946\n",
      "Epoch: 2738, Train Loss: 2.244, Validation Loss: 5.939\n",
      "Epoch: 2739, Train Loss: 2.231, Validation Loss: 5.941\n",
      "Epoch: 2740, Train Loss: 2.874, Validation Loss: 5.955\n",
      "Epoch: 2741, Train Loss: 2.393, Validation Loss: 5.929\n",
      "Epoch: 2742, Train Loss: 2.727, Validation Loss: 5.897\n",
      "Epoch: 2743, Train Loss: 2.433, Validation Loss: 5.847\n",
      "Epoch: 2744, Train Loss: 3.115, Validation Loss: 5.871\n",
      "Epoch: 2745, Train Loss: 3.191, Validation Loss: 5.908\n",
      "Epoch: 2746, Train Loss: 2.725, Validation Loss: 5.875\n",
      "Epoch: 2747, Train Loss: 3.052, Validation Loss: 5.866\n",
      "Epoch: 2748, Train Loss: 2.374, Validation Loss: 5.886\n",
      "Epoch: 2749, Train Loss: 2.396, Validation Loss: 5.918\n",
      "Epoch: 2750, Train Loss: 2.829, Validation Loss: 5.881\n",
      "Epoch: 2751, Train Loss: 2.793, Validation Loss: 5.871\n",
      "Epoch: 2752, Train Loss: 2.961, Validation Loss: 5.868\n",
      "Epoch: 2753, Train Loss: 2.126, Validation Loss: 5.875\n",
      "Epoch: 2754, Train Loss: 2.373, Validation Loss: 5.894\n",
      "Epoch: 2755, Train Loss: 2.589, Validation Loss: 5.916\n",
      "Epoch: 2756, Train Loss: 2.486, Validation Loss: 5.899\n",
      "Epoch: 2757, Train Loss: 2.646, Validation Loss: 5.937\n",
      "Epoch: 2758, Train Loss: 2.594, Validation Loss: 5.949\n",
      "Epoch: 2759, Train Loss: 2.312, Validation Loss: 5.913\n",
      "Epoch: 2760, Train Loss: 2.374, Validation Loss: 5.920\n",
      "Epoch: 2761, Train Loss: 2.498, Validation Loss: 5.909\n",
      "Epoch: 2762, Train Loss: 2.521, Validation Loss: 5.891\n",
      "Epoch: 2763, Train Loss: 2.362, Validation Loss: 5.887\n",
      "Epoch: 2764, Train Loss: 2.588, Validation Loss: 5.876\n",
      "Epoch: 2765, Train Loss: 2.638, Validation Loss: 5.865\n",
      "Epoch: 2766, Train Loss: 3.110, Validation Loss: 5.866\n",
      "Epoch: 2767, Train Loss: 2.949, Validation Loss: 5.913\n",
      "Epoch: 2768, Train Loss: 3.019, Validation Loss: 5.905\n",
      "Epoch: 2769, Train Loss: 3.244, Validation Loss: 5.856\n",
      "Epoch: 2770, Train Loss: 2.480, Validation Loss: 5.870\n",
      "Epoch: 2771, Train Loss: 2.483, Validation Loss: 5.884\n",
      "Epoch: 2772, Train Loss: 2.567, Validation Loss: 5.887\n",
      "Epoch: 2773, Train Loss: 3.959, Validation Loss: 5.909\n",
      "Epoch: 2774, Train Loss: 2.732, Validation Loss: 5.883\n",
      "Epoch: 2775, Train Loss: 2.432, Validation Loss: 5.878\n",
      "Epoch: 2776, Train Loss: 3.147, Validation Loss: 5.863\n",
      "Epoch: 2777, Train Loss: 2.720, Validation Loss: 5.881\n",
      "Epoch: 2778, Train Loss: 2.995, Validation Loss: 5.869\n",
      "Epoch: 2779, Train Loss: 2.833, Validation Loss: 5.890\n",
      "Epoch: 2780, Train Loss: 3.176, Validation Loss: 5.946\n",
      "Epoch: 2781, Train Loss: 2.545, Validation Loss: 5.913\n",
      "Epoch: 2782, Train Loss: 2.340, Validation Loss: 5.922\n",
      "Epoch: 2783, Train Loss: 2.453, Validation Loss: 5.894\n",
      "Epoch: 2784, Train Loss: 2.208, Validation Loss: 5.903\n",
      "Epoch: 2785, Train Loss: 2.191, Validation Loss: 5.912\n",
      "Epoch: 2786, Train Loss: 2.554, Validation Loss: 5.936\n",
      "Epoch: 2787, Train Loss: 2.937, Validation Loss: 5.866\n",
      "Epoch: 2788, Train Loss: 2.656, Validation Loss: 5.899\n",
      "Epoch: 2789, Train Loss: 2.436, Validation Loss: 5.862\n",
      "Epoch: 2790, Train Loss: 2.520, Validation Loss: 5.945\n",
      "Epoch: 2791, Train Loss: 2.862, Validation Loss: 5.914\n",
      "Epoch: 2792, Train Loss: 2.642, Validation Loss: 5.910\n",
      "Epoch: 2793, Train Loss: 2.337, Validation Loss: 5.902\n",
      "Epoch: 2794, Train Loss: 2.839, Validation Loss: 5.872\n",
      "Epoch: 2795, Train Loss: 2.511, Validation Loss: 5.873\n",
      "Epoch: 2796, Train Loss: 2.604, Validation Loss: 5.921\n",
      "Epoch: 2797, Train Loss: 2.536, Validation Loss: 5.902\n",
      "Epoch: 2798, Train Loss: 3.126, Validation Loss: 5.926\n",
      "Epoch: 2799, Train Loss: 2.619, Validation Loss: 5.930\n",
      "Epoch: 2800, Train Loss: 2.485, Validation Loss: 5.909\n",
      "Epoch: 2801, Train Loss: 2.699, Validation Loss: 5.910\n",
      "Epoch: 2802, Train Loss: 2.975, Validation Loss: 5.901\n",
      "Epoch: 2803, Train Loss: 2.724, Validation Loss: 5.926\n",
      "Epoch: 2804, Train Loss: 2.925, Validation Loss: 5.917\n",
      "Epoch: 2805, Train Loss: 2.616, Validation Loss: 5.900\n",
      "Epoch: 2806, Train Loss: 2.589, Validation Loss: 5.946\n",
      "Epoch: 2807, Train Loss: 2.966, Validation Loss: 5.939\n",
      "Epoch: 2808, Train Loss: 2.870, Validation Loss: 5.916\n",
      "Epoch: 2809, Train Loss: 2.576, Validation Loss: 5.894\n",
      "Epoch: 2810, Train Loss: 2.643, Validation Loss: 5.935\n",
      "Epoch: 2811, Train Loss: 2.384, Validation Loss: 5.899\n",
      "Epoch: 2812, Train Loss: 2.511, Validation Loss: 5.900\n",
      "Epoch: 2813, Train Loss: 2.769, Validation Loss: 5.947\n",
      "Epoch: 2814, Train Loss: 2.500, Validation Loss: 5.950\n",
      "Epoch: 2815, Train Loss: 2.987, Validation Loss: 5.940\n",
      "Epoch: 2816, Train Loss: 2.754, Validation Loss: 5.923\n",
      "Epoch: 2817, Train Loss: 2.219, Validation Loss: 5.924\n",
      "Epoch: 2818, Train Loss: 2.746, Validation Loss: 5.953\n",
      "Epoch: 2819, Train Loss: 2.152, Validation Loss: 5.935\n",
      "Epoch: 2820, Train Loss: 2.603, Validation Loss: 5.989\n",
      "Epoch: 2821, Train Loss: 2.511, Validation Loss: 6.008\n",
      "Epoch: 2822, Train Loss: 2.712, Validation Loss: 5.983\n",
      "Epoch: 2823, Train Loss: 3.093, Validation Loss: 5.988\n",
      "Epoch: 2824, Train Loss: 2.656, Validation Loss: 5.934\n",
      "Epoch: 2825, Train Loss: 2.614, Validation Loss: 5.942\n",
      "Epoch: 2826, Train Loss: 2.395, Validation Loss: 5.943\n",
      "Epoch: 2827, Train Loss: 3.070, Validation Loss: 5.971\n",
      "Epoch: 2828, Train Loss: 2.139, Validation Loss: 5.971\n",
      "Epoch: 2829, Train Loss: 2.715, Validation Loss: 5.984\n",
      "Epoch: 2830, Train Loss: 2.871, Validation Loss: 5.963\n",
      "Epoch: 2831, Train Loss: 2.803, Validation Loss: 5.944\n",
      "Epoch: 2832, Train Loss: 3.203, Validation Loss: 5.984\n",
      "Epoch: 2833, Train Loss: 2.766, Validation Loss: 6.013\n",
      "Epoch: 2834, Train Loss: 2.260, Validation Loss: 5.999\n",
      "Epoch: 2835, Train Loss: 2.618, Validation Loss: 5.963\n",
      "Epoch: 2836, Train Loss: 2.035, Validation Loss: 5.977\n",
      "Epoch: 2837, Train Loss: 2.709, Validation Loss: 5.978\n",
      "Epoch: 2838, Train Loss: 2.792, Validation Loss: 5.949\n",
      "Epoch: 2839, Train Loss: 2.599, Validation Loss: 5.955\n",
      "Epoch: 2840, Train Loss: 2.519, Validation Loss: 5.962\n",
      "Epoch: 2841, Train Loss: 2.921, Validation Loss: 5.969\n",
      "Epoch: 2842, Train Loss: 2.748, Validation Loss: 5.943\n",
      "Epoch: 2843, Train Loss: 2.952, Validation Loss: 5.941\n",
      "Epoch: 2844, Train Loss: 2.578, Validation Loss: 5.960\n",
      "Epoch: 2845, Train Loss: 2.577, Validation Loss: 5.938\n",
      "Epoch: 2846, Train Loss: 2.708, Validation Loss: 5.955\n",
      "Epoch: 2847, Train Loss: 3.122, Validation Loss: 5.961\n",
      "Epoch: 2848, Train Loss: 3.122, Validation Loss: 5.939\n",
      "Epoch: 2849, Train Loss: 2.981, Validation Loss: 5.967\n",
      "Epoch: 2850, Train Loss: 2.167, Validation Loss: 5.935\n",
      "Epoch: 2851, Train Loss: 2.253, Validation Loss: 5.904\n",
      "Epoch: 2852, Train Loss: 2.280, Validation Loss: 5.906\n",
      "Epoch: 2853, Train Loss: 2.585, Validation Loss: 5.890\n",
      "Epoch: 2854, Train Loss: 2.570, Validation Loss: 5.859\n",
      "Epoch: 2855, Train Loss: 2.283, Validation Loss: 5.899\n",
      "Epoch: 2856, Train Loss: 2.341, Validation Loss: 5.945\n",
      "Epoch: 2857, Train Loss: 2.519, Validation Loss: 5.917\n",
      "Epoch: 2858, Train Loss: 2.146, Validation Loss: 5.917\n",
      "Epoch: 2859, Train Loss: 2.381, Validation Loss: 5.945\n",
      "Epoch: 2860, Train Loss: 2.665, Validation Loss: 5.932\n",
      "Epoch: 2861, Train Loss: 2.901, Validation Loss: 5.945\n",
      "Epoch: 2862, Train Loss: 2.994, Validation Loss: 5.906\n",
      "Epoch: 2863, Train Loss: 2.736, Validation Loss: 5.909\n",
      "Epoch: 2864, Train Loss: 2.080, Validation Loss: 5.895\n",
      "Epoch: 2865, Train Loss: 1.949, Validation Loss: 5.891\n",
      "Epoch: 2866, Train Loss: 2.542, Validation Loss: 5.891\n",
      "Epoch: 2867, Train Loss: 2.345, Validation Loss: 5.882\n",
      "Epoch: 2868, Train Loss: 2.355, Validation Loss: 5.903\n",
      "Epoch: 2869, Train Loss: 2.830, Validation Loss: 5.909\n",
      "Epoch: 2870, Train Loss: 3.012, Validation Loss: 5.912\n",
      "Epoch: 2871, Train Loss: 2.882, Validation Loss: 5.890\n",
      "Epoch: 2872, Train Loss: 2.276, Validation Loss: 5.885\n",
      "Epoch: 2873, Train Loss: 2.501, Validation Loss: 5.897\n",
      "Epoch: 2874, Train Loss: 2.584, Validation Loss: 5.879\n",
      "Epoch: 2875, Train Loss: 2.807, Validation Loss: 5.911\n",
      "Epoch: 2876, Train Loss: 2.318, Validation Loss: 5.894\n",
      "Epoch: 2877, Train Loss: 2.263, Validation Loss: 5.900\n",
      "Epoch: 2878, Train Loss: 2.253, Validation Loss: 5.911\n",
      "Epoch: 2879, Train Loss: 2.079, Validation Loss: 5.926\n",
      "Epoch: 2880, Train Loss: 2.686, Validation Loss: 5.916\n",
      "Epoch: 2881, Train Loss: 2.864, Validation Loss: 5.895\n",
      "Epoch: 2882, Train Loss: 2.727, Validation Loss: 5.897\n",
      "Epoch: 2883, Train Loss: 2.683, Validation Loss: 5.867\n",
      "Epoch: 2884, Train Loss: 3.222, Validation Loss: 5.894\n",
      "Epoch: 2885, Train Loss: 3.695, Validation Loss: 5.894\n",
      "Epoch: 2886, Train Loss: 2.702, Validation Loss: 5.879\n",
      "Epoch: 2887, Train Loss: 2.101, Validation Loss: 5.915\n",
      "Epoch: 2888, Train Loss: 2.708, Validation Loss: 5.907\n",
      "Epoch: 2889, Train Loss: 2.480, Validation Loss: 5.929\n",
      "Epoch: 2890, Train Loss: 2.190, Validation Loss: 5.923\n",
      "Epoch: 2891, Train Loss: 2.983, Validation Loss: 5.918\n",
      "Epoch: 2892, Train Loss: 2.828, Validation Loss: 5.937\n",
      "Epoch: 2893, Train Loss: 2.638, Validation Loss: 5.909\n",
      "Epoch: 2894, Train Loss: 3.005, Validation Loss: 5.945\n",
      "Epoch: 2895, Train Loss: 2.580, Validation Loss: 5.907\n",
      "Epoch: 2896, Train Loss: 2.748, Validation Loss: 5.889\n",
      "Epoch: 2897, Train Loss: 2.174, Validation Loss: 5.896\n",
      "Epoch: 2898, Train Loss: 2.839, Validation Loss: 5.938\n",
      "Epoch: 2899, Train Loss: 2.178, Validation Loss: 5.931\n",
      "Epoch: 2900, Train Loss: 2.407, Validation Loss: 5.896\n",
      "Epoch: 2901, Train Loss: 2.180, Validation Loss: 5.911\n",
      "Epoch: 2902, Train Loss: 2.535, Validation Loss: 5.910\n",
      "Epoch: 2903, Train Loss: 2.343, Validation Loss: 5.925\n",
      "Epoch: 2904, Train Loss: 2.115, Validation Loss: 5.973\n",
      "Epoch: 2905, Train Loss: 2.230, Validation Loss: 5.948\n",
      "Epoch: 2906, Train Loss: 2.723, Validation Loss: 5.949\n",
      "Epoch: 2907, Train Loss: 2.648, Validation Loss: 5.906\n",
      "Epoch: 2908, Train Loss: 2.504, Validation Loss: 5.895\n",
      "Epoch: 2909, Train Loss: 2.871, Validation Loss: 5.886\n",
      "Epoch: 2910, Train Loss: 2.293, Validation Loss: 5.862\n",
      "Epoch: 2911, Train Loss: 2.130, Validation Loss: 5.915\n",
      "Epoch: 2912, Train Loss: 2.665, Validation Loss: 5.889\n",
      "Epoch: 2913, Train Loss: 2.131, Validation Loss: 5.902\n",
      "Epoch: 2914, Train Loss: 3.040, Validation Loss: 5.915\n",
      "Epoch: 2915, Train Loss: 2.637, Validation Loss: 5.897\n",
      "Epoch: 2916, Train Loss: 2.609, Validation Loss: 5.899\n",
      "Epoch: 2917, Train Loss: 2.381, Validation Loss: 5.888\n",
      "Epoch: 2918, Train Loss: 2.610, Validation Loss: 5.896\n",
      "Epoch: 2919, Train Loss: 3.037, Validation Loss: 5.905\n",
      "Epoch: 2920, Train Loss: 2.633, Validation Loss: 5.875\n",
      "Epoch: 2921, Train Loss: 2.601, Validation Loss: 5.924\n",
      "Epoch: 2922, Train Loss: 2.505, Validation Loss: 5.894\n",
      "Epoch: 2923, Train Loss: 2.609, Validation Loss: 5.889\n",
      "Epoch: 2924, Train Loss: 3.322, Validation Loss: 5.896\n",
      "Epoch: 2925, Train Loss: 2.894, Validation Loss: 5.922\n",
      "Epoch: 2926, Train Loss: 2.975, Validation Loss: 5.967\n",
      "Epoch: 2927, Train Loss: 2.609, Validation Loss: 5.915\n",
      "Epoch: 2928, Train Loss: 2.359, Validation Loss: 5.900\n",
      "Epoch: 2929, Train Loss: 2.699, Validation Loss: 5.867\n",
      "Epoch: 2930, Train Loss: 2.348, Validation Loss: 5.868\n",
      "Epoch: 2931, Train Loss: 2.478, Validation Loss: 5.889\n",
      "Epoch: 2932, Train Loss: 2.688, Validation Loss: 5.921\n",
      "Epoch: 2933, Train Loss: 2.737, Validation Loss: 5.926\n",
      "Epoch: 2934, Train Loss: 2.319, Validation Loss: 5.901\n",
      "Epoch: 2935, Train Loss: 2.727, Validation Loss: 5.932\n",
      "Epoch: 2936, Train Loss: 2.154, Validation Loss: 5.955\n",
      "Epoch: 2937, Train Loss: 2.786, Validation Loss: 5.954\n",
      "Epoch: 2938, Train Loss: 2.471, Validation Loss: 5.880\n",
      "Epoch: 2939, Train Loss: 2.127, Validation Loss: 5.914\n",
      "Epoch: 2940, Train Loss: 2.040, Validation Loss: 5.928\n",
      "Epoch: 2941, Train Loss: 2.336, Validation Loss: 5.923\n",
      "Epoch: 2942, Train Loss: 2.162, Validation Loss: 5.909\n",
      "Epoch: 2943, Train Loss: 2.199, Validation Loss: 5.942\n",
      "Epoch: 2944, Train Loss: 2.806, Validation Loss: 5.942\n",
      "Epoch: 2945, Train Loss: 2.544, Validation Loss: 5.919\n",
      "Epoch: 2946, Train Loss: 2.471, Validation Loss: 5.951\n",
      "Epoch: 2947, Train Loss: 2.711, Validation Loss: 5.932\n",
      "Epoch: 2948, Train Loss: 2.805, Validation Loss: 5.916\n",
      "Epoch: 2949, Train Loss: 2.804, Validation Loss: 5.897\n",
      "Epoch: 2950, Train Loss: 2.713, Validation Loss: 5.879\n",
      "Epoch: 2951, Train Loss: 2.632, Validation Loss: 5.851\n",
      "Epoch: 2952, Train Loss: 2.357, Validation Loss: 5.850\n",
      "Epoch: 2953, Train Loss: 2.501, Validation Loss: 5.881\n",
      "Epoch: 2954, Train Loss: 2.521, Validation Loss: 5.895\n",
      "Epoch: 2955, Train Loss: 2.485, Validation Loss: 5.875\n",
      "Epoch: 2956, Train Loss: 2.509, Validation Loss: 5.891\n",
      "Epoch: 2957, Train Loss: 3.384, Validation Loss: 5.884\n",
      "Epoch: 2958, Train Loss: 2.877, Validation Loss: 5.931\n",
      "Epoch: 2959, Train Loss: 2.573, Validation Loss: 5.902\n",
      "Epoch: 2960, Train Loss: 2.597, Validation Loss: 5.883\n",
      "Epoch: 2961, Train Loss: 2.226, Validation Loss: 5.903\n",
      "Epoch: 2962, Train Loss: 2.301, Validation Loss: 5.944\n",
      "Epoch: 2963, Train Loss: 2.950, Validation Loss: 5.951\n",
      "Epoch: 2964, Train Loss: 2.508, Validation Loss: 5.966\n",
      "Epoch: 2965, Train Loss: 3.018, Validation Loss: 6.002\n",
      "Epoch: 2966, Train Loss: 2.759, Validation Loss: 5.974\n",
      "Epoch: 2967, Train Loss: 2.984, Validation Loss: 5.965\n",
      "Epoch: 2968, Train Loss: 3.237, Validation Loss: 5.978\n",
      "Epoch: 2969, Train Loss: 2.348, Validation Loss: 5.896\n",
      "Epoch: 2970, Train Loss: 2.597, Validation Loss: 5.889\n",
      "Epoch: 2971, Train Loss: 2.091, Validation Loss: 5.875\n",
      "Epoch: 2972, Train Loss: 2.733, Validation Loss: 5.896\n",
      "Epoch: 2973, Train Loss: 2.374, Validation Loss: 5.912\n",
      "Epoch: 2974, Train Loss: 2.822, Validation Loss: 5.902\n",
      "Epoch: 2975, Train Loss: 1.985, Validation Loss: 5.905\n",
      "Epoch: 2976, Train Loss: 1.829, Validation Loss: 5.879\n",
      "Epoch: 2977, Train Loss: 2.222, Validation Loss: 5.925\n",
      "Epoch: 2978, Train Loss: 2.818, Validation Loss: 5.932\n",
      "Epoch: 2979, Train Loss: 2.762, Validation Loss: 5.901\n",
      "Epoch: 2980, Train Loss: 2.516, Validation Loss: 5.916\n",
      "Epoch: 2981, Train Loss: 3.021, Validation Loss: 5.990\n",
      "Epoch: 2982, Train Loss: 2.705, Validation Loss: 6.003\n",
      "Epoch: 2983, Train Loss: 2.834, Validation Loss: 6.007\n",
      "Epoch: 2984, Train Loss: 2.278, Validation Loss: 5.942\n",
      "Epoch: 2985, Train Loss: 2.324, Validation Loss: 5.960\n",
      "Epoch: 2986, Train Loss: 2.360, Validation Loss: 5.982\n",
      "Epoch: 2987, Train Loss: 2.542, Validation Loss: 6.021\n",
      "Epoch: 2988, Train Loss: 2.867, Validation Loss: 5.988\n",
      "Epoch: 2989, Train Loss: 2.663, Validation Loss: 6.026\n",
      "Epoch: 2990, Train Loss: 2.554, Validation Loss: 6.025\n",
      "Epoch: 2991, Train Loss: 2.080, Validation Loss: 5.951\n",
      "Epoch: 2992, Train Loss: 2.407, Validation Loss: 5.979\n",
      "Epoch: 2993, Train Loss: 2.592, Validation Loss: 5.996\n",
      "Epoch: 2994, Train Loss: 2.680, Validation Loss: 6.021\n",
      "Epoch: 2995, Train Loss: 2.810, Validation Loss: 6.010\n",
      "Epoch: 2996, Train Loss: 2.736, Validation Loss: 5.980\n",
      "Epoch: 2997, Train Loss: 2.764, Validation Loss: 5.974\n",
      "Epoch: 2998, Train Loss: 2.595, Validation Loss: 5.972\n",
      "Epoch: 2999, Train Loss: 2.264, Validation Loss: 5.998\n",
      "Epoch: 3000, Train Loss: 2.006, Validation Loss: 5.976\n",
      "Epoch: 3001, Train Loss: 2.499, Validation Loss: 5.974\n",
      "Epoch: 3002, Train Loss: 2.591, Validation Loss: 5.967\n",
      "Epoch: 3003, Train Loss: 3.800, Validation Loss: 6.009\n",
      "Epoch: 3004, Train Loss: 2.515, Validation Loss: 5.956\n",
      "Epoch: 3005, Train Loss: 2.400, Validation Loss: 5.947\n",
      "Epoch: 3006, Train Loss: 2.256, Validation Loss: 5.958\n",
      "Epoch: 3007, Train Loss: 2.838, Validation Loss: 5.937\n",
      "Epoch: 3008, Train Loss: 2.520, Validation Loss: 5.965\n",
      "Epoch: 3009, Train Loss: 2.064, Validation Loss: 5.985\n",
      "Epoch: 3010, Train Loss: 2.255, Validation Loss: 6.027\n",
      "Epoch: 3011, Train Loss: 2.621, Validation Loss: 5.991\n",
      "Epoch: 3012, Train Loss: 2.015, Validation Loss: 5.972\n",
      "Epoch: 3013, Train Loss: 2.718, Validation Loss: 5.956\n",
      "Epoch: 3014, Train Loss: 2.241, Validation Loss: 5.943\n",
      "Epoch: 3015, Train Loss: 1.874, Validation Loss: 5.928\n",
      "Epoch: 3016, Train Loss: 2.562, Validation Loss: 5.932\n",
      "Epoch: 3017, Train Loss: 2.763, Validation Loss: 5.983\n",
      "Epoch: 3018, Train Loss: 2.649, Validation Loss: 5.957\n",
      "Epoch: 3019, Train Loss: 2.218, Validation Loss: 5.908\n",
      "Epoch: 3020, Train Loss: 2.231, Validation Loss: 5.885\n",
      "Epoch: 3021, Train Loss: 2.947, Validation Loss: 5.887\n",
      "Epoch: 3022, Train Loss: 2.503, Validation Loss: 5.821\n",
      "Epoch: 3023, Train Loss: 2.497, Validation Loss: 5.837\n",
      "Epoch: 3024, Train Loss: 2.222, Validation Loss: 5.853\n",
      "Epoch: 3025, Train Loss: 3.599, Validation Loss: 5.897\n",
      "Epoch: 3026, Train Loss: 2.687, Validation Loss: 5.866\n",
      "Epoch: 3027, Train Loss: 2.619, Validation Loss: 5.884\n",
      "Epoch: 3028, Train Loss: 2.548, Validation Loss: 5.875\n",
      "Epoch: 3029, Train Loss: 2.663, Validation Loss: 5.958\n",
      "Epoch: 3030, Train Loss: 3.186, Validation Loss: 5.947\n",
      "Epoch: 3031, Train Loss: 2.801, Validation Loss: 5.923\n",
      "Epoch: 3032, Train Loss: 2.416, Validation Loss: 5.901\n",
      "Epoch: 3033, Train Loss: 2.173, Validation Loss: 5.867\n",
      "Epoch: 3034, Train Loss: 3.165, Validation Loss: 5.871\n",
      "Epoch: 3035, Train Loss: 2.867, Validation Loss: 5.869\n",
      "Epoch: 3036, Train Loss: 1.988, Validation Loss: 5.867\n",
      "Epoch: 3037, Train Loss: 2.313, Validation Loss: 5.868\n",
      "Epoch: 3038, Train Loss: 2.952, Validation Loss: 5.887\n",
      "Epoch: 3039, Train Loss: 2.386, Validation Loss: 5.929\n",
      "Epoch: 3040, Train Loss: 2.751, Validation Loss: 5.944\n",
      "Epoch: 3041, Train Loss: 2.730, Validation Loss: 5.947\n",
      "Epoch: 3042, Train Loss: 2.342, Validation Loss: 5.951\n",
      "Epoch: 3043, Train Loss: 2.757, Validation Loss: 5.953\n",
      "Epoch: 3044, Train Loss: 2.646, Validation Loss: 5.992\n",
      "Epoch: 3045, Train Loss: 2.335, Validation Loss: 5.939\n",
      "Epoch: 3046, Train Loss: 2.297, Validation Loss: 5.955\n",
      "Epoch: 3047, Train Loss: 2.472, Validation Loss: 5.960\n",
      "Epoch: 3048, Train Loss: 2.321, Validation Loss: 5.966\n",
      "Epoch: 3049, Train Loss: 2.225, Validation Loss: 5.957\n",
      "Epoch: 3050, Train Loss: 2.652, Validation Loss: 5.954\n",
      "Epoch: 3051, Train Loss: 2.385, Validation Loss: 5.959\n",
      "Epoch: 3052, Train Loss: 1.910, Validation Loss: 5.928\n",
      "Epoch: 3053, Train Loss: 2.845, Validation Loss: 5.943\n",
      "Epoch: 3054, Train Loss: 2.492, Validation Loss: 5.923\n",
      "Epoch: 3055, Train Loss: 2.729, Validation Loss: 5.926\n",
      "Epoch: 3056, Train Loss: 2.074, Validation Loss: 5.863\n",
      "Epoch: 3057, Train Loss: 2.702, Validation Loss: 5.843\n",
      "Epoch: 3058, Train Loss: 2.455, Validation Loss: 5.870\n",
      "Epoch: 3059, Train Loss: 2.488, Validation Loss: 5.934\n",
      "Epoch: 3060, Train Loss: 2.906, Validation Loss: 5.895\n",
      "Epoch: 3061, Train Loss: 2.366, Validation Loss: 5.891\n",
      "Epoch: 3062, Train Loss: 2.466, Validation Loss: 5.916\n",
      "Epoch: 3063, Train Loss: 2.541, Validation Loss: 5.853\n",
      "Epoch: 3064, Train Loss: 2.107, Validation Loss: 5.878\n",
      "Epoch: 3065, Train Loss: 2.176, Validation Loss: 5.878\n",
      "Epoch: 3066, Train Loss: 2.646, Validation Loss: 5.904\n",
      "Epoch: 3067, Train Loss: 2.343, Validation Loss: 5.916\n",
      "Epoch: 3068, Train Loss: 2.405, Validation Loss: 5.863\n",
      "Epoch: 3069, Train Loss: 2.310, Validation Loss: 5.868\n",
      "Epoch: 3070, Train Loss: 2.671, Validation Loss: 5.876\n",
      "Epoch: 3071, Train Loss: 2.691, Validation Loss: 5.932\n",
      "Epoch: 3072, Train Loss: 2.609, Validation Loss: 5.899\n",
      "Epoch: 3073, Train Loss: 2.115, Validation Loss: 5.866\n",
      "Epoch: 3074, Train Loss: 2.100, Validation Loss: 5.836\n",
      "Epoch: 3075, Train Loss: 2.526, Validation Loss: 5.864\n",
      "Epoch: 3076, Train Loss: 2.319, Validation Loss: 5.874\n",
      "Epoch: 3077, Train Loss: 3.057, Validation Loss: 5.839\n",
      "Epoch: 3078, Train Loss: 1.859, Validation Loss: 5.860\n",
      "Epoch: 3079, Train Loss: 2.305, Validation Loss: 5.876\n",
      "Epoch: 3080, Train Loss: 2.365, Validation Loss: 5.915\n",
      "Epoch: 3081, Train Loss: 2.590, Validation Loss: 5.860\n",
      "Epoch: 3082, Train Loss: 2.478, Validation Loss: 5.878\n",
      "Epoch: 3083, Train Loss: 2.680, Validation Loss: 5.902\n",
      "Epoch: 3084, Train Loss: 2.320, Validation Loss: 5.858\n",
      "Epoch: 3085, Train Loss: 2.481, Validation Loss: 5.841\n",
      "Epoch: 3086, Train Loss: 2.185, Validation Loss: 5.825\n",
      "Epoch: 3087, Train Loss: 2.378, Validation Loss: 5.820\n",
      "Epoch: 3088, Train Loss: 2.524, Validation Loss: 5.833\n",
      "Epoch: 3089, Train Loss: 2.794, Validation Loss: 5.861\n",
      "Epoch: 3090, Train Loss: 2.372, Validation Loss: 5.857\n",
      "Epoch: 3091, Train Loss: 2.437, Validation Loss: 5.913\n",
      "Epoch: 3092, Train Loss: 2.952, Validation Loss: 5.895\n",
      "Epoch: 3093, Train Loss: 2.115, Validation Loss: 5.895\n",
      "Epoch: 3094, Train Loss: 2.416, Validation Loss: 5.906\n",
      "Epoch: 3095, Train Loss: 2.169, Validation Loss: 5.895\n",
      "Epoch: 3096, Train Loss: 2.388, Validation Loss: 5.892\n",
      "Epoch: 3097, Train Loss: 2.435, Validation Loss: 5.922\n",
      "Epoch: 3098, Train Loss: 2.588, Validation Loss: 5.910\n",
      "Epoch: 3099, Train Loss: 2.217, Validation Loss: 5.881\n",
      "Epoch: 3100, Train Loss: 2.543, Validation Loss: 5.882\n",
      "Epoch: 3101, Train Loss: 1.912, Validation Loss: 5.884\n",
      "Epoch: 3102, Train Loss: 2.412, Validation Loss: 5.904\n",
      "Epoch: 3103, Train Loss: 2.485, Validation Loss: 5.871\n",
      "Epoch: 3104, Train Loss: 2.302, Validation Loss: 5.893\n",
      "Epoch: 3105, Train Loss: 1.881, Validation Loss: 5.909\n",
      "Epoch: 3106, Train Loss: 2.192, Validation Loss: 5.889\n",
      "Epoch: 3107, Train Loss: 2.495, Validation Loss: 5.906\n",
      "Epoch: 3108, Train Loss: 2.388, Validation Loss: 5.899\n",
      "Epoch: 3109, Train Loss: 2.222, Validation Loss: 5.907\n",
      "Epoch: 3110, Train Loss: 2.517, Validation Loss: 5.915\n",
      "Epoch: 3111, Train Loss: 2.699, Validation Loss: 5.950\n",
      "Epoch: 3112, Train Loss: 2.273, Validation Loss: 5.876\n",
      "Epoch: 3113, Train Loss: 2.279, Validation Loss: 5.884\n",
      "Epoch: 3114, Train Loss: 2.598, Validation Loss: 5.878\n",
      "Epoch: 3115, Train Loss: 2.227, Validation Loss: 5.893\n",
      "Epoch: 3116, Train Loss: 2.390, Validation Loss: 5.956\n",
      "Epoch: 3117, Train Loss: 2.041, Validation Loss: 5.965\n",
      "Epoch: 3118, Train Loss: 1.990, Validation Loss: 5.955\n",
      "Epoch: 3119, Train Loss: 2.284, Validation Loss: 5.995\n",
      "Epoch: 3120, Train Loss: 2.441, Validation Loss: 5.958\n",
      "Epoch: 3121, Train Loss: 2.660, Validation Loss: 5.955\n",
      "Epoch: 3122, Train Loss: 2.832, Validation Loss: 5.910\n",
      "Epoch: 3123, Train Loss: 2.379, Validation Loss: 5.862\n",
      "Epoch: 3124, Train Loss: 2.292, Validation Loss: 5.924\n",
      "Epoch: 3125, Train Loss: 2.597, Validation Loss: 5.924\n",
      "Epoch: 3126, Train Loss: 2.380, Validation Loss: 5.909\n",
      "Epoch: 3127, Train Loss: 2.673, Validation Loss: 5.915\n",
      "Epoch: 3128, Train Loss: 2.201, Validation Loss: 5.848\n",
      "Epoch: 3129, Train Loss: 2.311, Validation Loss: 5.887\n",
      "Epoch: 3130, Train Loss: 2.004, Validation Loss: 5.890\n",
      "Epoch: 3131, Train Loss: 2.565, Validation Loss: 5.875\n",
      "Epoch: 3132, Train Loss: 2.394, Validation Loss: 5.897\n",
      "Epoch: 3133, Train Loss: 2.856, Validation Loss: 5.915\n",
      "Epoch: 3134, Train Loss: 2.314, Validation Loss: 5.922\n",
      "Epoch: 3135, Train Loss: 2.771, Validation Loss: 5.910\n",
      "Epoch: 3136, Train Loss: 2.322, Validation Loss: 5.909\n",
      "Epoch: 3137, Train Loss: 2.474, Validation Loss: 5.846\n",
      "Epoch: 3138, Train Loss: 2.606, Validation Loss: 5.857\n",
      "Epoch: 3139, Train Loss: 2.666, Validation Loss: 5.853\n",
      "Epoch: 3140, Train Loss: 2.308, Validation Loss: 5.850\n",
      "Epoch: 3141, Train Loss: 2.330, Validation Loss: 5.842\n",
      "Epoch: 3142, Train Loss: 2.753, Validation Loss: 5.819\n",
      "Epoch: 3143, Train Loss: 2.627, Validation Loss: 5.882\n",
      "Epoch: 3144, Train Loss: 2.265, Validation Loss: 5.908\n",
      "Epoch: 3145, Train Loss: 2.700, Validation Loss: 5.944\n",
      "Epoch: 3146, Train Loss: 2.062, Validation Loss: 5.896\n",
      "Epoch: 3147, Train Loss: 2.153, Validation Loss: 5.908\n",
      "Epoch: 3148, Train Loss: 2.541, Validation Loss: 5.901\n",
      "Epoch: 3149, Train Loss: 1.783, Validation Loss: 5.912\n",
      "Epoch: 3150, Train Loss: 2.509, Validation Loss: 5.982\n",
      "Epoch: 3151, Train Loss: 2.277, Validation Loss: 5.905\n",
      "Epoch: 3152, Train Loss: 2.707, Validation Loss: 5.927\n",
      "Epoch: 3153, Train Loss: 2.093, Validation Loss: 5.937\n",
      "Epoch: 3154, Train Loss: 1.815, Validation Loss: 5.908\n",
      "Epoch: 3155, Train Loss: 2.340, Validation Loss: 5.873\n",
      "Epoch: 3156, Train Loss: 2.402, Validation Loss: 5.914\n",
      "Epoch: 3157, Train Loss: 2.599, Validation Loss: 5.923\n",
      "Epoch: 3158, Train Loss: 2.804, Validation Loss: 5.971\n",
      "Epoch: 3159, Train Loss: 2.601, Validation Loss: 5.947\n",
      "Epoch: 3160, Train Loss: 2.319, Validation Loss: 5.920\n",
      "Epoch: 3161, Train Loss: 2.541, Validation Loss: 5.949\n",
      "Epoch: 3162, Train Loss: 2.560, Validation Loss: 5.937\n",
      "Epoch: 3163, Train Loss: 2.377, Validation Loss: 5.910\n",
      "Epoch: 3164, Train Loss: 3.011, Validation Loss: 5.920\n",
      "Epoch: 3165, Train Loss: 2.674, Validation Loss: 5.935\n",
      "Epoch: 3166, Train Loss: 2.056, Validation Loss: 5.907\n",
      "Epoch: 3167, Train Loss: 2.639, Validation Loss: 5.891\n",
      "Epoch: 3168, Train Loss: 2.949, Validation Loss: 5.902\n",
      "Epoch: 3169, Train Loss: 2.524, Validation Loss: 5.928\n",
      "Epoch: 3170, Train Loss: 2.518, Validation Loss: 5.895\n",
      "Epoch: 3171, Train Loss: 2.001, Validation Loss: 5.903\n",
      "Epoch: 3172, Train Loss: 2.527, Validation Loss: 5.920\n",
      "Epoch: 3173, Train Loss: 2.668, Validation Loss: 5.906\n",
      "Epoch: 3174, Train Loss: 2.167, Validation Loss: 5.908\n",
      "Epoch: 3175, Train Loss: 2.180, Validation Loss: 5.904\n",
      "Epoch: 3176, Train Loss: 2.817, Validation Loss: 5.890\n",
      "Epoch: 3177, Train Loss: 2.236, Validation Loss: 5.886\n",
      "Epoch: 3178, Train Loss: 2.617, Validation Loss: 5.913\n",
      "Epoch: 3179, Train Loss: 2.450, Validation Loss: 5.898\n",
      "Epoch: 3180, Train Loss: 2.483, Validation Loss: 5.876\n",
      "Epoch: 3181, Train Loss: 2.357, Validation Loss: 5.885\n",
      "Epoch: 3182, Train Loss: 2.151, Validation Loss: 5.873\n",
      "Epoch: 3183, Train Loss: 2.266, Validation Loss: 5.855\n",
      "Epoch: 3184, Train Loss: 2.784, Validation Loss: 5.846\n",
      "Epoch: 3185, Train Loss: 2.851, Validation Loss: 5.850\n",
      "Epoch: 3186, Train Loss: 2.120, Validation Loss: 5.812\n",
      "Epoch: 3187, Train Loss: 2.502, Validation Loss: 5.832\n",
      "Epoch: 3188, Train Loss: 2.126, Validation Loss: 5.859\n",
      "Epoch: 3189, Train Loss: 2.137, Validation Loss: 5.840\n",
      "Epoch: 3190, Train Loss: 2.131, Validation Loss: 5.817\n",
      "Epoch: 3191, Train Loss: 2.789, Validation Loss: 5.879\n",
      "Epoch: 3192, Train Loss: 2.229, Validation Loss: 5.829\n",
      "Epoch: 3193, Train Loss: 2.293, Validation Loss: 5.860\n",
      "Epoch: 3194, Train Loss: 2.381, Validation Loss: 5.888\n",
      "Epoch: 3195, Train Loss: 2.374, Validation Loss: 5.814\n",
      "Epoch: 3196, Train Loss: 2.436, Validation Loss: 5.819\n",
      "Epoch: 3197, Train Loss: 1.782, Validation Loss: 5.823\n",
      "Epoch: 3198, Train Loss: 2.483, Validation Loss: 5.863\n",
      "Epoch: 3199, Train Loss: 2.855, Validation Loss: 5.886\n",
      "Epoch: 3200, Train Loss: 2.450, Validation Loss: 5.851\n",
      "Epoch: 3201, Train Loss: 2.689, Validation Loss: 5.891\n",
      "Epoch: 3202, Train Loss: 2.723, Validation Loss: 5.866\n",
      "Epoch: 3203, Train Loss: 2.499, Validation Loss: 5.877\n",
      "Epoch: 3204, Train Loss: 2.226, Validation Loss: 5.889\n",
      "Epoch: 3205, Train Loss: 2.601, Validation Loss: 5.885\n",
      "Epoch: 3206, Train Loss: 2.606, Validation Loss: 5.844\n",
      "Epoch: 3207, Train Loss: 2.732, Validation Loss: 5.854\n",
      "Epoch: 3208, Train Loss: 3.114, Validation Loss: 5.845\n",
      "Epoch: 3209, Train Loss: 2.380, Validation Loss: 5.880\n",
      "Epoch: 3210, Train Loss: 2.462, Validation Loss: 5.888\n",
      "Epoch: 3211, Train Loss: 2.394, Validation Loss: 5.890\n",
      "Epoch: 3212, Train Loss: 2.583, Validation Loss: 5.892\n",
      "Epoch: 3213, Train Loss: 1.837, Validation Loss: 5.871\n",
      "Epoch: 3214, Train Loss: 2.475, Validation Loss: 5.835\n",
      "Epoch: 3215, Train Loss: 2.886, Validation Loss: 5.868\n",
      "Epoch: 3216, Train Loss: 2.290, Validation Loss: 5.868\n",
      "Epoch: 3217, Train Loss: 2.146, Validation Loss: 5.939\n",
      "Epoch: 3218, Train Loss: 2.190, Validation Loss: 5.954\n",
      "Epoch: 3219, Train Loss: 2.153, Validation Loss: 5.960\n",
      "Epoch: 3220, Train Loss: 2.436, Validation Loss: 5.950\n",
      "Epoch: 3221, Train Loss: 1.992, Validation Loss: 5.943\n",
      "Epoch: 3222, Train Loss: 2.442, Validation Loss: 5.966\n",
      "Epoch: 3223, Train Loss: 2.409, Validation Loss: 5.905\n",
      "Epoch: 3224, Train Loss: 2.759, Validation Loss: 5.928\n",
      "Epoch: 3225, Train Loss: 2.284, Validation Loss: 5.937\n",
      "Epoch: 3226, Train Loss: 2.200, Validation Loss: 5.918\n",
      "Epoch: 3227, Train Loss: 2.265, Validation Loss: 5.897\n",
      "Epoch: 3228, Train Loss: 2.134, Validation Loss: 5.924\n",
      "Epoch: 3229, Train Loss: 1.753, Validation Loss: 5.927\n",
      "Epoch: 3230, Train Loss: 2.344, Validation Loss: 5.959\n",
      "Epoch: 3231, Train Loss: 2.385, Validation Loss: 5.949\n",
      "Epoch: 3232, Train Loss: 2.359, Validation Loss: 5.942\n",
      "Epoch: 3233, Train Loss: 2.477, Validation Loss: 5.880\n",
      "Epoch: 3234, Train Loss: 2.641, Validation Loss: 5.852\n",
      "Epoch: 3235, Train Loss: 1.814, Validation Loss: 5.852\n",
      "Epoch: 3236, Train Loss: 2.474, Validation Loss: 5.855\n",
      "Epoch: 3237, Train Loss: 1.951, Validation Loss: 5.878\n",
      "Epoch: 3238, Train Loss: 1.839, Validation Loss: 5.891\n",
      "Epoch: 3239, Train Loss: 2.214, Validation Loss: 5.887\n",
      "Epoch: 3240, Train Loss: 2.092, Validation Loss: 5.899\n",
      "Epoch: 3241, Train Loss: 2.181, Validation Loss: 5.907\n",
      "Epoch: 3242, Train Loss: 2.378, Validation Loss: 5.918\n",
      "Epoch: 3243, Train Loss: 2.260, Validation Loss: 5.940\n",
      "Epoch: 3244, Train Loss: 2.434, Validation Loss: 5.949\n",
      "Epoch: 3245, Train Loss: 2.352, Validation Loss: 5.961\n",
      "Epoch: 3246, Train Loss: 2.080, Validation Loss: 5.976\n",
      "Epoch: 3247, Train Loss: 2.285, Validation Loss: 5.995\n",
      "Epoch: 3248, Train Loss: 2.339, Validation Loss: 5.957\n",
      "Epoch: 3249, Train Loss: 1.943, Validation Loss: 5.956\n",
      "Epoch: 3250, Train Loss: 1.965, Validation Loss: 5.936\n",
      "Epoch: 3251, Train Loss: 2.279, Validation Loss: 5.935\n",
      "Epoch: 3252, Train Loss: 2.366, Validation Loss: 5.885\n",
      "Epoch: 3253, Train Loss: 2.081, Validation Loss: 5.866\n",
      "Epoch: 3254, Train Loss: 2.803, Validation Loss: 5.877\n",
      "Epoch: 3255, Train Loss: 3.023, Validation Loss: 5.880\n",
      "Epoch: 3256, Train Loss: 2.005, Validation Loss: 5.868\n",
      "Epoch: 3257, Train Loss: 2.327, Validation Loss: 5.898\n",
      "Epoch: 3258, Train Loss: 1.907, Validation Loss: 5.862\n",
      "Epoch: 3259, Train Loss: 2.101, Validation Loss: 5.892\n",
      "Epoch: 3260, Train Loss: 2.767, Validation Loss: 5.889\n",
      "Epoch: 3261, Train Loss: 2.409, Validation Loss: 5.852\n",
      "Epoch: 3262, Train Loss: 2.498, Validation Loss: 5.842\n",
      "Epoch: 3263, Train Loss: 2.760, Validation Loss: 5.873\n",
      "Epoch: 3264, Train Loss: 2.168, Validation Loss: 5.891\n",
      "Epoch: 3265, Train Loss: 2.737, Validation Loss: 5.892\n",
      "Epoch: 3266, Train Loss: 2.581, Validation Loss: 5.883\n",
      "Epoch: 3267, Train Loss: 2.200, Validation Loss: 5.850\n",
      "Epoch: 3268, Train Loss: 2.080, Validation Loss: 5.872\n",
      "Epoch: 3269, Train Loss: 2.350, Validation Loss: 5.935\n",
      "Epoch: 3270, Train Loss: 2.674, Validation Loss: 5.953\n",
      "Epoch: 3271, Train Loss: 2.373, Validation Loss: 5.920\n",
      "Epoch: 3272, Train Loss: 2.377, Validation Loss: 5.947\n",
      "Epoch: 3273, Train Loss: 3.223, Validation Loss: 5.898\n",
      "Epoch: 3274, Train Loss: 2.922, Validation Loss: 5.901\n",
      "Epoch: 3275, Train Loss: 2.445, Validation Loss: 5.884\n",
      "Epoch: 3276, Train Loss: 2.924, Validation Loss: 5.884\n",
      "Epoch: 3277, Train Loss: 2.260, Validation Loss: 5.881\n",
      "Epoch: 3278, Train Loss: 2.104, Validation Loss: 5.900\n",
      "Epoch: 3279, Train Loss: 1.944, Validation Loss: 5.865\n",
      "Epoch: 3280, Train Loss: 2.385, Validation Loss: 5.902\n",
      "Epoch: 3281, Train Loss: 2.287, Validation Loss: 5.910\n",
      "Epoch: 3282, Train Loss: 2.507, Validation Loss: 5.893\n",
      "Epoch: 3283, Train Loss: 2.126, Validation Loss: 5.854\n",
      "Epoch: 3284, Train Loss: 2.623, Validation Loss: 5.861\n",
      "Epoch: 3285, Train Loss: 2.408, Validation Loss: 5.832\n",
      "Epoch: 3286, Train Loss: 2.678, Validation Loss: 5.842\n",
      "Epoch: 3287, Train Loss: 2.741, Validation Loss: 5.898\n",
      "Epoch: 3288, Train Loss: 2.400, Validation Loss: 5.878\n",
      "Epoch: 3289, Train Loss: 2.172, Validation Loss: 5.897\n",
      "Epoch: 3290, Train Loss: 2.215, Validation Loss: 5.875\n",
      "Epoch: 3291, Train Loss: 2.451, Validation Loss: 5.927\n",
      "Epoch: 3292, Train Loss: 2.238, Validation Loss: 5.907\n",
      "Epoch: 3293, Train Loss: 1.919, Validation Loss: 5.886\n",
      "Epoch: 3294, Train Loss: 2.104, Validation Loss: 5.899\n",
      "Epoch: 3295, Train Loss: 2.272, Validation Loss: 5.917\n",
      "Epoch: 3296, Train Loss: 1.987, Validation Loss: 5.931\n",
      "Epoch: 3297, Train Loss: 2.695, Validation Loss: 5.935\n",
      "Epoch: 3298, Train Loss: 2.146, Validation Loss: 5.916\n",
      "Epoch: 3299, Train Loss: 1.965, Validation Loss: 5.919\n",
      "Epoch: 3300, Train Loss: 2.094, Validation Loss: 5.898\n",
      "Epoch: 3301, Train Loss: 2.226, Validation Loss: 5.919\n",
      "Epoch: 3302, Train Loss: 1.965, Validation Loss: 5.900\n",
      "Epoch: 3303, Train Loss: 2.281, Validation Loss: 5.897\n",
      "Epoch: 3304, Train Loss: 2.361, Validation Loss: 5.960\n",
      "Epoch: 3305, Train Loss: 2.193, Validation Loss: 5.947\n",
      "Epoch: 3306, Train Loss: 2.223, Validation Loss: 5.922\n",
      "Epoch: 3307, Train Loss: 2.209, Validation Loss: 5.893\n",
      "Epoch: 3308, Train Loss: 2.407, Validation Loss: 5.885\n",
      "Epoch: 3309, Train Loss: 2.800, Validation Loss: 5.895\n",
      "Epoch: 3310, Train Loss: 2.780, Validation Loss: 5.925\n",
      "Epoch: 3311, Train Loss: 2.184, Validation Loss: 5.888\n",
      "Epoch: 3312, Train Loss: 2.051, Validation Loss: 5.894\n",
      "Epoch: 3313, Train Loss: 2.094, Validation Loss: 5.928\n",
      "Epoch: 3314, Train Loss: 2.499, Validation Loss: 5.950\n",
      "Epoch: 3315, Train Loss: 2.362, Validation Loss: 5.910\n",
      "Epoch: 3316, Train Loss: 2.575, Validation Loss: 5.908\n",
      "Epoch: 3317, Train Loss: 2.489, Validation Loss: 5.917\n",
      "Epoch: 3318, Train Loss: 2.327, Validation Loss: 5.918\n",
      "Epoch: 3319, Train Loss: 1.971, Validation Loss: 5.894\n",
      "Epoch: 3320, Train Loss: 2.315, Validation Loss: 5.890\n",
      "Epoch: 3321, Train Loss: 1.768, Validation Loss: 5.897\n",
      "Epoch: 3322, Train Loss: 2.507, Validation Loss: 5.921\n",
      "Epoch: 3323, Train Loss: 2.065, Validation Loss: 5.894\n",
      "Epoch: 3324, Train Loss: 1.996, Validation Loss: 5.900\n",
      "Epoch: 3325, Train Loss: 1.975, Validation Loss: 5.932\n",
      "Epoch: 3326, Train Loss: 2.508, Validation Loss: 5.946\n",
      "Epoch: 3327, Train Loss: 2.045, Validation Loss: 5.915\n",
      "Epoch: 3328, Train Loss: 2.192, Validation Loss: 5.926\n",
      "Epoch: 3329, Train Loss: 2.408, Validation Loss: 5.900\n",
      "Epoch: 3330, Train Loss: 2.655, Validation Loss: 5.906\n",
      "Epoch: 3331, Train Loss: 2.802, Validation Loss: 5.930\n",
      "Epoch: 3332, Train Loss: 2.904, Validation Loss: 5.932\n",
      "Epoch: 3333, Train Loss: 2.649, Validation Loss: 5.863\n",
      "Epoch: 3334, Train Loss: 2.272, Validation Loss: 5.844\n",
      "Epoch: 3335, Train Loss: 2.534, Validation Loss: 5.888\n",
      "Epoch: 3336, Train Loss: 2.115, Validation Loss: 5.877\n",
      "Epoch: 3337, Train Loss: 2.334, Validation Loss: 5.856\n",
      "Epoch: 3338, Train Loss: 2.159, Validation Loss: 5.837\n",
      "Epoch: 3339, Train Loss: 2.173, Validation Loss: 5.814\n",
      "Epoch: 3340, Train Loss: 2.325, Validation Loss: 5.832\n",
      "Epoch: 3341, Train Loss: 2.278, Validation Loss: 5.800\n",
      "Epoch: 3342, Train Loss: 2.516, Validation Loss: 5.797\n",
      "Epoch: 3343, Train Loss: 2.118, Validation Loss: 5.789\n",
      "Epoch: 3344, Train Loss: 2.461, Validation Loss: 5.758\n",
      "Epoch: 3345, Train Loss: 2.357, Validation Loss: 5.772\n",
      "Epoch: 3346, Train Loss: 2.752, Validation Loss: 5.822\n",
      "Epoch: 3347, Train Loss: 2.147, Validation Loss: 5.857\n",
      "Epoch: 3348, Train Loss: 2.171, Validation Loss: 5.877\n",
      "Epoch: 3349, Train Loss: 2.298, Validation Loss: 5.877\n",
      "Epoch: 3350, Train Loss: 2.613, Validation Loss: 5.915\n",
      "Epoch: 3351, Train Loss: 2.617, Validation Loss: 5.894\n",
      "Epoch: 3352, Train Loss: 1.895, Validation Loss: 5.872\n",
      "Epoch: 3353, Train Loss: 1.956, Validation Loss: 5.859\n",
      "Epoch: 3354, Train Loss: 2.296, Validation Loss: 5.845\n",
      "Epoch: 3355, Train Loss: 2.577, Validation Loss: 5.820\n",
      "Epoch: 3356, Train Loss: 2.533, Validation Loss: 5.828\n",
      "Epoch: 3357, Train Loss: 2.567, Validation Loss: 5.822\n",
      "Epoch: 3358, Train Loss: 2.630, Validation Loss: 5.858\n",
      "Epoch: 3359, Train Loss: 2.501, Validation Loss: 5.866\n",
      "Epoch: 3360, Train Loss: 2.253, Validation Loss: 5.846\n",
      "Epoch: 3361, Train Loss: 2.111, Validation Loss: 5.858\n",
      "Epoch: 3362, Train Loss: 2.420, Validation Loss: 5.868\n",
      "Epoch: 3363, Train Loss: 2.595, Validation Loss: 5.873\n",
      "Epoch: 3364, Train Loss: 2.083, Validation Loss: 5.845\n",
      "Epoch: 3365, Train Loss: 2.839, Validation Loss: 5.871\n",
      "Epoch: 3366, Train Loss: 2.125, Validation Loss: 5.863\n",
      "Epoch: 3367, Train Loss: 2.274, Validation Loss: 5.861\n",
      "Epoch: 3368, Train Loss: 1.856, Validation Loss: 5.889\n",
      "Epoch: 3369, Train Loss: 2.151, Validation Loss: 5.898\n",
      "Epoch: 3370, Train Loss: 2.620, Validation Loss: 5.903\n",
      "Epoch: 3371, Train Loss: 2.092, Validation Loss: 5.913\n",
      "Epoch: 3372, Train Loss: 1.986, Validation Loss: 5.922\n",
      "Epoch: 3373, Train Loss: 2.314, Validation Loss: 5.882\n",
      "Epoch: 3374, Train Loss: 2.041, Validation Loss: 5.933\n",
      "Epoch: 3375, Train Loss: 2.391, Validation Loss: 5.925\n",
      "Epoch: 3376, Train Loss: 2.738, Validation Loss: 5.902\n",
      "Epoch: 3377, Train Loss: 2.761, Validation Loss: 5.891\n",
      "Epoch: 3378, Train Loss: 2.379, Validation Loss: 5.860\n",
      "Epoch: 3379, Train Loss: 2.412, Validation Loss: 5.884\n",
      "Epoch: 3380, Train Loss: 2.307, Validation Loss: 5.873\n",
      "Epoch: 3381, Train Loss: 1.841, Validation Loss: 5.850\n",
      "Epoch: 3382, Train Loss: 2.512, Validation Loss: 5.866\n",
      "Epoch: 3383, Train Loss: 1.873, Validation Loss: 5.859\n",
      "Epoch: 3384, Train Loss: 2.247, Validation Loss: 5.863\n",
      "Epoch: 3385, Train Loss: 2.579, Validation Loss: 5.792\n",
      "Epoch: 3386, Train Loss: 2.076, Validation Loss: 5.797\n",
      "Epoch: 3387, Train Loss: 2.116, Validation Loss: 5.820\n",
      "Epoch: 3388, Train Loss: 2.374, Validation Loss: 5.810\n",
      "Epoch: 3389, Train Loss: 2.534, Validation Loss: 5.830\n",
      "Epoch: 3390, Train Loss: 1.754, Validation Loss: 5.810\n",
      "Epoch: 3391, Train Loss: 2.303, Validation Loss: 5.855\n",
      "Epoch: 3392, Train Loss: 2.112, Validation Loss: 5.865\n",
      "Epoch: 3393, Train Loss: 2.458, Validation Loss: 5.880\n",
      "Epoch: 3394, Train Loss: 2.757, Validation Loss: 5.905\n",
      "Epoch: 3395, Train Loss: 2.264, Validation Loss: 5.963\n",
      "Epoch: 3396, Train Loss: 2.051, Validation Loss: 5.933\n",
      "Epoch: 3397, Train Loss: 1.982, Validation Loss: 5.865\n",
      "Epoch: 3398, Train Loss: 2.192, Validation Loss: 5.862\n",
      "Epoch: 3399, Train Loss: 1.752, Validation Loss: 5.854\n",
      "Epoch: 3400, Train Loss: 2.361, Validation Loss: 5.875\n",
      "Epoch: 3401, Train Loss: 2.017, Validation Loss: 5.885\n",
      "Epoch: 3402, Train Loss: 2.001, Validation Loss: 5.884\n",
      "Epoch: 3403, Train Loss: 2.114, Validation Loss: 5.868\n",
      "Epoch: 3404, Train Loss: 1.976, Validation Loss: 5.901\n",
      "Epoch: 3405, Train Loss: 2.461, Validation Loss: 5.887\n",
      "Epoch: 3406, Train Loss: 2.444, Validation Loss: 5.862\n",
      "Epoch: 3407, Train Loss: 2.216, Validation Loss: 5.891\n",
      "Epoch: 3408, Train Loss: 2.458, Validation Loss: 5.897\n",
      "Epoch: 3409, Train Loss: 2.703, Validation Loss: 5.903\n",
      "Epoch: 3410, Train Loss: 2.017, Validation Loss: 5.836\n",
      "Epoch: 3411, Train Loss: 2.235, Validation Loss: 5.794\n",
      "Epoch: 3412, Train Loss: 2.428, Validation Loss: 5.818\n",
      "Epoch: 3413, Train Loss: 2.081, Validation Loss: 5.833\n",
      "Epoch: 3414, Train Loss: 2.069, Validation Loss: 5.856\n",
      "Epoch: 3415, Train Loss: 2.249, Validation Loss: 5.870\n",
      "Epoch: 3416, Train Loss: 2.144, Validation Loss: 5.841\n",
      "Epoch: 3417, Train Loss: 2.541, Validation Loss: 5.814\n",
      "Epoch: 3418, Train Loss: 2.148, Validation Loss: 5.811\n",
      "Epoch: 3419, Train Loss: 1.633, Validation Loss: 5.823\n",
      "Epoch: 3420, Train Loss: 2.266, Validation Loss: 5.798\n",
      "Epoch: 3421, Train Loss: 2.223, Validation Loss: 5.796\n",
      "Epoch: 3422, Train Loss: 2.036, Validation Loss: 5.802\n",
      "Epoch: 3423, Train Loss: 2.752, Validation Loss: 5.812\n",
      "Epoch: 3424, Train Loss: 2.033, Validation Loss: 5.850\n",
      "Epoch: 3425, Train Loss: 2.291, Validation Loss: 5.809\n",
      "Epoch: 3426, Train Loss: 2.042, Validation Loss: 5.796\n",
      "Epoch: 3427, Train Loss: 2.475, Validation Loss: 5.809\n",
      "Epoch: 3428, Train Loss: 2.249, Validation Loss: 5.811\n",
      "Epoch: 3429, Train Loss: 2.342, Validation Loss: 5.873\n",
      "Epoch: 3430, Train Loss: 1.679, Validation Loss: 5.816\n",
      "Epoch: 3431, Train Loss: 2.103, Validation Loss: 5.828\n",
      "Epoch: 3432, Train Loss: 2.076, Validation Loss: 5.811\n",
      "Epoch: 3433, Train Loss: 2.054, Validation Loss: 5.780\n",
      "Epoch: 3434, Train Loss: 2.472, Validation Loss: 5.812\n",
      "Epoch: 3435, Train Loss: 2.641, Validation Loss: 5.766\n",
      "Epoch: 3436, Train Loss: 2.439, Validation Loss: 5.798\n",
      "Epoch: 3437, Train Loss: 2.410, Validation Loss: 5.820\n",
      "Epoch: 3438, Train Loss: 2.615, Validation Loss: 5.853\n",
      "Epoch: 3439, Train Loss: 2.734, Validation Loss: 5.810\n",
      "Epoch: 3440, Train Loss: 2.330, Validation Loss: 5.801\n",
      "Epoch: 3441, Train Loss: 2.019, Validation Loss: 5.802\n",
      "Epoch: 3442, Train Loss: 2.584, Validation Loss: 5.788\n",
      "Epoch: 3443, Train Loss: 2.306, Validation Loss: 5.795\n",
      "Epoch: 3444, Train Loss: 2.157, Validation Loss: 5.804\n",
      "Epoch: 3445, Train Loss: 2.428, Validation Loss: 5.862\n",
      "Epoch: 3446, Train Loss: 2.719, Validation Loss: 5.861\n",
      "Epoch: 3447, Train Loss: 1.677, Validation Loss: 5.915\n",
      "Epoch: 3448, Train Loss: 1.726, Validation Loss: 5.870\n",
      "Epoch: 3449, Train Loss: 2.141, Validation Loss: 5.853\n",
      "Epoch: 3450, Train Loss: 1.873, Validation Loss: 5.843\n",
      "Epoch: 3451, Train Loss: 2.045, Validation Loss: 5.862\n",
      "Epoch: 3452, Train Loss: 2.389, Validation Loss: 5.853\n",
      "Epoch: 3453, Train Loss: 1.748, Validation Loss: 5.861\n",
      "Epoch: 3454, Train Loss: 2.303, Validation Loss: 5.822\n",
      "Epoch: 3455, Train Loss: 2.528, Validation Loss: 5.804\n",
      "Epoch: 3456, Train Loss: 3.019, Validation Loss: 5.852\n",
      "Epoch: 3457, Train Loss: 2.367, Validation Loss: 5.850\n",
      "Epoch: 3458, Train Loss: 2.969, Validation Loss: 5.882\n",
      "Epoch: 3459, Train Loss: 2.258, Validation Loss: 5.844\n",
      "Epoch: 3460, Train Loss: 2.228, Validation Loss: 5.864\n",
      "Epoch: 3461, Train Loss: 1.958, Validation Loss: 5.835\n",
      "Epoch: 3462, Train Loss: 2.126, Validation Loss: 5.839\n",
      "Epoch: 3463, Train Loss: 2.214, Validation Loss: 5.842\n",
      "Epoch: 3464, Train Loss: 2.233, Validation Loss: 5.857\n",
      "Epoch: 3465, Train Loss: 2.424, Validation Loss: 5.906\n",
      "Epoch: 3466, Train Loss: 2.121, Validation Loss: 5.870\n",
      "Epoch: 3467, Train Loss: 2.270, Validation Loss: 5.844\n",
      "Epoch: 3468, Train Loss: 2.157, Validation Loss: 5.822\n",
      "Epoch: 3469, Train Loss: 2.352, Validation Loss: 5.764\n",
      "Epoch: 3470, Train Loss: 2.172, Validation Loss: 5.801\n",
      "Epoch: 3471, Train Loss: 2.360, Validation Loss: 5.832\n",
      "Epoch: 3472, Train Loss: 2.113, Validation Loss: 5.856\n",
      "Epoch: 3473, Train Loss: 2.472, Validation Loss: 5.799\n",
      "Epoch: 3474, Train Loss: 2.075, Validation Loss: 5.827\n",
      "Epoch: 3475, Train Loss: 2.540, Validation Loss: 5.790\n",
      "Epoch: 3476, Train Loss: 2.089, Validation Loss: 5.784\n",
      "Epoch: 3477, Train Loss: 2.020, Validation Loss: 5.793\n",
      "Epoch: 3478, Train Loss: 2.586, Validation Loss: 5.807\n",
      "Epoch: 3479, Train Loss: 2.544, Validation Loss: 5.815\n",
      "Epoch: 3480, Train Loss: 2.714, Validation Loss: 5.794\n",
      "Epoch: 3481, Train Loss: 1.995, Validation Loss: 5.823\n",
      "Epoch: 3482, Train Loss: 2.505, Validation Loss: 5.846\n",
      "Epoch: 3483, Train Loss: 1.926, Validation Loss: 5.853\n",
      "Epoch: 3484, Train Loss: 2.577, Validation Loss: 5.893\n",
      "Epoch: 3485, Train Loss: 2.142, Validation Loss: 5.837\n",
      "Epoch: 3486, Train Loss: 1.889, Validation Loss: 5.807\n",
      "Epoch: 3487, Train Loss: 2.066, Validation Loss: 5.836\n",
      "Epoch: 3488, Train Loss: 2.534, Validation Loss: 5.834\n",
      "Epoch: 3489, Train Loss: 2.338, Validation Loss: 5.846\n",
      "Epoch: 3490, Train Loss: 1.825, Validation Loss: 5.803\n",
      "Epoch: 3491, Train Loss: 1.966, Validation Loss: 5.799\n",
      "Epoch: 3492, Train Loss: 1.787, Validation Loss: 5.773\n",
      "Epoch: 3493, Train Loss: 2.045, Validation Loss: 5.785\n",
      "Epoch: 3494, Train Loss: 1.758, Validation Loss: 5.776\n",
      "Epoch: 3495, Train Loss: 2.428, Validation Loss: 5.772\n",
      "Epoch: 3496, Train Loss: 1.892, Validation Loss: 5.787\n",
      "Epoch: 3497, Train Loss: 2.042, Validation Loss: 5.784\n",
      "Epoch: 3498, Train Loss: 2.253, Validation Loss: 5.789\n",
      "Epoch: 3499, Train Loss: 2.086, Validation Loss: 5.779\n",
      "Epoch: 3500, Train Loss: 1.972, Validation Loss: 5.811\n",
      "Epoch: 3501, Train Loss: 2.757, Validation Loss: 5.857\n",
      "Epoch: 3502, Train Loss: 1.907, Validation Loss: 5.822\n",
      "Epoch: 3503, Train Loss: 2.044, Validation Loss: 5.828\n",
      "Epoch: 3504, Train Loss: 2.380, Validation Loss: 5.870\n",
      "Epoch: 3505, Train Loss: 2.262, Validation Loss: 5.852\n",
      "Epoch: 3506, Train Loss: 2.067, Validation Loss: 5.813\n",
      "Epoch: 3507, Train Loss: 2.531, Validation Loss: 5.836\n",
      "Epoch: 3508, Train Loss: 2.118, Validation Loss: 5.857\n",
      "Epoch: 3509, Train Loss: 2.053, Validation Loss: 5.878\n",
      "Epoch: 3510, Train Loss: 2.257, Validation Loss: 5.856\n",
      "Epoch: 3511, Train Loss: 2.335, Validation Loss: 5.899\n",
      "Epoch: 3512, Train Loss: 2.424, Validation Loss: 5.872\n",
      "Epoch: 3513, Train Loss: 2.358, Validation Loss: 5.876\n",
      "Epoch: 3514, Train Loss: 1.909, Validation Loss: 5.895\n",
      "Epoch: 3515, Train Loss: 2.161, Validation Loss: 5.887\n",
      "Epoch: 3516, Train Loss: 2.319, Validation Loss: 5.864\n",
      "Epoch: 3517, Train Loss: 2.321, Validation Loss: 5.882\n",
      "Epoch: 3518, Train Loss: 2.435, Validation Loss: 5.872\n",
      "Epoch: 3519, Train Loss: 2.037, Validation Loss: 5.866\n",
      "Epoch: 3520, Train Loss: 2.188, Validation Loss: 5.886\n",
      "Epoch: 3521, Train Loss: 2.060, Validation Loss: 5.870\n",
      "Epoch: 3522, Train Loss: 2.125, Validation Loss: 5.841\n",
      "Epoch: 3523, Train Loss: 2.414, Validation Loss: 5.814\n",
      "Epoch: 3524, Train Loss: 2.175, Validation Loss: 5.834\n",
      "Epoch: 3525, Train Loss: 2.651, Validation Loss: 5.877\n",
      "Epoch: 3526, Train Loss: 2.278, Validation Loss: 5.857\n",
      "Epoch: 3527, Train Loss: 1.987, Validation Loss: 5.850\n",
      "Epoch: 3528, Train Loss: 1.900, Validation Loss: 5.849\n",
      "Epoch: 3529, Train Loss: 2.517, Validation Loss: 5.840\n",
      "Epoch: 3530, Train Loss: 2.040, Validation Loss: 5.867\n",
      "Epoch: 3531, Train Loss: 2.898, Validation Loss: 5.871\n",
      "Epoch: 3532, Train Loss: 1.780, Validation Loss: 5.887\n",
      "Epoch: 3533, Train Loss: 2.549, Validation Loss: 5.846\n",
      "Epoch: 3534, Train Loss: 2.681, Validation Loss: 5.856\n",
      "Epoch: 3535, Train Loss: 2.820, Validation Loss: 5.862\n",
      "Epoch: 3536, Train Loss: 2.271, Validation Loss: 5.881\n",
      "Epoch: 3537, Train Loss: 2.370, Validation Loss: 5.856\n",
      "Epoch: 3538, Train Loss: 2.218, Validation Loss: 5.873\n",
      "Epoch: 3539, Train Loss: 2.060, Validation Loss: 5.875\n",
      "Epoch: 3540, Train Loss: 2.355, Validation Loss: 5.851\n",
      "Epoch: 3541, Train Loss: 2.117, Validation Loss: 5.837\n",
      "Epoch: 3542, Train Loss: 1.754, Validation Loss: 5.830\n",
      "Epoch: 3543, Train Loss: 2.288, Validation Loss: 5.883\n",
      "Epoch: 3544, Train Loss: 1.591, Validation Loss: 5.884\n",
      "Epoch: 3545, Train Loss: 2.299, Validation Loss: 5.912\n",
      "Epoch: 3546, Train Loss: 2.000, Validation Loss: 5.915\n",
      "Epoch: 3547, Train Loss: 2.191, Validation Loss: 5.974\n",
      "Epoch: 3548, Train Loss: 2.455, Validation Loss: 5.928\n",
      "Epoch: 3549, Train Loss: 2.266, Validation Loss: 5.960\n",
      "Epoch: 3550, Train Loss: 2.007, Validation Loss: 5.960\n",
      "Epoch: 3551, Train Loss: 2.036, Validation Loss: 5.932\n",
      "Epoch: 3552, Train Loss: 2.248, Validation Loss: 5.916\n",
      "Epoch: 3553, Train Loss: 2.242, Validation Loss: 5.920\n",
      "Epoch: 3554, Train Loss: 1.833, Validation Loss: 5.879\n",
      "Epoch: 3555, Train Loss: 1.915, Validation Loss: 5.887\n",
      "Epoch: 3556, Train Loss: 1.994, Validation Loss: 5.884\n",
      "Epoch: 3557, Train Loss: 1.964, Validation Loss: 5.906\n",
      "Epoch: 3558, Train Loss: 2.155, Validation Loss: 5.886\n",
      "Epoch: 3559, Train Loss: 2.538, Validation Loss: 5.909\n",
      "Epoch: 3560, Train Loss: 2.105, Validation Loss: 5.916\n",
      "Epoch: 3561, Train Loss: 2.051, Validation Loss: 5.914\n",
      "Epoch: 3562, Train Loss: 2.353, Validation Loss: 5.954\n",
      "Epoch: 3563, Train Loss: 2.947, Validation Loss: 5.901\n",
      "Epoch: 3564, Train Loss: 2.072, Validation Loss: 5.887\n",
      "Epoch: 3565, Train Loss: 2.034, Validation Loss: 5.864\n",
      "Epoch: 3566, Train Loss: 2.256, Validation Loss: 5.904\n",
      "Epoch: 3567, Train Loss: 2.314, Validation Loss: 5.924\n",
      "Epoch: 3568, Train Loss: 2.130, Validation Loss: 5.896\n",
      "Epoch: 3569, Train Loss: 2.397, Validation Loss: 5.897\n",
      "Epoch: 3570, Train Loss: 2.768, Validation Loss: 5.951\n",
      "Epoch: 3571, Train Loss: 2.171, Validation Loss: 5.952\n",
      "Epoch: 3572, Train Loss: 2.303, Validation Loss: 5.908\n",
      "Epoch: 3573, Train Loss: 2.400, Validation Loss: 5.883\n",
      "Epoch: 3574, Train Loss: 2.331, Validation Loss: 5.898\n",
      "Epoch: 3575, Train Loss: 1.842, Validation Loss: 5.846\n",
      "Epoch: 3576, Train Loss: 1.988, Validation Loss: 5.861\n",
      "Epoch: 3577, Train Loss: 1.846, Validation Loss: 5.868\n",
      "Epoch: 3578, Train Loss: 1.978, Validation Loss: 5.910\n",
      "Epoch: 3579, Train Loss: 2.123, Validation Loss: 5.893\n",
      "Epoch: 3580, Train Loss: 1.548, Validation Loss: 5.864\n",
      "Epoch: 3581, Train Loss: 2.394, Validation Loss: 5.858\n",
      "Epoch: 3582, Train Loss: 2.061, Validation Loss: 5.915\n",
      "Epoch: 3583, Train Loss: 1.845, Validation Loss: 5.880\n",
      "Epoch: 3584, Train Loss: 2.573, Validation Loss: 5.861\n",
      "Epoch: 3585, Train Loss: 2.480, Validation Loss: 5.911\n",
      "Epoch: 3586, Train Loss: 2.277, Validation Loss: 5.889\n",
      "Epoch: 3587, Train Loss: 1.815, Validation Loss: 5.928\n",
      "Epoch: 3588, Train Loss: 2.326, Validation Loss: 6.009\n",
      "Epoch: 3589, Train Loss: 1.765, Validation Loss: 5.954\n",
      "Epoch: 3590, Train Loss: 1.816, Validation Loss: 5.926\n",
      "Epoch: 3591, Train Loss: 2.144, Validation Loss: 5.910\n",
      "Epoch: 3592, Train Loss: 2.165, Validation Loss: 5.890\n",
      "Epoch: 3593, Train Loss: 2.165, Validation Loss: 5.903\n",
      "Epoch: 3594, Train Loss: 1.835, Validation Loss: 5.885\n",
      "Epoch: 3595, Train Loss: 2.162, Validation Loss: 5.896\n",
      "Epoch: 3596, Train Loss: 2.250, Validation Loss: 5.899\n",
      "Epoch: 3597, Train Loss: 1.740, Validation Loss: 5.922\n",
      "Epoch: 3598, Train Loss: 2.041, Validation Loss: 5.892\n",
      "Epoch: 3599, Train Loss: 2.149, Validation Loss: 5.887\n",
      "Epoch: 3600, Train Loss: 2.321, Validation Loss: 5.889\n",
      "Epoch: 3601, Train Loss: 2.488, Validation Loss: 5.906\n",
      "Epoch: 3602, Train Loss: 2.274, Validation Loss: 5.897\n",
      "Epoch: 3603, Train Loss: 2.327, Validation Loss: 5.892\n",
      "Epoch: 3604, Train Loss: 2.411, Validation Loss: 5.859\n",
      "Epoch: 3605, Train Loss: 2.111, Validation Loss: 5.857\n",
      "Epoch: 3606, Train Loss: 2.453, Validation Loss: 5.810\n",
      "Epoch: 3607, Train Loss: 2.071, Validation Loss: 5.777\n",
      "Epoch: 3608, Train Loss: 1.864, Validation Loss: 5.820\n",
      "Epoch: 3609, Train Loss: 2.112, Validation Loss: 5.798\n",
      "Epoch: 3610, Train Loss: 2.413, Validation Loss: 5.796\n",
      "Epoch: 3611, Train Loss: 2.039, Validation Loss: 5.827\n",
      "Epoch: 3612, Train Loss: 2.204, Validation Loss: 5.844\n",
      "Epoch: 3613, Train Loss: 2.127, Validation Loss: 5.867\n",
      "Epoch: 3614, Train Loss: 2.397, Validation Loss: 5.852\n",
      "Epoch: 3615, Train Loss: 2.324, Validation Loss: 5.882\n",
      "Epoch: 3616, Train Loss: 1.909, Validation Loss: 5.809\n",
      "Epoch: 3617, Train Loss: 2.195, Validation Loss: 5.829\n",
      "Epoch: 3618, Train Loss: 2.066, Validation Loss: 5.869\n",
      "Epoch: 3619, Train Loss: 2.278, Validation Loss: 5.900\n",
      "Epoch: 3620, Train Loss: 2.184, Validation Loss: 5.860\n",
      "Epoch: 3621, Train Loss: 2.451, Validation Loss: 5.848\n",
      "Epoch: 3622, Train Loss: 2.195, Validation Loss: 5.830\n",
      "Epoch: 3623, Train Loss: 1.675, Validation Loss: 5.830\n",
      "Epoch: 3624, Train Loss: 2.278, Validation Loss: 5.824\n",
      "Epoch: 3625, Train Loss: 1.935, Validation Loss: 5.896\n",
      "Epoch: 3626, Train Loss: 2.486, Validation Loss: 5.880\n",
      "Epoch: 3627, Train Loss: 1.832, Validation Loss: 5.868\n",
      "Epoch: 3628, Train Loss: 2.180, Validation Loss: 5.866\n",
      "Epoch: 3629, Train Loss: 2.361, Validation Loss: 5.870\n",
      "Epoch: 3630, Train Loss: 2.018, Validation Loss: 5.894\n",
      "Epoch: 3631, Train Loss: 2.226, Validation Loss: 5.883\n",
      "Epoch: 3632, Train Loss: 2.136, Validation Loss: 5.886\n",
      "Epoch: 3633, Train Loss: 1.700, Validation Loss: 5.868\n",
      "Epoch: 3634, Train Loss: 2.469, Validation Loss: 5.870\n",
      "Epoch: 3635, Train Loss: 2.304, Validation Loss: 5.832\n",
      "Epoch: 3636, Train Loss: 2.144, Validation Loss: 5.833\n",
      "Epoch: 3637, Train Loss: 1.997, Validation Loss: 5.849\n",
      "Epoch: 3638, Train Loss: 1.950, Validation Loss: 5.854\n",
      "Epoch: 3639, Train Loss: 2.088, Validation Loss: 5.846\n",
      "Epoch: 3640, Train Loss: 1.764, Validation Loss: 5.839\n",
      "Epoch: 3641, Train Loss: 2.272, Validation Loss: 5.834\n",
      "Epoch: 3642, Train Loss: 2.015, Validation Loss: 5.835\n",
      "Epoch: 3643, Train Loss: 2.217, Validation Loss: 5.869\n",
      "Epoch: 3644, Train Loss: 2.268, Validation Loss: 5.886\n",
      "Epoch: 3645, Train Loss: 2.036, Validation Loss: 5.888\n",
      "Epoch: 3646, Train Loss: 2.463, Validation Loss: 5.906\n",
      "Epoch: 3647, Train Loss: 2.459, Validation Loss: 5.918\n",
      "Epoch: 3648, Train Loss: 1.684, Validation Loss: 5.839\n",
      "Epoch: 3649, Train Loss: 2.093, Validation Loss: 5.812\n",
      "Epoch: 3650, Train Loss: 2.395, Validation Loss: 5.854\n",
      "Epoch: 3651, Train Loss: 1.851, Validation Loss: 5.842\n",
      "Epoch: 3652, Train Loss: 1.965, Validation Loss: 5.886\n",
      "Epoch: 3653, Train Loss: 2.059, Validation Loss: 5.959\n",
      "Epoch: 3654, Train Loss: 2.610, Validation Loss: 5.918\n",
      "Epoch: 3655, Train Loss: 2.377, Validation Loss: 5.924\n",
      "Epoch: 3656, Train Loss: 2.128, Validation Loss: 5.855\n",
      "Epoch: 3657, Train Loss: 2.357, Validation Loss: 5.891\n",
      "Epoch: 3658, Train Loss: 1.724, Validation Loss: 5.830\n",
      "Epoch: 3659, Train Loss: 2.727, Validation Loss: 5.815\n",
      "Epoch: 3660, Train Loss: 2.244, Validation Loss: 5.858\n",
      "Epoch: 3661, Train Loss: 2.217, Validation Loss: 5.868\n",
      "Epoch: 3662, Train Loss: 2.551, Validation Loss: 5.834\n",
      "Epoch: 3663, Train Loss: 2.794, Validation Loss: 5.869\n",
      "Epoch: 3664, Train Loss: 1.841, Validation Loss: 5.889\n",
      "Epoch: 3665, Train Loss: 1.784, Validation Loss: 5.890\n",
      "Epoch: 3666, Train Loss: 2.297, Validation Loss: 5.935\n",
      "Epoch: 3667, Train Loss: 2.132, Validation Loss: 5.906\n",
      "Epoch: 3668, Train Loss: 2.047, Validation Loss: 5.895\n",
      "Epoch: 3669, Train Loss: 2.455, Validation Loss: 5.877\n",
      "Epoch: 3670, Train Loss: 2.130, Validation Loss: 5.933\n",
      "Epoch: 3671, Train Loss: 1.821, Validation Loss: 5.922\n",
      "Epoch: 3672, Train Loss: 2.110, Validation Loss: 5.908\n",
      "Epoch: 3673, Train Loss: 2.187, Validation Loss: 5.988\n",
      "Epoch: 3674, Train Loss: 2.220, Validation Loss: 6.003\n",
      "Epoch: 3675, Train Loss: 2.286, Validation Loss: 6.000\n",
      "Epoch: 3676, Train Loss: 2.049, Validation Loss: 5.941\n",
      "Epoch: 3677, Train Loss: 2.006, Validation Loss: 5.931\n",
      "Epoch: 3678, Train Loss: 2.112, Validation Loss: 5.940\n",
      "Epoch: 3679, Train Loss: 1.809, Validation Loss: 5.943\n",
      "Epoch: 3680, Train Loss: 1.690, Validation Loss: 5.892\n",
      "Epoch: 3681, Train Loss: 2.562, Validation Loss: 5.922\n",
      "Epoch: 3682, Train Loss: 2.316, Validation Loss: 5.919\n",
      "Epoch: 3683, Train Loss: 2.412, Validation Loss: 5.929\n",
      "Epoch: 3684, Train Loss: 2.018, Validation Loss: 5.913\n",
      "Epoch: 3685, Train Loss: 1.924, Validation Loss: 5.948\n",
      "Epoch: 3686, Train Loss: 2.003, Validation Loss: 5.934\n",
      "Epoch: 3687, Train Loss: 2.040, Validation Loss: 5.904\n",
      "Epoch: 3688, Train Loss: 2.611, Validation Loss: 5.954\n",
      "Epoch: 3689, Train Loss: 2.035, Validation Loss: 5.914\n",
      "Epoch: 3690, Train Loss: 2.768, Validation Loss: 5.897\n",
      "Epoch: 3691, Train Loss: 2.059, Validation Loss: 5.901\n",
      "Epoch: 3692, Train Loss: 2.302, Validation Loss: 5.933\n",
      "Epoch: 3693, Train Loss: 2.098, Validation Loss: 5.958\n",
      "Epoch: 3694, Train Loss: 1.843, Validation Loss: 5.926\n",
      "Epoch: 3695, Train Loss: 1.990, Validation Loss: 5.916\n",
      "Epoch: 3696, Train Loss: 2.148, Validation Loss: 5.892\n",
      "Epoch: 3697, Train Loss: 2.449, Validation Loss: 5.912\n",
      "Epoch: 3698, Train Loss: 2.050, Validation Loss: 5.897\n",
      "Epoch: 3699, Train Loss: 2.222, Validation Loss: 5.879\n",
      "Epoch: 3700, Train Loss: 2.322, Validation Loss: 5.864\n",
      "Epoch: 3701, Train Loss: 1.861, Validation Loss: 5.899\n",
      "Epoch: 3702, Train Loss: 2.518, Validation Loss: 5.871\n",
      "Epoch: 3703, Train Loss: 2.059, Validation Loss: 5.894\n",
      "Epoch: 3704, Train Loss: 2.182, Validation Loss: 5.897\n",
      "Epoch: 3705, Train Loss: 2.089, Validation Loss: 5.924\n",
      "Epoch: 3706, Train Loss: 1.631, Validation Loss: 5.897\n",
      "Epoch: 3707, Train Loss: 2.003, Validation Loss: 5.888\n",
      "Epoch: 3708, Train Loss: 1.869, Validation Loss: 5.904\n",
      "Epoch: 3709, Train Loss: 2.115, Validation Loss: 5.930\n",
      "Epoch: 3710, Train Loss: 2.439, Validation Loss: 5.913\n",
      "Epoch: 3711, Train Loss: 1.949, Validation Loss: 5.874\n",
      "Epoch: 3712, Train Loss: 1.899, Validation Loss: 5.904\n",
      "Epoch: 3713, Train Loss: 1.560, Validation Loss: 5.903\n",
      "Epoch: 3714, Train Loss: 2.351, Validation Loss: 5.896\n",
      "Epoch: 3715, Train Loss: 1.919, Validation Loss: 5.906\n",
      "Epoch: 3716, Train Loss: 1.746, Validation Loss: 5.890\n",
      "Epoch: 3717, Train Loss: 2.002, Validation Loss: 5.875\n",
      "Epoch: 3718, Train Loss: 2.472, Validation Loss: 5.857\n",
      "Epoch: 3719, Train Loss: 2.093, Validation Loss: 5.874\n",
      "Epoch: 3720, Train Loss: 1.827, Validation Loss: 5.914\n",
      "Epoch: 3721, Train Loss: 1.896, Validation Loss: 5.870\n",
      "Epoch: 3722, Train Loss: 1.708, Validation Loss: 5.892\n",
      "Epoch: 3723, Train Loss: 2.341, Validation Loss: 5.888\n",
      "Epoch: 3724, Train Loss: 2.217, Validation Loss: 5.864\n",
      "Epoch: 3725, Train Loss: 2.007, Validation Loss: 5.878\n",
      "Epoch: 3726, Train Loss: 1.890, Validation Loss: 5.856\n",
      "Epoch: 3727, Train Loss: 1.683, Validation Loss: 5.816\n",
      "Epoch: 3728, Train Loss: 2.117, Validation Loss: 5.818\n",
      "Epoch: 3729, Train Loss: 1.973, Validation Loss: 5.845\n",
      "Epoch: 3730, Train Loss: 2.043, Validation Loss: 5.859\n",
      "Epoch: 3731, Train Loss: 2.152, Validation Loss: 5.804\n",
      "Epoch: 3732, Train Loss: 2.276, Validation Loss: 5.771\n",
      "Epoch: 3733, Train Loss: 2.161, Validation Loss: 5.797\n",
      "Epoch: 3734, Train Loss: 2.453, Validation Loss: 5.814\n",
      "Epoch: 3735, Train Loss: 2.538, Validation Loss: 5.861\n",
      "Epoch: 3736, Train Loss: 2.034, Validation Loss: 5.868\n",
      "Epoch: 3737, Train Loss: 1.674, Validation Loss: 5.861\n",
      "Epoch: 3738, Train Loss: 1.865, Validation Loss: 5.852\n",
      "Epoch: 3739, Train Loss: 2.421, Validation Loss: 5.861\n",
      "Epoch: 3740, Train Loss: 2.206, Validation Loss: 5.839\n",
      "Epoch: 3741, Train Loss: 2.161, Validation Loss: 5.819\n",
      "Epoch: 3742, Train Loss: 2.406, Validation Loss: 5.833\n",
      "Epoch: 3743, Train Loss: 2.035, Validation Loss: 5.814\n",
      "Epoch: 3744, Train Loss: 2.773, Validation Loss: 5.856\n",
      "Epoch: 3745, Train Loss: 2.507, Validation Loss: 5.851\n",
      "Epoch: 3746, Train Loss: 2.041, Validation Loss: 5.799\n",
      "Epoch: 3747, Train Loss: 1.973, Validation Loss: 5.796\n",
      "Epoch: 3748, Train Loss: 1.791, Validation Loss: 5.810\n",
      "Epoch: 3749, Train Loss: 1.902, Validation Loss: 5.815\n",
      "Epoch: 3750, Train Loss: 2.224, Validation Loss: 5.830\n",
      "Epoch: 3751, Train Loss: 2.212, Validation Loss: 5.807\n",
      "Epoch: 3752, Train Loss: 2.212, Validation Loss: 5.809\n",
      "Epoch: 3753, Train Loss: 2.039, Validation Loss: 5.874\n",
      "Epoch: 3754, Train Loss: 1.701, Validation Loss: 5.902\n",
      "Epoch: 3755, Train Loss: 2.085, Validation Loss: 5.864\n",
      "Epoch: 3756, Train Loss: 1.906, Validation Loss: 5.863\n",
      "Epoch: 3757, Train Loss: 2.233, Validation Loss: 5.849\n",
      "Epoch: 3758, Train Loss: 2.296, Validation Loss: 5.865\n",
      "Epoch: 3759, Train Loss: 1.875, Validation Loss: 5.913\n",
      "Epoch: 3760, Train Loss: 2.184, Validation Loss: 5.877\n",
      "Epoch: 3761, Train Loss: 2.112, Validation Loss: 5.876\n",
      "Epoch: 3762, Train Loss: 2.458, Validation Loss: 5.865\n",
      "Epoch: 3763, Train Loss: 2.310, Validation Loss: 5.861\n",
      "Epoch: 3764, Train Loss: 2.520, Validation Loss: 5.888\n",
      "Epoch: 3765, Train Loss: 2.347, Validation Loss: 5.914\n",
      "Epoch: 3766, Train Loss: 1.976, Validation Loss: 5.880\n",
      "Epoch: 3767, Train Loss: 2.158, Validation Loss: 5.907\n",
      "Epoch: 3768, Train Loss: 1.955, Validation Loss: 5.877\n",
      "Epoch: 3769, Train Loss: 2.158, Validation Loss: 5.869\n",
      "Epoch: 3770, Train Loss: 2.709, Validation Loss: 5.895\n",
      "Epoch: 3771, Train Loss: 2.016, Validation Loss: 5.903\n",
      "Epoch: 3772, Train Loss: 1.853, Validation Loss: 5.842\n",
      "Epoch: 3773, Train Loss: 2.087, Validation Loss: 5.814\n",
      "Epoch: 3774, Train Loss: 1.552, Validation Loss: 5.820\n",
      "Epoch: 3775, Train Loss: 1.870, Validation Loss: 5.787\n",
      "Epoch: 3776, Train Loss: 2.399, Validation Loss: 5.826\n",
      "Epoch: 3777, Train Loss: 2.018, Validation Loss: 5.817\n",
      "Epoch: 3778, Train Loss: 2.171, Validation Loss: 5.853\n",
      "Epoch: 3779, Train Loss: 2.129, Validation Loss: 5.839\n",
      "Epoch: 3780, Train Loss: 2.207, Validation Loss: 5.812\n",
      "Epoch: 3781, Train Loss: 2.008, Validation Loss: 5.800\n",
      "Epoch: 3782, Train Loss: 1.985, Validation Loss: 5.817\n",
      "Epoch: 3783, Train Loss: 2.008, Validation Loss: 5.841\n",
      "Epoch: 3784, Train Loss: 1.901, Validation Loss: 5.843\n",
      "Epoch: 3785, Train Loss: 2.200, Validation Loss: 5.864\n",
      "Epoch: 3786, Train Loss: 1.881, Validation Loss: 5.863\n",
      "Epoch: 3787, Train Loss: 1.934, Validation Loss: 5.817\n",
      "Epoch: 3788, Train Loss: 2.233, Validation Loss: 5.859\n",
      "Epoch: 3789, Train Loss: 2.012, Validation Loss: 5.809\n",
      "Epoch: 3790, Train Loss: 2.276, Validation Loss: 5.836\n",
      "Epoch: 3791, Train Loss: 2.581, Validation Loss: 5.832\n",
      "Epoch: 3792, Train Loss: 2.016, Validation Loss: 5.851\n",
      "Epoch: 3793, Train Loss: 1.922, Validation Loss: 5.858\n",
      "Epoch: 3794, Train Loss: 1.916, Validation Loss: 5.841\n",
      "Epoch: 3795, Train Loss: 2.320, Validation Loss: 5.877\n",
      "Epoch: 3796, Train Loss: 2.227, Validation Loss: 5.866\n",
      "Epoch: 3797, Train Loss: 2.237, Validation Loss: 5.825\n",
      "Epoch: 3798, Train Loss: 1.823, Validation Loss: 5.822\n",
      "Epoch: 3799, Train Loss: 1.925, Validation Loss: 5.856\n",
      "Epoch: 3800, Train Loss: 2.017, Validation Loss: 5.856\n",
      "Epoch: 3801, Train Loss: 2.093, Validation Loss: 5.836\n",
      "Epoch: 3802, Train Loss: 1.696, Validation Loss: 5.869\n",
      "Epoch: 3803, Train Loss: 1.971, Validation Loss: 5.825\n",
      "Epoch: 3804, Train Loss: 2.084, Validation Loss: 5.833\n",
      "Epoch: 3805, Train Loss: 2.071, Validation Loss: 5.814\n",
      "Epoch: 3806, Train Loss: 2.229, Validation Loss: 5.828\n",
      "Epoch: 3807, Train Loss: 2.565, Validation Loss: 5.838\n",
      "Epoch: 3808, Train Loss: 2.079, Validation Loss: 5.803\n",
      "Epoch: 3809, Train Loss: 1.858, Validation Loss: 5.820\n",
      "Epoch: 3810, Train Loss: 2.003, Validation Loss: 5.867\n",
      "Epoch: 3811, Train Loss: 2.396, Validation Loss: 5.835\n",
      "Epoch: 3812, Train Loss: 2.012, Validation Loss: 5.834\n",
      "Epoch: 3813, Train Loss: 2.294, Validation Loss: 5.789\n",
      "Epoch: 3814, Train Loss: 1.937, Validation Loss: 5.783\n",
      "Epoch: 3815, Train Loss: 2.768, Validation Loss: 5.829\n",
      "Epoch: 3816, Train Loss: 2.169, Validation Loss: 5.905\n",
      "Epoch: 3817, Train Loss: 1.645, Validation Loss: 5.866\n",
      "Epoch: 3818, Train Loss: 2.196, Validation Loss: 5.865\n",
      "Epoch: 3819, Train Loss: 2.235, Validation Loss: 5.900\n",
      "Epoch: 3820, Train Loss: 1.871, Validation Loss: 5.846\n",
      "Epoch: 3821, Train Loss: 2.097, Validation Loss: 5.842\n",
      "Epoch: 3822, Train Loss: 2.153, Validation Loss: 5.830\n",
      "Epoch: 3823, Train Loss: 2.394, Validation Loss: 5.787\n",
      "Epoch: 3824, Train Loss: 1.937, Validation Loss: 5.791\n",
      "Epoch: 3825, Train Loss: 2.113, Validation Loss: 5.789\n",
      "Epoch: 3826, Train Loss: 2.377, Validation Loss: 5.823\n",
      "Epoch: 3827, Train Loss: 2.605, Validation Loss: 5.807\n",
      "Epoch: 3828, Train Loss: 2.286, Validation Loss: 5.832\n",
      "Epoch: 3829, Train Loss: 1.856, Validation Loss: 5.817\n",
      "Epoch: 3830, Train Loss: 2.507, Validation Loss: 5.904\n",
      "Epoch: 3831, Train Loss: 1.936, Validation Loss: 5.882\n",
      "Epoch: 3832, Train Loss: 2.132, Validation Loss: 5.858\n",
      "Epoch: 3833, Train Loss: 2.329, Validation Loss: 5.831\n",
      "Epoch: 3834, Train Loss: 2.253, Validation Loss: 5.830\n",
      "Epoch: 3835, Train Loss: 2.304, Validation Loss: 5.811\n",
      "Epoch: 3836, Train Loss: 2.192, Validation Loss: 5.821\n",
      "Epoch: 3837, Train Loss: 2.123, Validation Loss: 5.881\n",
      "Epoch: 3838, Train Loss: 2.138, Validation Loss: 5.960\n",
      "Epoch: 3839, Train Loss: 1.956, Validation Loss: 5.925\n",
      "Epoch: 3840, Train Loss: 2.212, Validation Loss: 5.900\n",
      "Epoch: 3841, Train Loss: 2.481, Validation Loss: 5.867\n",
      "Epoch: 3842, Train Loss: 2.540, Validation Loss: 5.853\n",
      "Epoch: 3843, Train Loss: 1.828, Validation Loss: 5.892\n",
      "Epoch: 3844, Train Loss: 2.004, Validation Loss: 5.868\n",
      "Epoch: 3845, Train Loss: 1.890, Validation Loss: 5.893\n",
      "Epoch: 3846, Train Loss: 2.218, Validation Loss: 5.906\n",
      "Epoch: 3847, Train Loss: 1.792, Validation Loss: 5.856\n",
      "Epoch: 3848, Train Loss: 1.886, Validation Loss: 5.881\n",
      "Epoch: 3849, Train Loss: 2.107, Validation Loss: 5.894\n",
      "Epoch: 3850, Train Loss: 2.210, Validation Loss: 5.893\n",
      "Epoch: 3851, Train Loss: 1.982, Validation Loss: 5.882\n",
      "Epoch: 3852, Train Loss: 2.133, Validation Loss: 5.894\n",
      "Epoch: 3853, Train Loss: 1.997, Validation Loss: 5.863\n",
      "Epoch: 3854, Train Loss: 2.198, Validation Loss: 5.878\n",
      "Epoch: 3855, Train Loss: 2.010, Validation Loss: 5.814\n",
      "Epoch: 3856, Train Loss: 2.178, Validation Loss: 5.821\n",
      "Epoch: 3857, Train Loss: 1.994, Validation Loss: 5.842\n",
      "Epoch: 3858, Train Loss: 1.654, Validation Loss: 5.818\n",
      "Epoch: 3859, Train Loss: 2.154, Validation Loss: 5.859\n",
      "Epoch: 3860, Train Loss: 2.363, Validation Loss: 5.871\n",
      "Epoch: 3861, Train Loss: 2.405, Validation Loss: 5.847\n",
      "Epoch: 3862, Train Loss: 1.882, Validation Loss: 5.879\n",
      "Epoch: 3863, Train Loss: 1.909, Validation Loss: 5.827\n",
      "Epoch: 3864, Train Loss: 1.689, Validation Loss: 5.820\n",
      "Epoch: 3865, Train Loss: 2.106, Validation Loss: 5.797\n",
      "Epoch: 3866, Train Loss: 1.776, Validation Loss: 5.780\n",
      "Epoch: 3867, Train Loss: 2.006, Validation Loss: 5.828\n",
      "Epoch: 3868, Train Loss: 1.921, Validation Loss: 5.806\n",
      "Epoch: 3869, Train Loss: 2.747, Validation Loss: 5.783\n",
      "Epoch: 3870, Train Loss: 2.141, Validation Loss: 5.763\n",
      "Epoch: 3871, Train Loss: 2.258, Validation Loss: 5.805\n",
      "Epoch: 3872, Train Loss: 1.940, Validation Loss: 5.820\n",
      "Epoch: 3873, Train Loss: 2.214, Validation Loss: 5.801\n",
      "Epoch: 3874, Train Loss: 2.236, Validation Loss: 5.818\n",
      "Epoch: 3875, Train Loss: 2.089, Validation Loss: 5.844\n",
      "Epoch: 3876, Train Loss: 2.022, Validation Loss: 5.838\n",
      "Epoch: 3877, Train Loss: 1.933, Validation Loss: 5.842\n",
      "Epoch: 3878, Train Loss: 1.870, Validation Loss: 5.824\n",
      "Epoch: 3879, Train Loss: 2.447, Validation Loss: 5.786\n",
      "Epoch: 3880, Train Loss: 2.271, Validation Loss: 5.789\n",
      "Epoch: 3881, Train Loss: 2.075, Validation Loss: 5.804\n",
      "Epoch: 3882, Train Loss: 1.704, Validation Loss: 5.834\n",
      "Epoch: 3883, Train Loss: 1.930, Validation Loss: 5.835\n",
      "Epoch: 3884, Train Loss: 1.383, Validation Loss: 5.788\n",
      "Epoch: 3885, Train Loss: 1.723, Validation Loss: 5.835\n",
      "Epoch: 3886, Train Loss: 2.240, Validation Loss: 5.824\n",
      "Epoch: 3887, Train Loss: 2.491, Validation Loss: 5.832\n",
      "Epoch: 3888, Train Loss: 1.930, Validation Loss: 5.827\n",
      "Epoch: 3889, Train Loss: 2.190, Validation Loss: 5.855\n",
      "Epoch: 3890, Train Loss: 2.088, Validation Loss: 5.928\n",
      "Epoch: 3891, Train Loss: 1.986, Validation Loss: 5.938\n",
      "Epoch: 3892, Train Loss: 2.131, Validation Loss: 5.937\n",
      "Epoch: 3893, Train Loss: 1.914, Validation Loss: 5.908\n",
      "Epoch: 3894, Train Loss: 2.281, Validation Loss: 5.874\n",
      "Epoch: 3895, Train Loss: 2.360, Validation Loss: 5.895\n",
      "Epoch: 3896, Train Loss: 1.938, Validation Loss: 5.888\n",
      "Epoch: 3897, Train Loss: 2.360, Validation Loss: 5.882\n",
      "Epoch: 3898, Train Loss: 1.627, Validation Loss: 5.886\n",
      "Epoch: 3899, Train Loss: 1.710, Validation Loss: 5.911\n",
      "Epoch: 3900, Train Loss: 1.851, Validation Loss: 5.926\n",
      "Epoch: 3901, Train Loss: 2.012, Validation Loss: 5.955\n",
      "Epoch: 3902, Train Loss: 2.393, Validation Loss: 5.963\n",
      "Epoch: 3903, Train Loss: 1.808, Validation Loss: 5.950\n",
      "Epoch: 3904, Train Loss: 2.456, Validation Loss: 5.922\n",
      "Epoch: 3905, Train Loss: 2.297, Validation Loss: 5.920\n",
      "Epoch: 3906, Train Loss: 1.802, Validation Loss: 5.905\n",
      "Epoch: 3907, Train Loss: 2.009, Validation Loss: 5.944\n",
      "Epoch: 3908, Train Loss: 1.939, Validation Loss: 5.893\n",
      "Epoch: 3909, Train Loss: 2.115, Validation Loss: 5.888\n",
      "Epoch: 3910, Train Loss: 2.010, Validation Loss: 5.892\n",
      "Epoch: 3911, Train Loss: 2.016, Validation Loss: 5.887\n",
      "Epoch: 3912, Train Loss: 1.670, Validation Loss: 5.913\n",
      "Epoch: 3913, Train Loss: 1.934, Validation Loss: 5.871\n",
      "Epoch: 3914, Train Loss: 2.732, Validation Loss: 5.868\n",
      "Epoch: 3915, Train Loss: 2.161, Validation Loss: 5.897\n",
      "Epoch: 3916, Train Loss: 2.015, Validation Loss: 5.910\n",
      "Epoch: 3917, Train Loss: 2.194, Validation Loss: 5.842\n",
      "Epoch: 3918, Train Loss: 2.285, Validation Loss: 5.861\n",
      "Epoch: 3919, Train Loss: 1.873, Validation Loss: 5.839\n",
      "Epoch: 3920, Train Loss: 2.213, Validation Loss: 5.836\n",
      "Epoch: 3921, Train Loss: 2.008, Validation Loss: 5.868\n",
      "Epoch: 3922, Train Loss: 2.392, Validation Loss: 5.843\n",
      "Epoch: 3923, Train Loss: 2.209, Validation Loss: 5.857\n",
      "Epoch: 3924, Train Loss: 2.009, Validation Loss: 5.858\n",
      "Epoch: 3925, Train Loss: 2.269, Validation Loss: 5.901\n",
      "Epoch: 3926, Train Loss: 1.476, Validation Loss: 5.852\n",
      "Epoch: 3927, Train Loss: 2.245, Validation Loss: 5.874\n",
      "Epoch: 3928, Train Loss: 1.993, Validation Loss: 5.899\n",
      "Epoch: 3929, Train Loss: 2.770, Validation Loss: 5.929\n",
      "Epoch: 3930, Train Loss: 1.795, Validation Loss: 5.933\n",
      "Epoch: 3931, Train Loss: 2.152, Validation Loss: 5.977\n",
      "Epoch: 3932, Train Loss: 1.900, Validation Loss: 5.939\n",
      "Epoch: 3933, Train Loss: 1.953, Validation Loss: 5.888\n",
      "Epoch: 3934, Train Loss: 2.079, Validation Loss: 5.841\n",
      "Epoch: 3935, Train Loss: 1.917, Validation Loss: 5.844\n",
      "Epoch: 3936, Train Loss: 1.749, Validation Loss: 5.830\n",
      "Epoch: 3937, Train Loss: 2.257, Validation Loss: 5.830\n",
      "Epoch: 3938, Train Loss: 1.990, Validation Loss: 5.844\n",
      "Epoch: 3939, Train Loss: 2.205, Validation Loss: 5.834\n",
      "Epoch: 3940, Train Loss: 2.030, Validation Loss: 5.858\n",
      "Epoch: 3941, Train Loss: 2.133, Validation Loss: 5.879\n",
      "Epoch: 3942, Train Loss: 2.417, Validation Loss: 5.894\n",
      "Epoch: 3943, Train Loss: 1.843, Validation Loss: 5.865\n",
      "Epoch: 3944, Train Loss: 1.946, Validation Loss: 5.885\n",
      "Epoch: 3945, Train Loss: 1.935, Validation Loss: 5.860\n",
      "Epoch: 3946, Train Loss: 1.907, Validation Loss: 5.909\n",
      "Epoch: 3947, Train Loss: 1.438, Validation Loss: 5.846\n",
      "Epoch: 3948, Train Loss: 2.158, Validation Loss: 5.859\n",
      "Epoch: 3949, Train Loss: 1.817, Validation Loss: 5.883\n",
      "Epoch: 3950, Train Loss: 2.373, Validation Loss: 5.894\n",
      "Epoch: 3951, Train Loss: 1.973, Validation Loss: 5.872\n",
      "Epoch: 3952, Train Loss: 1.967, Validation Loss: 5.909\n",
      "Epoch: 3953, Train Loss: 1.744, Validation Loss: 5.930\n",
      "Epoch: 3954, Train Loss: 1.929, Validation Loss: 5.885\n",
      "Epoch: 3955, Train Loss: 1.894, Validation Loss: 5.922\n",
      "Epoch: 3956, Train Loss: 2.216, Validation Loss: 5.945\n",
      "Epoch: 3957, Train Loss: 2.057, Validation Loss: 5.925\n",
      "Epoch: 3958, Train Loss: 1.932, Validation Loss: 5.926\n",
      "Epoch: 3959, Train Loss: 2.037, Validation Loss: 5.895\n",
      "Epoch: 3960, Train Loss: 2.001, Validation Loss: 5.939\n",
      "Epoch: 3961, Train Loss: 2.205, Validation Loss: 5.963\n",
      "Epoch: 3962, Train Loss: 2.146, Validation Loss: 5.946\n",
      "Epoch: 3963, Train Loss: 1.629, Validation Loss: 5.904\n",
      "Epoch: 3964, Train Loss: 1.970, Validation Loss: 5.886\n",
      "Epoch: 3965, Train Loss: 1.742, Validation Loss: 5.858\n",
      "Epoch: 3966, Train Loss: 1.791, Validation Loss: 5.865\n",
      "Epoch: 3967, Train Loss: 2.320, Validation Loss: 5.874\n",
      "Epoch: 3968, Train Loss: 2.124, Validation Loss: 5.879\n",
      "Epoch: 3969, Train Loss: 1.977, Validation Loss: 5.870\n",
      "Epoch: 3970, Train Loss: 2.101, Validation Loss: 5.873\n",
      "Epoch: 3971, Train Loss: 1.970, Validation Loss: 5.888\n",
      "Epoch: 3972, Train Loss: 2.495, Validation Loss: 5.920\n",
      "Epoch: 3973, Train Loss: 1.652, Validation Loss: 5.898\n",
      "Epoch: 3974, Train Loss: 1.817, Validation Loss: 5.882\n",
      "Epoch: 3975, Train Loss: 1.735, Validation Loss: 5.893\n",
      "Epoch: 3976, Train Loss: 2.123, Validation Loss: 5.833\n",
      "Epoch: 3977, Train Loss: 1.899, Validation Loss: 5.834\n",
      "Epoch: 3978, Train Loss: 1.790, Validation Loss: 5.862\n",
      "Epoch: 3979, Train Loss: 2.257, Validation Loss: 5.852\n",
      "Epoch: 3980, Train Loss: 2.046, Validation Loss: 5.835\n",
      "Epoch: 3981, Train Loss: 2.073, Validation Loss: 5.854\n",
      "Epoch: 3982, Train Loss: 2.107, Validation Loss: 5.854\n",
      "Epoch: 3983, Train Loss: 2.005, Validation Loss: 5.864\n",
      "Epoch: 3984, Train Loss: 1.972, Validation Loss: 5.918\n",
      "Epoch: 3985, Train Loss: 2.072, Validation Loss: 5.918\n",
      "Epoch: 3986, Train Loss: 1.654, Validation Loss: 5.884\n",
      "Epoch: 3987, Train Loss: 1.721, Validation Loss: 5.856\n",
      "Epoch: 3988, Train Loss: 1.867, Validation Loss: 5.854\n",
      "Epoch: 3989, Train Loss: 2.370, Validation Loss: 5.822\n",
      "Epoch: 3990, Train Loss: 1.894, Validation Loss: 5.801\n",
      "Epoch: 3991, Train Loss: 1.640, Validation Loss: 5.813\n",
      "Epoch: 3992, Train Loss: 2.260, Validation Loss: 5.866\n",
      "Epoch: 3993, Train Loss: 1.741, Validation Loss: 5.849\n",
      "Epoch: 3994, Train Loss: 1.634, Validation Loss: 5.816\n",
      "Epoch: 3995, Train Loss: 1.982, Validation Loss: 5.803\n",
      "Epoch: 3996, Train Loss: 2.152, Validation Loss: 5.816\n",
      "Epoch: 3997, Train Loss: 2.368, Validation Loss: 5.813\n",
      "Epoch: 3998, Train Loss: 2.099, Validation Loss: 5.801\n",
      "Epoch: 3999, Train Loss: 2.056, Validation Loss: 5.819\n",
      "Epoch: 4000, Train Loss: 2.011, Validation Loss: 5.805\n",
      "Epoch: 4001, Train Loss: 1.964, Validation Loss: 5.826\n",
      "Epoch: 4002, Train Loss: 1.853, Validation Loss: 5.803\n",
      "Epoch: 4003, Train Loss: 2.178, Validation Loss: 5.786\n",
      "Epoch: 4004, Train Loss: 2.032, Validation Loss: 5.759\n",
      "Epoch: 4005, Train Loss: 1.977, Validation Loss: 5.785\n",
      "Epoch: 4006, Train Loss: 2.119, Validation Loss: 5.804\n",
      "Epoch: 4007, Train Loss: 1.635, Validation Loss: 5.801\n",
      "Epoch: 4008, Train Loss: 2.283, Validation Loss: 5.790\n",
      "Epoch: 4009, Train Loss: 2.208, Validation Loss: 5.861\n",
      "Epoch: 4010, Train Loss: 2.189, Validation Loss: 5.874\n",
      "Epoch: 4011, Train Loss: 1.928, Validation Loss: 5.795\n",
      "Epoch: 4012, Train Loss: 1.963, Validation Loss: 5.820\n",
      "Epoch: 4013, Train Loss: 1.774, Validation Loss: 5.843\n",
      "Epoch: 4014, Train Loss: 1.937, Validation Loss: 5.835\n",
      "Epoch: 4015, Train Loss: 1.812, Validation Loss: 5.851\n",
      "Epoch: 4016, Train Loss: 2.078, Validation Loss: 5.846\n",
      "Epoch: 4017, Train Loss: 1.912, Validation Loss: 5.878\n",
      "Epoch: 4018, Train Loss: 2.193, Validation Loss: 5.885\n",
      "Epoch: 4019, Train Loss: 1.858, Validation Loss: 5.853\n",
      "Epoch: 4020, Train Loss: 2.020, Validation Loss: 5.862\n",
      "Epoch: 4021, Train Loss: 1.934, Validation Loss: 5.886\n",
      "Epoch: 4022, Train Loss: 2.184, Validation Loss: 5.905\n",
      "Epoch: 4023, Train Loss: 1.704, Validation Loss: 5.937\n",
      "Epoch: 4024, Train Loss: 2.527, Validation Loss: 5.986\n",
      "Epoch: 4025, Train Loss: 2.294, Validation Loss: 5.990\n",
      "Epoch: 4026, Train Loss: 2.166, Validation Loss: 5.957\n",
      "Epoch: 4027, Train Loss: 1.789, Validation Loss: 5.907\n",
      "Epoch: 4028, Train Loss: 2.661, Validation Loss: 5.923\n",
      "Epoch: 4029, Train Loss: 1.980, Validation Loss: 5.846\n",
      "Epoch: 4030, Train Loss: 1.814, Validation Loss: 5.843\n",
      "Epoch: 4031, Train Loss: 2.085, Validation Loss: 5.839\n",
      "Epoch: 4032, Train Loss: 1.854, Validation Loss: 5.845\n",
      "Epoch: 4033, Train Loss: 1.775, Validation Loss: 5.790\n",
      "Epoch: 4034, Train Loss: 1.915, Validation Loss: 5.822\n",
      "Epoch: 4035, Train Loss: 1.754, Validation Loss: 5.778\n",
      "Epoch: 4036, Train Loss: 1.894, Validation Loss: 5.796\n",
      "Epoch: 4037, Train Loss: 2.100, Validation Loss: 5.829\n",
      "Epoch: 4038, Train Loss: 2.123, Validation Loss: 5.801\n",
      "Epoch: 4039, Train Loss: 1.733, Validation Loss: 5.832\n",
      "Epoch: 4040, Train Loss: 2.224, Validation Loss: 5.850\n",
      "Epoch: 4041, Train Loss: 2.115, Validation Loss: 5.876\n",
      "Epoch: 4042, Train Loss: 2.023, Validation Loss: 5.934\n",
      "Epoch: 4043, Train Loss: 1.960, Validation Loss: 5.944\n",
      "Epoch: 4044, Train Loss: 2.190, Validation Loss: 5.926\n",
      "Epoch: 4045, Train Loss: 2.078, Validation Loss: 5.880\n",
      "Epoch: 4046, Train Loss: 1.821, Validation Loss: 5.864\n",
      "Epoch: 4047, Train Loss: 2.194, Validation Loss: 5.855\n",
      "Epoch: 4048, Train Loss: 1.825, Validation Loss: 5.893\n",
      "Epoch: 4049, Train Loss: 2.528, Validation Loss: 5.871\n",
      "Epoch: 4050, Train Loss: 2.325, Validation Loss: 5.917\n",
      "Epoch: 4051, Train Loss: 2.006, Validation Loss: 5.925\n",
      "Epoch: 4052, Train Loss: 2.106, Validation Loss: 5.933\n",
      "Epoch: 4053, Train Loss: 2.045, Validation Loss: 5.888\n",
      "Epoch: 4054, Train Loss: 2.372, Validation Loss: 5.880\n",
      "Epoch: 4055, Train Loss: 2.254, Validation Loss: 5.878\n",
      "Epoch: 4056, Train Loss: 1.898, Validation Loss: 5.894\n",
      "Epoch: 4057, Train Loss: 1.597, Validation Loss: 5.851\n",
      "Epoch: 4058, Train Loss: 1.992, Validation Loss: 5.867\n",
      "Epoch: 4059, Train Loss: 2.329, Validation Loss: 5.876\n",
      "Epoch: 4060, Train Loss: 1.873, Validation Loss: 5.861\n",
      "Epoch: 4061, Train Loss: 1.945, Validation Loss: 5.904\n",
      "Epoch: 4062, Train Loss: 1.799, Validation Loss: 5.880\n",
      "Epoch: 4063, Train Loss: 2.297, Validation Loss: 5.883\n",
      "Epoch: 4064, Train Loss: 1.941, Validation Loss: 5.848\n",
      "Epoch: 4065, Train Loss: 2.254, Validation Loss: 5.896\n",
      "Epoch: 4066, Train Loss: 1.579, Validation Loss: 5.916\n",
      "Epoch: 4067, Train Loss: 1.771, Validation Loss: 5.905\n",
      "Epoch: 4068, Train Loss: 1.860, Validation Loss: 5.877\n",
      "Epoch: 4069, Train Loss: 2.541, Validation Loss: 5.842\n",
      "Epoch: 4070, Train Loss: 1.837, Validation Loss: 5.804\n",
      "Epoch: 4071, Train Loss: 1.939, Validation Loss: 5.837\n",
      "Epoch: 4072, Train Loss: 2.335, Validation Loss: 5.802\n",
      "Epoch: 4073, Train Loss: 2.087, Validation Loss: 5.850\n",
      "Epoch: 4074, Train Loss: 1.753, Validation Loss: 5.843\n",
      "Epoch: 4075, Train Loss: 1.862, Validation Loss: 5.845\n",
      "Epoch: 4076, Train Loss: 2.342, Validation Loss: 5.848\n",
      "Epoch: 4077, Train Loss: 1.912, Validation Loss: 5.864\n",
      "Epoch: 4078, Train Loss: 2.368, Validation Loss: 5.837\n",
      "Epoch: 4079, Train Loss: 1.886, Validation Loss: 5.823\n",
      "Epoch: 4080, Train Loss: 1.632, Validation Loss: 5.824\n",
      "Epoch: 4081, Train Loss: 1.790, Validation Loss: 5.829\n",
      "Epoch: 4082, Train Loss: 2.017, Validation Loss: 5.871\n",
      "Epoch: 4083, Train Loss: 2.068, Validation Loss: 5.845\n",
      "Epoch: 4084, Train Loss: 1.887, Validation Loss: 5.817\n",
      "Epoch: 4085, Train Loss: 1.767, Validation Loss: 5.847\n",
      "Epoch: 4086, Train Loss: 2.044, Validation Loss: 5.863\n",
      "Epoch: 4087, Train Loss: 2.065, Validation Loss: 5.907\n",
      "Epoch: 4088, Train Loss: 2.463, Validation Loss: 5.886\n",
      "Epoch: 4089, Train Loss: 2.082, Validation Loss: 5.880\n",
      "Epoch: 4090, Train Loss: 1.992, Validation Loss: 5.823\n",
      "Epoch: 4091, Train Loss: 2.171, Validation Loss: 5.800\n",
      "Epoch: 4092, Train Loss: 1.993, Validation Loss: 5.835\n",
      "Epoch: 4093, Train Loss: 2.064, Validation Loss: 5.807\n",
      "Epoch: 4094, Train Loss: 2.448, Validation Loss: 5.858\n",
      "Epoch: 4095, Train Loss: 2.042, Validation Loss: 5.824\n",
      "Epoch: 4096, Train Loss: 1.980, Validation Loss: 5.810\n",
      "Epoch: 4097, Train Loss: 2.222, Validation Loss: 5.818\n",
      "Epoch: 4098, Train Loss: 2.068, Validation Loss: 5.834\n",
      "Epoch: 4099, Train Loss: 2.503, Validation Loss: 5.850\n",
      "Epoch: 4100, Train Loss: 1.950, Validation Loss: 5.870\n",
      "Epoch: 4101, Train Loss: 2.281, Validation Loss: 5.918\n",
      "Epoch: 4102, Train Loss: 1.873, Validation Loss: 5.893\n",
      "Epoch: 4103, Train Loss: 1.893, Validation Loss: 5.893\n",
      "Epoch: 4104, Train Loss: 2.030, Validation Loss: 5.862\n",
      "Epoch: 4105, Train Loss: 1.608, Validation Loss: 5.854\n",
      "Epoch: 4106, Train Loss: 1.851, Validation Loss: 5.846\n",
      "Epoch: 4107, Train Loss: 1.410, Validation Loss: 5.786\n",
      "Epoch: 4108, Train Loss: 2.098, Validation Loss: 5.851\n",
      "Epoch: 4109, Train Loss: 2.004, Validation Loss: 5.854\n",
      "Epoch: 4110, Train Loss: 1.994, Validation Loss: 5.798\n",
      "Epoch: 4111, Train Loss: 2.280, Validation Loss: 5.846\n",
      "Epoch: 4112, Train Loss: 2.495, Validation Loss: 5.840\n",
      "Epoch: 4113, Train Loss: 1.889, Validation Loss: 5.775\n",
      "Epoch: 4114, Train Loss: 1.915, Validation Loss: 5.832\n",
      "Epoch: 4115, Train Loss: 2.172, Validation Loss: 5.856\n",
      "Epoch: 4116, Train Loss: 1.712, Validation Loss: 5.846\n",
      "Epoch: 4117, Train Loss: 1.658, Validation Loss: 5.846\n",
      "Epoch: 4118, Train Loss: 2.003, Validation Loss: 5.811\n",
      "Epoch: 4119, Train Loss: 1.847, Validation Loss: 5.802\n",
      "Epoch: 4120, Train Loss: 2.016, Validation Loss: 5.822\n",
      "Epoch: 4121, Train Loss: 2.189, Validation Loss: 5.817\n",
      "Epoch: 4122, Train Loss: 2.207, Validation Loss: 5.813\n",
      "Epoch: 4123, Train Loss: 1.925, Validation Loss: 5.811\n",
      "Epoch: 4124, Train Loss: 1.959, Validation Loss: 5.802\n",
      "Epoch: 4125, Train Loss: 1.984, Validation Loss: 5.815\n",
      "Epoch: 4126, Train Loss: 2.061, Validation Loss: 5.772\n",
      "Epoch: 4127, Train Loss: 1.946, Validation Loss: 5.732\n",
      "Epoch: 4128, Train Loss: 1.842, Validation Loss: 5.722\n",
      "Epoch: 4129, Train Loss: 1.879, Validation Loss: 5.733\n",
      "Epoch: 4130, Train Loss: 2.157, Validation Loss: 5.750\n",
      "Epoch: 4131, Train Loss: 1.844, Validation Loss: 5.737\n",
      "Epoch: 4132, Train Loss: 2.150, Validation Loss: 5.764\n",
      "Epoch: 4133, Train Loss: 1.723, Validation Loss: 5.824\n",
      "Epoch: 4134, Train Loss: 2.037, Validation Loss: 5.812\n",
      "Epoch: 4135, Train Loss: 1.631, Validation Loss: 5.801\n",
      "Epoch: 4136, Train Loss: 2.539, Validation Loss: 5.823\n",
      "Epoch: 4137, Train Loss: 2.144, Validation Loss: 5.806\n",
      "Epoch: 4138, Train Loss: 1.964, Validation Loss: 5.822\n",
      "Epoch: 4139, Train Loss: 1.778, Validation Loss: 5.825\n",
      "Epoch: 4140, Train Loss: 1.753, Validation Loss: 5.831\n",
      "Epoch: 4141, Train Loss: 1.910, Validation Loss: 5.833\n",
      "Epoch: 4142, Train Loss: 2.100, Validation Loss: 5.826\n",
      "Epoch: 4143, Train Loss: 1.873, Validation Loss: 5.832\n",
      "Epoch: 4144, Train Loss: 2.026, Validation Loss: 5.832\n",
      "Epoch: 4145, Train Loss: 2.105, Validation Loss: 5.845\n",
      "Epoch: 4146, Train Loss: 1.842, Validation Loss: 5.863\n",
      "Epoch: 4147, Train Loss: 1.935, Validation Loss: 5.897\n",
      "Epoch: 4148, Train Loss: 1.894, Validation Loss: 5.908\n",
      "Epoch: 4149, Train Loss: 1.666, Validation Loss: 5.873\n",
      "Epoch: 4150, Train Loss: 1.955, Validation Loss: 5.887\n",
      "Epoch: 4151, Train Loss: 1.794, Validation Loss: 5.878\n",
      "Epoch: 4152, Train Loss: 1.741, Validation Loss: 5.827\n",
      "Epoch: 4153, Train Loss: 2.400, Validation Loss: 5.815\n",
      "Epoch: 4154, Train Loss: 2.012, Validation Loss: 5.789\n",
      "Epoch: 4155, Train Loss: 1.743, Validation Loss: 5.803\n",
      "Epoch: 4156, Train Loss: 1.744, Validation Loss: 5.824\n",
      "Epoch: 4157, Train Loss: 2.308, Validation Loss: 5.836\n",
      "Epoch: 4158, Train Loss: 2.434, Validation Loss: 5.828\n",
      "Epoch: 4159, Train Loss: 2.388, Validation Loss: 5.849\n",
      "Epoch: 4160, Train Loss: 1.935, Validation Loss: 5.876\n",
      "Epoch: 4161, Train Loss: 2.122, Validation Loss: 5.864\n",
      "Epoch: 4162, Train Loss: 1.859, Validation Loss: 5.821\n",
      "Epoch: 4163, Train Loss: 2.117, Validation Loss: 5.839\n",
      "Epoch: 4164, Train Loss: 2.523, Validation Loss: 5.850\n",
      "Epoch: 4165, Train Loss: 2.199, Validation Loss: 5.824\n",
      "Epoch: 4166, Train Loss: 2.163, Validation Loss: 5.814\n",
      "Epoch: 4167, Train Loss: 2.052, Validation Loss: 5.793\n",
      "Epoch: 4168, Train Loss: 2.301, Validation Loss: 5.799\n",
      "Epoch: 4169, Train Loss: 1.958, Validation Loss: 5.783\n",
      "Epoch: 4170, Train Loss: 2.361, Validation Loss: 5.798\n",
      "Epoch: 4171, Train Loss: 1.638, Validation Loss: 5.818\n",
      "Epoch: 4172, Train Loss: 1.837, Validation Loss: 5.836\n",
      "Epoch: 4173, Train Loss: 2.111, Validation Loss: 5.786\n",
      "Epoch: 4174, Train Loss: 1.587, Validation Loss: 5.817\n",
      "Epoch: 4175, Train Loss: 1.875, Validation Loss: 5.854\n",
      "Epoch: 4176, Train Loss: 1.958, Validation Loss: 5.821\n",
      "Epoch: 4177, Train Loss: 1.978, Validation Loss: 5.845\n",
      "Epoch: 4178, Train Loss: 2.228, Validation Loss: 5.836\n",
      "Epoch: 4179, Train Loss: 1.610, Validation Loss: 5.849\n",
      "Epoch: 4180, Train Loss: 1.899, Validation Loss: 5.807\n",
      "Epoch: 4181, Train Loss: 1.873, Validation Loss: 5.821\n",
      "Epoch: 4182, Train Loss: 1.698, Validation Loss: 5.806\n",
      "Epoch: 4183, Train Loss: 1.720, Validation Loss: 5.790\n",
      "Epoch: 4184, Train Loss: 1.741, Validation Loss: 5.778\n",
      "Epoch: 4185, Train Loss: 2.141, Validation Loss: 5.746\n",
      "Epoch: 4186, Train Loss: 2.207, Validation Loss: 5.752\n",
      "Epoch: 4187, Train Loss: 2.091, Validation Loss: 5.746\n",
      "Epoch: 4188, Train Loss: 1.714, Validation Loss: 5.763\n",
      "Epoch: 4189, Train Loss: 2.093, Validation Loss: 5.793\n",
      "Epoch: 4190, Train Loss: 2.080, Validation Loss: 5.779\n",
      "Epoch: 4191, Train Loss: 1.907, Validation Loss: 5.788\n",
      "Epoch: 4192, Train Loss: 1.743, Validation Loss: 5.777\n",
      "Epoch: 4193, Train Loss: 2.017, Validation Loss: 5.730\n",
      "Epoch: 4194, Train Loss: 1.763, Validation Loss: 5.727\n",
      "Epoch: 4195, Train Loss: 1.836, Validation Loss: 5.750\n",
      "Epoch: 4196, Train Loss: 2.271, Validation Loss: 5.765\n",
      "Epoch: 4197, Train Loss: 2.035, Validation Loss: 5.794\n",
      "Epoch: 4198, Train Loss: 2.197, Validation Loss: 5.816\n",
      "Epoch: 4199, Train Loss: 1.660, Validation Loss: 5.806\n",
      "Epoch: 4200, Train Loss: 1.865, Validation Loss: 5.799\n",
      "Epoch: 4201, Train Loss: 1.901, Validation Loss: 5.795\n",
      "Epoch: 4202, Train Loss: 2.004, Validation Loss: 5.834\n",
      "Epoch: 4203, Train Loss: 2.387, Validation Loss: 5.807\n",
      "Epoch: 4204, Train Loss: 2.049, Validation Loss: 5.777\n",
      "Epoch: 4205, Train Loss: 1.617, Validation Loss: 5.753\n",
      "Epoch: 4206, Train Loss: 2.312, Validation Loss: 5.720\n",
      "Epoch: 4207, Train Loss: 1.907, Validation Loss: 5.750\n",
      "Epoch: 4208, Train Loss: 1.959, Validation Loss: 5.791\n",
      "Epoch: 4209, Train Loss: 1.752, Validation Loss: 5.797\n",
      "Epoch: 4210, Train Loss: 2.270, Validation Loss: 5.832\n",
      "Epoch: 4211, Train Loss: 1.755, Validation Loss: 5.801\n",
      "Epoch: 4212, Train Loss: 1.898, Validation Loss: 5.788\n",
      "Epoch: 4213, Train Loss: 1.949, Validation Loss: 5.827\n",
      "Epoch: 4214, Train Loss: 2.036, Validation Loss: 5.828\n",
      "Epoch: 4215, Train Loss: 2.109, Validation Loss: 5.789\n",
      "Epoch: 4216, Train Loss: 2.347, Validation Loss: 5.843\n",
      "Epoch: 4217, Train Loss: 1.952, Validation Loss: 5.863\n",
      "Epoch: 4218, Train Loss: 1.939, Validation Loss: 5.825\n",
      "Epoch: 4219, Train Loss: 2.343, Validation Loss: 5.879\n",
      "Epoch: 4220, Train Loss: 1.817, Validation Loss: 5.847\n",
      "Epoch: 4221, Train Loss: 1.671, Validation Loss: 5.901\n",
      "Epoch: 4222, Train Loss: 2.044, Validation Loss: 5.894\n",
      "Epoch: 4223, Train Loss: 1.595, Validation Loss: 5.866\n",
      "Epoch: 4224, Train Loss: 1.899, Validation Loss: 5.834\n",
      "Epoch: 4225, Train Loss: 2.132, Validation Loss: 5.854\n",
      "Epoch: 4226, Train Loss: 2.004, Validation Loss: 5.929\n",
      "Epoch: 4227, Train Loss: 1.968, Validation Loss: 5.941\n",
      "Epoch: 4228, Train Loss: 2.136, Validation Loss: 5.893\n",
      "Epoch: 4229, Train Loss: 1.687, Validation Loss: 5.910\n",
      "Epoch: 4230, Train Loss: 1.808, Validation Loss: 5.881\n",
      "Epoch: 4231, Train Loss: 2.308, Validation Loss: 5.887\n",
      "Epoch: 4232, Train Loss: 2.132, Validation Loss: 5.847\n",
      "Epoch: 4233, Train Loss: 2.179, Validation Loss: 5.886\n",
      "Epoch: 4234, Train Loss: 1.824, Validation Loss: 5.854\n",
      "Epoch: 4235, Train Loss: 2.009, Validation Loss: 5.827\n",
      "Epoch: 4236, Train Loss: 2.171, Validation Loss: 5.837\n",
      "Epoch: 4237, Train Loss: 1.783, Validation Loss: 5.783\n",
      "Epoch: 4238, Train Loss: 1.993, Validation Loss: 5.807\n",
      "Epoch: 4239, Train Loss: 1.914, Validation Loss: 5.813\n",
      "Epoch: 4240, Train Loss: 1.761, Validation Loss: 5.843\n",
      "Epoch: 4241, Train Loss: 1.727, Validation Loss: 5.851\n",
      "Epoch: 4242, Train Loss: 2.044, Validation Loss: 5.808\n",
      "Epoch: 4243, Train Loss: 2.068, Validation Loss: 5.817\n",
      "Epoch: 4244, Train Loss: 1.922, Validation Loss: 5.806\n",
      "Epoch: 4245, Train Loss: 1.783, Validation Loss: 5.786\n",
      "Epoch: 4246, Train Loss: 1.714, Validation Loss: 5.762\n",
      "Epoch: 4247, Train Loss: 2.069, Validation Loss: 5.775\n",
      "Epoch: 4248, Train Loss: 1.704, Validation Loss: 5.808\n",
      "Epoch: 4249, Train Loss: 2.223, Validation Loss: 5.768\n",
      "Epoch: 4250, Train Loss: 2.494, Validation Loss: 5.785\n",
      "Epoch: 4251, Train Loss: 1.707, Validation Loss: 5.767\n",
      "Epoch: 4252, Train Loss: 1.649, Validation Loss: 5.736\n",
      "Epoch: 4253, Train Loss: 2.045, Validation Loss: 5.769\n",
      "Epoch: 4254, Train Loss: 1.856, Validation Loss: 5.814\n",
      "Epoch: 4255, Train Loss: 1.916, Validation Loss: 5.790\n",
      "Epoch: 4256, Train Loss: 2.056, Validation Loss: 5.768\n",
      "Epoch: 4257, Train Loss: 2.137, Validation Loss: 5.765\n",
      "Epoch: 4258, Train Loss: 1.681, Validation Loss: 5.758\n",
      "Epoch: 4259, Train Loss: 2.088, Validation Loss: 5.727\n",
      "Epoch: 4260, Train Loss: 2.209, Validation Loss: 5.769\n",
      "Epoch: 4261, Train Loss: 1.975, Validation Loss: 5.810\n",
      "Epoch: 4262, Train Loss: 2.444, Validation Loss: 5.870\n",
      "Epoch: 4263, Train Loss: 2.109, Validation Loss: 5.814\n",
      "Epoch: 4264, Train Loss: 1.906, Validation Loss: 5.817\n",
      "Epoch: 4265, Train Loss: 1.858, Validation Loss: 5.802\n",
      "Epoch: 4266, Train Loss: 1.785, Validation Loss: 5.781\n",
      "Epoch: 4267, Train Loss: 2.210, Validation Loss: 5.814\n",
      "Epoch: 4268, Train Loss: 1.828, Validation Loss: 5.807\n",
      "Epoch: 4269, Train Loss: 1.717, Validation Loss: 5.766\n",
      "Epoch: 4270, Train Loss: 1.940, Validation Loss: 5.793\n",
      "Epoch: 4271, Train Loss: 2.016, Validation Loss: 5.851\n",
      "Epoch: 4272, Train Loss: 2.062, Validation Loss: 5.855\n",
      "Epoch: 4273, Train Loss: 1.808, Validation Loss: 5.833\n",
      "Epoch: 4274, Train Loss: 1.728, Validation Loss: 5.849\n",
      "Epoch: 4275, Train Loss: 1.992, Validation Loss: 5.850\n",
      "Epoch: 4276, Train Loss: 2.043, Validation Loss: 5.842\n",
      "Epoch: 4277, Train Loss: 1.721, Validation Loss: 5.824\n",
      "Epoch: 4278, Train Loss: 1.536, Validation Loss: 5.823\n",
      "Epoch: 4279, Train Loss: 2.084, Validation Loss: 5.842\n",
      "Epoch: 4280, Train Loss: 1.622, Validation Loss: 5.786\n",
      "Epoch: 4281, Train Loss: 2.195, Validation Loss: 5.829\n",
      "Epoch: 4282, Train Loss: 1.813, Validation Loss: 5.789\n",
      "Epoch: 4283, Train Loss: 1.639, Validation Loss: 5.861\n",
      "Epoch: 4284, Train Loss: 2.107, Validation Loss: 5.841\n",
      "Epoch: 4285, Train Loss: 1.924, Validation Loss: 5.874\n",
      "Epoch: 4286, Train Loss: 1.645, Validation Loss: 5.869\n",
      "Epoch: 4287, Train Loss: 2.459, Validation Loss: 5.907\n",
      "Epoch: 4288, Train Loss: 1.728, Validation Loss: 5.866\n",
      "Epoch: 4289, Train Loss: 1.695, Validation Loss: 5.843\n",
      "Epoch: 4290, Train Loss: 1.843, Validation Loss: 5.849\n",
      "Epoch: 4291, Train Loss: 1.733, Validation Loss: 5.841\n",
      "Epoch: 4292, Train Loss: 2.314, Validation Loss: 5.876\n",
      "Epoch: 4293, Train Loss: 2.276, Validation Loss: 5.907\n",
      "Epoch: 4294, Train Loss: 2.280, Validation Loss: 5.913\n",
      "Epoch: 4295, Train Loss: 1.998, Validation Loss: 5.917\n",
      "Epoch: 4296, Train Loss: 1.680, Validation Loss: 5.888\n",
      "Epoch: 4297, Train Loss: 1.879, Validation Loss: 5.859\n",
      "Epoch: 4298, Train Loss: 1.720, Validation Loss: 5.848\n",
      "Epoch: 4299, Train Loss: 1.818, Validation Loss: 5.810\n",
      "Epoch: 4300, Train Loss: 1.814, Validation Loss: 5.819\n",
      "Epoch: 4301, Train Loss: 2.131, Validation Loss: 5.833\n",
      "Epoch: 4302, Train Loss: 1.883, Validation Loss: 5.849\n",
      "Epoch: 4303, Train Loss: 2.011, Validation Loss: 5.863\n",
      "Epoch: 4304, Train Loss: 2.313, Validation Loss: 5.855\n",
      "Epoch: 4305, Train Loss: 1.831, Validation Loss: 5.841\n",
      "Epoch: 4306, Train Loss: 2.051, Validation Loss: 5.847\n",
      "Epoch: 4307, Train Loss: 2.168, Validation Loss: 5.860\n",
      "Epoch: 4308, Train Loss: 2.090, Validation Loss: 5.858\n",
      "Epoch: 4309, Train Loss: 2.036, Validation Loss: 5.891\n",
      "Epoch: 4310, Train Loss: 1.514, Validation Loss: 5.884\n",
      "Epoch: 4311, Train Loss: 1.828, Validation Loss: 5.863\n",
      "Epoch: 4312, Train Loss: 2.047, Validation Loss: 5.883\n",
      "Epoch: 4313, Train Loss: 1.804, Validation Loss: 5.816\n",
      "Epoch: 4314, Train Loss: 2.585, Validation Loss: 5.859\n",
      "Epoch: 4315, Train Loss: 1.845, Validation Loss: 5.846\n",
      "Epoch: 4316, Train Loss: 1.890, Validation Loss: 5.842\n",
      "Epoch: 4317, Train Loss: 1.901, Validation Loss: 5.785\n",
      "Epoch: 4318, Train Loss: 1.927, Validation Loss: 5.831\n",
      "Epoch: 4319, Train Loss: 1.685, Validation Loss: 5.780\n",
      "Epoch: 4320, Train Loss: 2.344, Validation Loss: 5.810\n",
      "Epoch: 4321, Train Loss: 1.731, Validation Loss: 5.817\n",
      "Epoch: 4322, Train Loss: 2.441, Validation Loss: 5.809\n",
      "Epoch: 4323, Train Loss: 2.010, Validation Loss: 5.797\n",
      "Epoch: 4324, Train Loss: 1.688, Validation Loss: 5.799\n",
      "Epoch: 4325, Train Loss: 1.534, Validation Loss: 5.812\n",
      "Epoch: 4326, Train Loss: 1.858, Validation Loss: 5.822\n",
      "Epoch: 4327, Train Loss: 1.888, Validation Loss: 5.801\n",
      "Epoch: 4328, Train Loss: 1.787, Validation Loss: 5.834\n",
      "Epoch: 4329, Train Loss: 1.822, Validation Loss: 5.853\n",
      "Epoch: 4330, Train Loss: 2.064, Validation Loss: 5.820\n",
      "Epoch: 4331, Train Loss: 2.205, Validation Loss: 5.846\n",
      "Epoch: 4332, Train Loss: 2.175, Validation Loss: 5.892\n",
      "Epoch: 4333, Train Loss: 2.290, Validation Loss: 5.839\n",
      "Epoch: 4334, Train Loss: 2.513, Validation Loss: 5.849\n",
      "Epoch: 4335, Train Loss: 2.046, Validation Loss: 5.787\n",
      "Epoch: 4336, Train Loss: 1.577, Validation Loss: 5.814\n",
      "Epoch: 4337, Train Loss: 2.120, Validation Loss: 5.834\n",
      "Epoch: 4338, Train Loss: 2.040, Validation Loss: 5.797\n",
      "Epoch: 4339, Train Loss: 1.509, Validation Loss: 5.807\n",
      "Epoch: 4340, Train Loss: 1.938, Validation Loss: 5.820\n",
      "Epoch: 4341, Train Loss: 1.897, Validation Loss: 5.815\n",
      "Epoch: 4342, Train Loss: 1.924, Validation Loss: 5.859\n",
      "Epoch: 4343, Train Loss: 1.954, Validation Loss: 5.886\n",
      "Epoch: 4344, Train Loss: 1.433, Validation Loss: 5.855\n",
      "Epoch: 4345, Train Loss: 1.926, Validation Loss: 5.886\n",
      "Epoch: 4346, Train Loss: 1.532, Validation Loss: 5.864\n",
      "Epoch: 4347, Train Loss: 2.164, Validation Loss: 5.886\n",
      "Epoch: 4348, Train Loss: 1.989, Validation Loss: 5.900\n",
      "Epoch: 4349, Train Loss: 2.073, Validation Loss: 5.862\n",
      "Epoch: 4350, Train Loss: 1.889, Validation Loss: 5.845\n",
      "Epoch: 4351, Train Loss: 2.110, Validation Loss: 5.847\n",
      "Epoch: 4352, Train Loss: 1.996, Validation Loss: 5.849\n",
      "Epoch: 4353, Train Loss: 1.709, Validation Loss: 5.838\n",
      "Epoch: 4354, Train Loss: 2.215, Validation Loss: 5.830\n",
      "Epoch: 4355, Train Loss: 2.010, Validation Loss: 5.825\n",
      "Epoch: 4356, Train Loss: 1.902, Validation Loss: 5.826\n",
      "Epoch: 4357, Train Loss: 1.859, Validation Loss: 5.789\n",
      "Epoch: 4358, Train Loss: 1.769, Validation Loss: 5.818\n",
      "Epoch: 4359, Train Loss: 1.826, Validation Loss: 5.855\n",
      "Epoch: 4360, Train Loss: 1.978, Validation Loss: 5.807\n",
      "Epoch: 4361, Train Loss: 1.873, Validation Loss: 5.843\n",
      "Epoch: 4362, Train Loss: 1.869, Validation Loss: 5.824\n",
      "Epoch: 4363, Train Loss: 1.865, Validation Loss: 5.854\n",
      "Epoch: 4364, Train Loss: 1.922, Validation Loss: 5.860\n",
      "Epoch: 4365, Train Loss: 1.818, Validation Loss: 5.807\n",
      "Epoch: 4366, Train Loss: 1.922, Validation Loss: 5.799\n",
      "Epoch: 4367, Train Loss: 1.445, Validation Loss: 5.823\n",
      "Epoch: 4368, Train Loss: 1.800, Validation Loss: 5.810\n",
      "Epoch: 4369, Train Loss: 1.705, Validation Loss: 5.823\n",
      "Epoch: 4370, Train Loss: 2.006, Validation Loss: 5.865\n",
      "Epoch: 4371, Train Loss: 1.981, Validation Loss: 5.862\n",
      "Epoch: 4372, Train Loss: 1.829, Validation Loss: 5.796\n",
      "Epoch: 4373, Train Loss: 1.310, Validation Loss: 5.772\n",
      "Epoch: 4374, Train Loss: 1.899, Validation Loss: 5.801\n",
      "Epoch: 4375, Train Loss: 2.115, Validation Loss: 5.841\n",
      "Epoch: 4376, Train Loss: 2.235, Validation Loss: 5.817\n",
      "Epoch: 4377, Train Loss: 1.769, Validation Loss: 5.822\n",
      "Epoch: 4378, Train Loss: 1.670, Validation Loss: 5.812\n",
      "Epoch: 4379, Train Loss: 1.752, Validation Loss: 5.837\n",
      "Epoch: 4380, Train Loss: 1.936, Validation Loss: 5.867\n",
      "Epoch: 4381, Train Loss: 1.892, Validation Loss: 5.801\n",
      "Epoch: 4382, Train Loss: 1.697, Validation Loss: 5.829\n",
      "Epoch: 4383, Train Loss: 1.726, Validation Loss: 5.831\n",
      "Epoch: 4384, Train Loss: 1.748, Validation Loss: 5.821\n",
      "Epoch: 4385, Train Loss: 1.994, Validation Loss: 5.834\n",
      "Epoch: 4386, Train Loss: 2.142, Validation Loss: 5.838\n",
      "Epoch: 4387, Train Loss: 1.625, Validation Loss: 5.815\n",
      "Epoch: 4388, Train Loss: 1.877, Validation Loss: 5.808\n",
      "Epoch: 4389, Train Loss: 1.887, Validation Loss: 5.813\n",
      "Epoch: 4390, Train Loss: 2.039, Validation Loss: 5.825\n",
      "Epoch: 4391, Train Loss: 1.957, Validation Loss: 5.894\n",
      "Epoch: 4392, Train Loss: 1.981, Validation Loss: 5.895\n",
      "Epoch: 4393, Train Loss: 2.138, Validation Loss: 5.870\n",
      "Epoch: 4394, Train Loss: 1.814, Validation Loss: 5.788\n",
      "Epoch: 4395, Train Loss: 1.756, Validation Loss: 5.866\n",
      "Epoch: 4396, Train Loss: 2.379, Validation Loss: 5.852\n",
      "Epoch: 4397, Train Loss: 1.639, Validation Loss: 5.772\n",
      "Epoch: 4398, Train Loss: 2.093, Validation Loss: 5.835\n",
      "Epoch: 4399, Train Loss: 1.792, Validation Loss: 5.905\n",
      "Epoch: 4400, Train Loss: 1.970, Validation Loss: 5.861\n",
      "Epoch: 4401, Train Loss: 1.653, Validation Loss: 5.804\n",
      "Epoch: 4402, Train Loss: 1.588, Validation Loss: 5.848\n",
      "Epoch: 4403, Train Loss: 1.760, Validation Loss: 5.845\n",
      "Epoch: 4404, Train Loss: 1.941, Validation Loss: 5.826\n",
      "Epoch: 4405, Train Loss: 2.574, Validation Loss: 5.861\n",
      "Epoch: 4406, Train Loss: 2.205, Validation Loss: 5.870\n",
      "Epoch: 4407, Train Loss: 1.378, Validation Loss: 5.825\n",
      "Epoch: 4408, Train Loss: 2.234, Validation Loss: 5.899\n",
      "Epoch: 4409, Train Loss: 1.730, Validation Loss: 5.881\n",
      "Epoch: 4410, Train Loss: 2.063, Validation Loss: 5.884\n",
      "Epoch: 4411, Train Loss: 1.826, Validation Loss: 5.855\n",
      "Epoch: 4412, Train Loss: 1.907, Validation Loss: 5.858\n",
      "Epoch: 4413, Train Loss: 1.830, Validation Loss: 5.897\n",
      "Epoch: 4414, Train Loss: 1.900, Validation Loss: 5.833\n",
      "Epoch: 4415, Train Loss: 2.204, Validation Loss: 5.877\n",
      "Epoch: 4416, Train Loss: 2.112, Validation Loss: 5.895\n",
      "Epoch: 4417, Train Loss: 1.624, Validation Loss: 5.871\n",
      "Epoch: 4418, Train Loss: 1.988, Validation Loss: 5.930\n",
      "Epoch: 4419, Train Loss: 1.760, Validation Loss: 5.943\n",
      "Epoch: 4420, Train Loss: 1.987, Validation Loss: 5.829\n",
      "Epoch: 4421, Train Loss: 1.588, Validation Loss: 5.854\n",
      "Epoch: 4422, Train Loss: 1.990, Validation Loss: 5.836\n",
      "Epoch: 4423, Train Loss: 1.645, Validation Loss: 5.859\n",
      "Epoch: 4424, Train Loss: 2.060, Validation Loss: 5.872\n",
      "Epoch: 4425, Train Loss: 1.785, Validation Loss: 5.878\n",
      "Epoch: 4426, Train Loss: 1.491, Validation Loss: 5.903\n",
      "Epoch: 4427, Train Loss: 1.882, Validation Loss: 5.872\n",
      "Epoch: 4428, Train Loss: 1.827, Validation Loss: 5.880\n",
      "Epoch: 4429, Train Loss: 1.558, Validation Loss: 5.848\n",
      "Epoch: 4430, Train Loss: 1.763, Validation Loss: 5.861\n",
      "Epoch: 4431, Train Loss: 1.880, Validation Loss: 5.846\n",
      "Epoch: 4432, Train Loss: 1.879, Validation Loss: 5.866\n",
      "Epoch: 4433, Train Loss: 2.082, Validation Loss: 5.948\n",
      "Epoch: 4434, Train Loss: 2.141, Validation Loss: 5.906\n",
      "Epoch: 4435, Train Loss: 1.743, Validation Loss: 5.885\n",
      "Epoch: 4436, Train Loss: 1.702, Validation Loss: 5.845\n",
      "Epoch: 4437, Train Loss: 1.978, Validation Loss: 5.833\n",
      "Epoch: 4438, Train Loss: 2.369, Validation Loss: 5.860\n",
      "Epoch: 4439, Train Loss: 2.024, Validation Loss: 5.895\n",
      "Epoch: 4440, Train Loss: 1.612, Validation Loss: 5.816\n",
      "Epoch: 4441, Train Loss: 2.013, Validation Loss: 5.869\n",
      "Epoch: 4442, Train Loss: 1.866, Validation Loss: 5.831\n",
      "Epoch: 4443, Train Loss: 1.792, Validation Loss: 5.801\n",
      "Epoch: 4444, Train Loss: 1.868, Validation Loss: 5.872\n",
      "Epoch: 4445, Train Loss: 2.608, Validation Loss: 5.851\n",
      "Epoch: 4446, Train Loss: 1.825, Validation Loss: 5.873\n",
      "Epoch: 4447, Train Loss: 1.973, Validation Loss: 5.830\n",
      "Epoch: 4448, Train Loss: 1.646, Validation Loss: 5.855\n",
      "Epoch: 4449, Train Loss: 1.650, Validation Loss: 5.822\n",
      "Epoch: 4450, Train Loss: 1.557, Validation Loss: 5.837\n",
      "Epoch: 4451, Train Loss: 1.778, Validation Loss: 5.804\n",
      "Epoch: 4452, Train Loss: 1.454, Validation Loss: 5.845\n",
      "Epoch: 4453, Train Loss: 1.646, Validation Loss: 5.892\n",
      "Epoch: 4454, Train Loss: 2.126, Validation Loss: 5.929\n",
      "Epoch: 4455, Train Loss: 1.861, Validation Loss: 5.916\n",
      "Epoch: 4456, Train Loss: 1.762, Validation Loss: 5.878\n",
      "Epoch: 4457, Train Loss: 2.216, Validation Loss: 5.822\n",
      "Epoch: 4458, Train Loss: 1.711, Validation Loss: 5.808\n",
      "Epoch: 4459, Train Loss: 1.806, Validation Loss: 5.810\n",
      "Epoch: 4460, Train Loss: 1.640, Validation Loss: 5.813\n",
      "Epoch: 4461, Train Loss: 1.880, Validation Loss: 5.895\n",
      "Epoch: 4462, Train Loss: 1.817, Validation Loss: 5.858\n",
      "Epoch: 4463, Train Loss: 1.816, Validation Loss: 5.862\n",
      "Epoch: 4464, Train Loss: 1.777, Validation Loss: 5.872\n",
      "Epoch: 4465, Train Loss: 1.833, Validation Loss: 5.861\n",
      "Epoch: 4466, Train Loss: 1.763, Validation Loss: 5.859\n",
      "Epoch: 4467, Train Loss: 2.086, Validation Loss: 5.865\n",
      "Epoch: 4468, Train Loss: 1.450, Validation Loss: 5.900\n",
      "Epoch: 4469, Train Loss: 1.783, Validation Loss: 5.912\n",
      "Epoch: 4470, Train Loss: 2.191, Validation Loss: 5.914\n",
      "Epoch: 4471, Train Loss: 1.924, Validation Loss: 5.941\n",
      "Epoch: 4472, Train Loss: 2.004, Validation Loss: 5.927\n",
      "Epoch: 4473, Train Loss: 2.166, Validation Loss: 5.889\n",
      "Epoch: 4474, Train Loss: 1.801, Validation Loss: 5.838\n",
      "Epoch: 4475, Train Loss: 1.604, Validation Loss: 5.841\n",
      "Epoch: 4476, Train Loss: 2.139, Validation Loss: 5.878\n",
      "Epoch: 4477, Train Loss: 1.714, Validation Loss: 5.912\n",
      "Epoch: 4478, Train Loss: 2.055, Validation Loss: 5.899\n",
      "Epoch: 4479, Train Loss: 1.816, Validation Loss: 5.916\n",
      "Epoch: 4480, Train Loss: 1.911, Validation Loss: 5.888\n",
      "Epoch: 4481, Train Loss: 1.547, Validation Loss: 5.899\n",
      "Epoch: 4482, Train Loss: 1.904, Validation Loss: 5.848\n",
      "Epoch: 4483, Train Loss: 1.823, Validation Loss: 5.837\n",
      "Epoch: 4484, Train Loss: 2.043, Validation Loss: 5.882\n",
      "Epoch: 4485, Train Loss: 1.797, Validation Loss: 5.860\n",
      "Epoch: 4486, Train Loss: 1.859, Validation Loss: 5.900\n",
      "Epoch: 4487, Train Loss: 1.711, Validation Loss: 5.850\n",
      "Epoch: 4488, Train Loss: 2.099, Validation Loss: 5.767\n",
      "Epoch: 4489, Train Loss: 1.605, Validation Loss: 5.758\n",
      "Epoch: 4490, Train Loss: 1.587, Validation Loss: 5.787\n",
      "Epoch: 4491, Train Loss: 1.489, Validation Loss: 5.801\n",
      "Epoch: 4492, Train Loss: 1.919, Validation Loss: 5.818\n",
      "Epoch: 4493, Train Loss: 1.726, Validation Loss: 5.809\n",
      "Epoch: 4494, Train Loss: 1.396, Validation Loss: 5.757\n",
      "Epoch: 4495, Train Loss: 2.235, Validation Loss: 5.757\n",
      "Epoch: 4496, Train Loss: 1.911, Validation Loss: 5.802\n",
      "Epoch: 4497, Train Loss: 1.722, Validation Loss: 5.761\n",
      "Epoch: 4498, Train Loss: 1.766, Validation Loss: 5.750\n",
      "Epoch: 4499, Train Loss: 1.732, Validation Loss: 5.728\n",
      "Epoch: 4500, Train Loss: 2.040, Validation Loss: 5.760\n",
      "Epoch: 4501, Train Loss: 2.176, Validation Loss: 5.782\n",
      "Epoch: 4502, Train Loss: 2.051, Validation Loss: 5.807\n",
      "Epoch: 4503, Train Loss: 2.102, Validation Loss: 5.787\n",
      "Epoch: 4504, Train Loss: 1.888, Validation Loss: 5.792\n",
      "Epoch: 4505, Train Loss: 1.572, Validation Loss: 5.796\n",
      "Epoch: 4506, Train Loss: 1.738, Validation Loss: 5.775\n",
      "Epoch: 4507, Train Loss: 1.745, Validation Loss: 5.778\n",
      "Epoch: 4508, Train Loss: 1.862, Validation Loss: 5.783\n",
      "Epoch: 4509, Train Loss: 1.598, Validation Loss: 5.808\n",
      "Epoch: 4510, Train Loss: 1.723, Validation Loss: 5.806\n",
      "Epoch: 4511, Train Loss: 1.582, Validation Loss: 5.789\n",
      "Epoch: 4512, Train Loss: 1.921, Validation Loss: 5.812\n",
      "Epoch: 4513, Train Loss: 2.017, Validation Loss: 5.786\n",
      "Epoch: 4514, Train Loss: 2.124, Validation Loss: 5.843\n",
      "Epoch: 4515, Train Loss: 1.801, Validation Loss: 5.836\n",
      "Epoch: 4516, Train Loss: 1.981, Validation Loss: 5.805\n",
      "Epoch: 4517, Train Loss: 1.756, Validation Loss: 5.755\n",
      "Epoch: 4518, Train Loss: 1.594, Validation Loss: 5.763\n",
      "Epoch: 4519, Train Loss: 1.768, Validation Loss: 5.805\n",
      "Epoch: 4520, Train Loss: 2.287, Validation Loss: 5.828\n",
      "Epoch: 4521, Train Loss: 1.934, Validation Loss: 5.827\n",
      "Epoch: 4522, Train Loss: 1.787, Validation Loss: 5.830\n",
      "Epoch: 4523, Train Loss: 2.017, Validation Loss: 5.828\n",
      "Epoch: 4524, Train Loss: 1.708, Validation Loss: 5.842\n",
      "Epoch: 4525, Train Loss: 1.819, Validation Loss: 5.837\n",
      "Epoch: 4526, Train Loss: 1.631, Validation Loss: 5.827\n",
      "Epoch: 4527, Train Loss: 1.513, Validation Loss: 5.818\n",
      "Epoch: 4528, Train Loss: 1.805, Validation Loss: 5.835\n",
      "Epoch: 4529, Train Loss: 1.900, Validation Loss: 5.864\n",
      "Epoch: 4530, Train Loss: 1.667, Validation Loss: 5.831\n",
      "Epoch: 4531, Train Loss: 1.623, Validation Loss: 5.855\n",
      "Epoch: 4532, Train Loss: 1.785, Validation Loss: 5.870\n",
      "Epoch: 4533, Train Loss: 1.559, Validation Loss: 5.827\n",
      "Epoch: 4534, Train Loss: 2.151, Validation Loss: 5.854\n",
      "Epoch: 4535, Train Loss: 1.969, Validation Loss: 5.836\n",
      "Epoch: 4536, Train Loss: 1.817, Validation Loss: 5.944\n",
      "Epoch: 4537, Train Loss: 1.821, Validation Loss: 5.938\n",
      "Epoch: 4538, Train Loss: 1.879, Validation Loss: 5.928\n",
      "Epoch: 4539, Train Loss: 1.945, Validation Loss: 5.939\n",
      "Epoch: 4540, Train Loss: 2.144, Validation Loss: 5.947\n",
      "Epoch: 4541, Train Loss: 1.992, Validation Loss: 5.939\n",
      "Epoch: 4542, Train Loss: 1.808, Validation Loss: 5.877\n",
      "Epoch: 4543, Train Loss: 1.740, Validation Loss: 5.882\n",
      "Epoch: 4544, Train Loss: 1.646, Validation Loss: 5.877\n",
      "Epoch: 4545, Train Loss: 2.182, Validation Loss: 5.904\n",
      "Epoch: 4546, Train Loss: 2.117, Validation Loss: 5.879\n",
      "Epoch: 4547, Train Loss: 1.899, Validation Loss: 5.883\n",
      "Epoch: 4548, Train Loss: 1.596, Validation Loss: 5.848\n",
      "Epoch: 4549, Train Loss: 2.083, Validation Loss: 5.878\n",
      "Epoch: 4550, Train Loss: 2.048, Validation Loss: 5.881\n",
      "Epoch: 4551, Train Loss: 1.808, Validation Loss: 5.887\n",
      "Epoch: 4552, Train Loss: 1.789, Validation Loss: 5.893\n",
      "Epoch: 4553, Train Loss: 1.882, Validation Loss: 5.915\n",
      "Epoch: 4554, Train Loss: 1.853, Validation Loss: 5.925\n",
      "Epoch: 4555, Train Loss: 1.577, Validation Loss: 5.920\n",
      "Epoch: 4556, Train Loss: 1.600, Validation Loss: 5.893\n",
      "Epoch: 4557, Train Loss: 1.859, Validation Loss: 5.907\n",
      "Epoch: 4558, Train Loss: 1.480, Validation Loss: 5.912\n",
      "Epoch: 4559, Train Loss: 1.779, Validation Loss: 5.918\n",
      "Epoch: 4560, Train Loss: 1.710, Validation Loss: 5.877\n",
      "Epoch: 4561, Train Loss: 2.062, Validation Loss: 5.903\n",
      "Epoch: 4562, Train Loss: 1.871, Validation Loss: 5.880\n",
      "Epoch: 4563, Train Loss: 1.841, Validation Loss: 5.906\n",
      "Epoch: 4564, Train Loss: 1.754, Validation Loss: 5.894\n",
      "Epoch: 4565, Train Loss: 1.566, Validation Loss: 5.889\n",
      "Epoch: 4566, Train Loss: 1.526, Validation Loss: 5.895\n",
      "Epoch: 4567, Train Loss: 1.829, Validation Loss: 5.898\n",
      "Epoch: 4568, Train Loss: 1.885, Validation Loss: 5.934\n",
      "Epoch: 4569, Train Loss: 1.731, Validation Loss: 5.939\n",
      "Epoch: 4570, Train Loss: 1.729, Validation Loss: 5.949\n",
      "Epoch: 4571, Train Loss: 1.604, Validation Loss: 5.988\n",
      "Epoch: 4572, Train Loss: 1.757, Validation Loss: 6.035\n",
      "Epoch: 4573, Train Loss: 1.686, Validation Loss: 5.953\n",
      "Epoch: 4574, Train Loss: 1.928, Validation Loss: 5.930\n",
      "Epoch: 4575, Train Loss: 1.886, Validation Loss: 5.879\n",
      "Epoch: 4576, Train Loss: 2.032, Validation Loss: 5.866\n",
      "Epoch: 4577, Train Loss: 1.575, Validation Loss: 5.881\n",
      "Epoch: 4578, Train Loss: 1.522, Validation Loss: 5.887\n",
      "Epoch: 4579, Train Loss: 1.860, Validation Loss: 5.925\n",
      "Epoch: 4580, Train Loss: 1.949, Validation Loss: 5.919\n",
      "Epoch: 4581, Train Loss: 2.355, Validation Loss: 5.848\n",
      "Epoch: 4582, Train Loss: 2.148, Validation Loss: 5.881\n",
      "Epoch: 4583, Train Loss: 1.806, Validation Loss: 5.832\n",
      "Epoch: 4584, Train Loss: 1.594, Validation Loss: 5.859\n",
      "Epoch: 4585, Train Loss: 1.554, Validation Loss: 5.882\n",
      "Epoch: 4586, Train Loss: 1.697, Validation Loss: 5.887\n",
      "Epoch: 4587, Train Loss: 1.589, Validation Loss: 5.876\n",
      "Epoch: 4588, Train Loss: 1.628, Validation Loss: 5.864\n",
      "Epoch: 4589, Train Loss: 1.713, Validation Loss: 5.834\n",
      "Epoch: 4590, Train Loss: 1.684, Validation Loss: 5.841\n",
      "Epoch: 4591, Train Loss: 1.572, Validation Loss: 5.806\n",
      "Epoch: 4592, Train Loss: 1.939, Validation Loss: 5.856\n",
      "Epoch: 4593, Train Loss: 1.669, Validation Loss: 5.863\n",
      "Epoch: 4594, Train Loss: 1.516, Validation Loss: 5.852\n",
      "Epoch: 4595, Train Loss: 1.873, Validation Loss: 5.822\n",
      "Epoch: 4596, Train Loss: 1.673, Validation Loss: 5.848\n",
      "Epoch: 4597, Train Loss: 1.963, Validation Loss: 5.827\n",
      "Epoch: 4598, Train Loss: 1.871, Validation Loss: 5.853\n",
      "Epoch: 4599, Train Loss: 1.532, Validation Loss: 5.842\n",
      "Epoch: 4600, Train Loss: 1.623, Validation Loss: 5.844\n",
      "Epoch: 4601, Train Loss: 1.973, Validation Loss: 5.831\n",
      "Epoch: 4602, Train Loss: 1.583, Validation Loss: 5.818\n",
      "Epoch: 4603, Train Loss: 1.943, Validation Loss: 5.840\n",
      "Epoch: 4604, Train Loss: 1.627, Validation Loss: 5.796\n",
      "Epoch: 4605, Train Loss: 1.892, Validation Loss: 5.876\n",
      "Epoch: 4606, Train Loss: 1.643, Validation Loss: 5.866\n",
      "Epoch: 4607, Train Loss: 1.898, Validation Loss: 5.906\n",
      "Epoch: 4608, Train Loss: 1.827, Validation Loss: 5.854\n",
      "Epoch: 4609, Train Loss: 1.634, Validation Loss: 5.842\n",
      "Epoch: 4610, Train Loss: 1.993, Validation Loss: 5.824\n",
      "Epoch: 4611, Train Loss: 1.473, Validation Loss: 5.804\n",
      "Epoch: 4612, Train Loss: 1.978, Validation Loss: 5.812\n",
      "Epoch: 4613, Train Loss: 1.942, Validation Loss: 5.800\n",
      "Epoch: 4614, Train Loss: 1.809, Validation Loss: 5.810\n",
      "Epoch: 4615, Train Loss: 1.949, Validation Loss: 5.772\n",
      "Epoch: 4616, Train Loss: 1.522, Validation Loss: 5.770\n",
      "Epoch: 4617, Train Loss: 2.017, Validation Loss: 5.799\n",
      "Epoch: 4618, Train Loss: 1.463, Validation Loss: 5.820\n",
      "Epoch: 4619, Train Loss: 1.718, Validation Loss: 5.817\n",
      "Epoch: 4620, Train Loss: 1.974, Validation Loss: 5.768\n",
      "Epoch: 4621, Train Loss: 1.523, Validation Loss: 5.798\n",
      "Epoch: 4622, Train Loss: 1.620, Validation Loss: 5.800\n",
      "Epoch: 4623, Train Loss: 2.275, Validation Loss: 5.830\n",
      "Epoch: 4624, Train Loss: 1.576, Validation Loss: 5.870\n",
      "Epoch: 4625, Train Loss: 2.048, Validation Loss: 5.884\n",
      "Epoch: 4626, Train Loss: 1.949, Validation Loss: 5.869\n",
      "Epoch: 4627, Train Loss: 1.777, Validation Loss: 5.900\n",
      "Epoch: 4628, Train Loss: 1.947, Validation Loss: 5.878\n",
      "Epoch: 4629, Train Loss: 2.086, Validation Loss: 5.856\n",
      "Epoch: 4630, Train Loss: 1.779, Validation Loss: 5.839\n",
      "Epoch: 4631, Train Loss: 1.698, Validation Loss: 5.814\n",
      "Epoch: 4632, Train Loss: 1.603, Validation Loss: 5.842\n",
      "Epoch: 4633, Train Loss: 1.769, Validation Loss: 5.836\n",
      "Epoch: 4634, Train Loss: 2.159, Validation Loss: 5.835\n",
      "Epoch: 4635, Train Loss: 2.223, Validation Loss: 5.848\n",
      "Epoch: 4636, Train Loss: 2.026, Validation Loss: 5.887\n",
      "Epoch: 4637, Train Loss: 1.751, Validation Loss: 5.898\n",
      "Epoch: 4638, Train Loss: 2.071, Validation Loss: 5.847\n",
      "Epoch: 4639, Train Loss: 1.885, Validation Loss: 5.809\n",
      "Epoch: 4640, Train Loss: 1.567, Validation Loss: 5.830\n",
      "Epoch: 4641, Train Loss: 1.823, Validation Loss: 5.839\n",
      "Epoch: 4642, Train Loss: 2.096, Validation Loss: 5.858\n",
      "Epoch: 4643, Train Loss: 1.548, Validation Loss: 5.835\n",
      "Epoch: 4644, Train Loss: 1.694, Validation Loss: 5.797\n",
      "Epoch: 4645, Train Loss: 1.963, Validation Loss: 5.795\n",
      "Epoch: 4646, Train Loss: 1.916, Validation Loss: 5.817\n",
      "Epoch: 4647, Train Loss: 1.674, Validation Loss: 5.893\n",
      "Epoch: 4648, Train Loss: 1.766, Validation Loss: 5.825\n",
      "Epoch: 4649, Train Loss: 1.784, Validation Loss: 5.854\n",
      "Epoch: 4650, Train Loss: 1.678, Validation Loss: 5.801\n",
      "Epoch: 4651, Train Loss: 1.520, Validation Loss: 5.781\n",
      "Epoch: 4652, Train Loss: 1.696, Validation Loss: 5.773\n",
      "Epoch: 4653, Train Loss: 2.180, Validation Loss: 5.806\n",
      "Epoch: 4654, Train Loss: 1.752, Validation Loss: 5.832\n",
      "Epoch: 4655, Train Loss: 1.724, Validation Loss: 5.800\n",
      "Epoch: 4656, Train Loss: 1.583, Validation Loss: 5.804\n",
      "Epoch: 4657, Train Loss: 1.845, Validation Loss: 5.805\n",
      "Epoch: 4658, Train Loss: 1.775, Validation Loss: 5.831\n",
      "Epoch: 4659, Train Loss: 1.724, Validation Loss: 5.825\n",
      "Epoch: 4660, Train Loss: 1.742, Validation Loss: 5.840\n",
      "Epoch: 4661, Train Loss: 1.860, Validation Loss: 5.856\n",
      "Epoch: 4662, Train Loss: 1.919, Validation Loss: 5.881\n",
      "Epoch: 4663, Train Loss: 2.319, Validation Loss: 5.882\n",
      "Epoch: 4664, Train Loss: 1.639, Validation Loss: 5.893\n",
      "Epoch: 4665, Train Loss: 1.893, Validation Loss: 5.866\n",
      "Epoch: 4666, Train Loss: 1.991, Validation Loss: 5.801\n",
      "Epoch: 4667, Train Loss: 2.233, Validation Loss: 5.890\n",
      "Epoch: 4668, Train Loss: 1.953, Validation Loss: 5.868\n",
      "Epoch: 4669, Train Loss: 1.979, Validation Loss: 5.850\n",
      "Epoch: 4670, Train Loss: 1.884, Validation Loss: 5.873\n",
      "Epoch: 4671, Train Loss: 1.735, Validation Loss: 5.892\n",
      "Epoch: 4672, Train Loss: 1.667, Validation Loss: 5.879\n",
      "Epoch: 4673, Train Loss: 1.608, Validation Loss: 5.845\n",
      "Epoch: 4674, Train Loss: 1.858, Validation Loss: 5.884\n",
      "Epoch: 4675, Train Loss: 1.945, Validation Loss: 5.859\n",
      "Epoch: 4676, Train Loss: 1.663, Validation Loss: 5.830\n",
      "Epoch: 4677, Train Loss: 1.634, Validation Loss: 5.868\n",
      "Epoch: 4678, Train Loss: 1.697, Validation Loss: 5.835\n",
      "Epoch: 4679, Train Loss: 1.764, Validation Loss: 5.845\n",
      "Epoch: 4680, Train Loss: 2.028, Validation Loss: 5.935\n",
      "Epoch: 4681, Train Loss: 1.617, Validation Loss: 5.889\n",
      "Epoch: 4682, Train Loss: 1.849, Validation Loss: 5.896\n",
      "Epoch: 4683, Train Loss: 1.635, Validation Loss: 5.917\n",
      "Epoch: 4684, Train Loss: 1.657, Validation Loss: 5.901\n",
      "Epoch: 4685, Train Loss: 1.882, Validation Loss: 5.875\n",
      "Epoch: 4686, Train Loss: 1.992, Validation Loss: 5.890\n",
      "Epoch: 4687, Train Loss: 1.777, Validation Loss: 5.926\n",
      "Epoch: 4688, Train Loss: 1.801, Validation Loss: 5.903\n",
      "Epoch: 4689, Train Loss: 1.906, Validation Loss: 5.898\n",
      "Epoch: 4690, Train Loss: 1.678, Validation Loss: 5.920\n",
      "Epoch: 4691, Train Loss: 1.909, Validation Loss: 5.914\n",
      "Epoch: 4692, Train Loss: 1.737, Validation Loss: 5.874\n",
      "Epoch: 4693, Train Loss: 1.850, Validation Loss: 5.884\n",
      "Epoch: 4694, Train Loss: 1.632, Validation Loss: 5.876\n",
      "Epoch: 4695, Train Loss: 1.818, Validation Loss: 5.837\n",
      "Epoch: 4696, Train Loss: 1.540, Validation Loss: 5.824\n",
      "Epoch: 4697, Train Loss: 1.628, Validation Loss: 5.836\n",
      "Epoch: 4698, Train Loss: 2.165, Validation Loss: 5.955\n",
      "Epoch: 4699, Train Loss: 1.978, Validation Loss: 5.989\n",
      "Epoch: 4700, Train Loss: 2.020, Validation Loss: 5.940\n",
      "Epoch: 4701, Train Loss: 1.639, Validation Loss: 5.904\n",
      "Epoch: 4702, Train Loss: 1.627, Validation Loss: 5.909\n",
      "Epoch: 4703, Train Loss: 1.912, Validation Loss: 5.922\n",
      "Epoch: 4704, Train Loss: 1.591, Validation Loss: 5.898\n",
      "Epoch: 4705, Train Loss: 1.724, Validation Loss: 5.866\n",
      "Epoch: 4706, Train Loss: 1.600, Validation Loss: 5.879\n",
      "Epoch: 4707, Train Loss: 1.633, Validation Loss: 5.897\n",
      "Epoch: 4708, Train Loss: 1.486, Validation Loss: 5.844\n",
      "Epoch: 4709, Train Loss: 1.829, Validation Loss: 5.874\n",
      "Epoch: 4710, Train Loss: 1.979, Validation Loss: 5.816\n",
      "Epoch: 4711, Train Loss: 1.850, Validation Loss: 5.856\n",
      "Epoch: 4712, Train Loss: 1.584, Validation Loss: 5.821\n",
      "Epoch: 4713, Train Loss: 1.631, Validation Loss: 5.854\n",
      "Epoch: 4714, Train Loss: 1.320, Validation Loss: 5.880\n",
      "Epoch: 4715, Train Loss: 1.427, Validation Loss: 5.861\n",
      "Epoch: 4716, Train Loss: 1.827, Validation Loss: 5.842\n",
      "Epoch: 4717, Train Loss: 1.612, Validation Loss: 5.797\n",
      "Epoch: 4718, Train Loss: 2.042, Validation Loss: 5.818\n",
      "Epoch: 4719, Train Loss: 1.788, Validation Loss: 5.845\n",
      "Epoch: 4720, Train Loss: 1.435, Validation Loss: 5.836\n",
      "Epoch: 4721, Train Loss: 1.670, Validation Loss: 5.834\n",
      "Epoch: 4722, Train Loss: 1.707, Validation Loss: 5.819\n",
      "Epoch: 4723, Train Loss: 1.891, Validation Loss: 5.845\n",
      "Epoch: 4724, Train Loss: 1.883, Validation Loss: 5.866\n",
      "Epoch: 4725, Train Loss: 1.493, Validation Loss: 5.788\n",
      "Epoch: 4726, Train Loss: 1.965, Validation Loss: 5.810\n",
      "Epoch: 4727, Train Loss: 1.635, Validation Loss: 5.832\n",
      "Epoch: 4728, Train Loss: 1.669, Validation Loss: 5.839\n",
      "Epoch: 4729, Train Loss: 1.624, Validation Loss: 5.911\n",
      "Epoch: 4730, Train Loss: 1.854, Validation Loss: 5.893\n",
      "Epoch: 4731, Train Loss: 1.860, Validation Loss: 5.892\n",
      "Epoch: 4732, Train Loss: 1.822, Validation Loss: 5.864\n",
      "Epoch: 4733, Train Loss: 1.744, Validation Loss: 5.865\n",
      "Epoch: 4734, Train Loss: 1.564, Validation Loss: 5.847\n",
      "Epoch: 4735, Train Loss: 1.527, Validation Loss: 5.823\n",
      "Epoch: 4736, Train Loss: 1.837, Validation Loss: 5.857\n",
      "Epoch: 4737, Train Loss: 1.314, Validation Loss: 5.847\n",
      "Epoch: 4738, Train Loss: 1.780, Validation Loss: 5.822\n",
      "Epoch: 4739, Train Loss: 1.646, Validation Loss: 5.811\n",
      "Epoch: 4740, Train Loss: 1.519, Validation Loss: 5.806\n",
      "Epoch: 4741, Train Loss: 1.463, Validation Loss: 5.869\n",
      "Epoch: 4742, Train Loss: 1.802, Validation Loss: 5.825\n",
      "Epoch: 4743, Train Loss: 2.092, Validation Loss: 5.853\n",
      "Epoch: 4744, Train Loss: 1.656, Validation Loss: 5.885\n",
      "Epoch: 4745, Train Loss: 1.462, Validation Loss: 5.863\n",
      "Epoch: 4746, Train Loss: 1.834, Validation Loss: 5.860\n",
      "Epoch: 4747, Train Loss: 1.563, Validation Loss: 5.842\n",
      "Epoch: 4748, Train Loss: 1.810, Validation Loss: 5.846\n",
      "Epoch: 4749, Train Loss: 1.710, Validation Loss: 5.874\n",
      "Epoch: 4750, Train Loss: 1.788, Validation Loss: 5.978\n",
      "Epoch: 4751, Train Loss: 1.882, Validation Loss: 5.919\n",
      "Epoch: 4752, Train Loss: 1.876, Validation Loss: 5.875\n",
      "Epoch: 4753, Train Loss: 1.800, Validation Loss: 5.863\n",
      "Epoch: 4754, Train Loss: 1.697, Validation Loss: 5.875\n",
      "Epoch: 4755, Train Loss: 1.944, Validation Loss: 5.895\n",
      "Epoch: 4756, Train Loss: 1.742, Validation Loss: 5.887\n",
      "Epoch: 4757, Train Loss: 1.635, Validation Loss: 5.888\n",
      "Epoch: 4758, Train Loss: 1.902, Validation Loss: 5.882\n",
      "Epoch: 4759, Train Loss: 1.578, Validation Loss: 5.868\n",
      "Epoch: 4760, Train Loss: 1.532, Validation Loss: 5.869\n",
      "Epoch: 4761, Train Loss: 1.763, Validation Loss: 5.859\n",
      "Epoch: 4762, Train Loss: 2.031, Validation Loss: 5.883\n",
      "Epoch: 4763, Train Loss: 1.820, Validation Loss: 5.859\n",
      "Epoch: 4764, Train Loss: 1.945, Validation Loss: 5.858\n",
      "Epoch: 4765, Train Loss: 1.473, Validation Loss: 5.843\n",
      "Epoch: 4766, Train Loss: 1.899, Validation Loss: 5.824\n",
      "Epoch: 4767, Train Loss: 1.620, Validation Loss: 5.848\n",
      "Epoch: 4768, Train Loss: 1.844, Validation Loss: 5.824\n",
      "Epoch: 4769, Train Loss: 1.871, Validation Loss: 5.905\n",
      "Epoch: 4770, Train Loss: 1.771, Validation Loss: 5.939\n",
      "Epoch: 4771, Train Loss: 1.517, Validation Loss: 5.909\n",
      "Epoch: 4772, Train Loss: 2.123, Validation Loss: 5.942\n",
      "Epoch: 4773, Train Loss: 1.757, Validation Loss: 5.855\n",
      "Epoch: 4774, Train Loss: 1.864, Validation Loss: 5.888\n",
      "Epoch: 4775, Train Loss: 1.835, Validation Loss: 5.878\n",
      "Epoch: 4776, Train Loss: 1.542, Validation Loss: 5.862\n",
      "Epoch: 4777, Train Loss: 1.673, Validation Loss: 5.906\n",
      "Epoch: 4778, Train Loss: 1.851, Validation Loss: 5.865\n",
      "Epoch: 4779, Train Loss: 1.842, Validation Loss: 5.868\n",
      "Epoch: 4780, Train Loss: 1.560, Validation Loss: 5.861\n",
      "Epoch: 4781, Train Loss: 1.756, Validation Loss: 5.853\n",
      "Epoch: 4782, Train Loss: 1.772, Validation Loss: 5.843\n",
      "Epoch: 4783, Train Loss: 1.427, Validation Loss: 5.876\n",
      "Epoch: 4784, Train Loss: 1.502, Validation Loss: 5.889\n",
      "Epoch: 4785, Train Loss: 1.780, Validation Loss: 5.863\n",
      "Epoch: 4786, Train Loss: 1.714, Validation Loss: 5.870\n",
      "Epoch: 4787, Train Loss: 1.608, Validation Loss: 5.930\n",
      "Epoch: 4788, Train Loss: 1.674, Validation Loss: 5.848\n",
      "Epoch: 4789, Train Loss: 1.467, Validation Loss: 5.837\n",
      "Epoch: 4790, Train Loss: 1.792, Validation Loss: 5.803\n",
      "Epoch: 4791, Train Loss: 1.601, Validation Loss: 5.828\n",
      "Epoch: 4792, Train Loss: 1.913, Validation Loss: 5.845\n",
      "Epoch: 4793, Train Loss: 1.691, Validation Loss: 5.839\n",
      "Epoch: 4794, Train Loss: 1.587, Validation Loss: 5.878\n",
      "Epoch: 4795, Train Loss: 1.598, Validation Loss: 5.886\n",
      "Epoch: 4796, Train Loss: 1.425, Validation Loss: 5.839\n",
      "Epoch: 4797, Train Loss: 1.823, Validation Loss: 5.780\n",
      "Epoch: 4798, Train Loss: 2.072, Validation Loss: 5.828\n",
      "Epoch: 4799, Train Loss: 2.117, Validation Loss: 5.764\n",
      "Epoch: 4800, Train Loss: 1.332, Validation Loss: 5.804\n",
      "Epoch: 4801, Train Loss: 1.942, Validation Loss: 5.800\n",
      "Epoch: 4802, Train Loss: 1.697, Validation Loss: 5.785\n",
      "Epoch: 4803, Train Loss: 1.590, Validation Loss: 5.848\n",
      "Epoch: 4804, Train Loss: 1.495, Validation Loss: 5.873\n",
      "Epoch: 4805, Train Loss: 1.805, Validation Loss: 5.875\n",
      "Epoch: 4806, Train Loss: 1.610, Validation Loss: 5.893\n",
      "Epoch: 4807, Train Loss: 1.900, Validation Loss: 5.875\n",
      "Epoch: 4808, Train Loss: 1.408, Validation Loss: 5.825\n",
      "Epoch: 4809, Train Loss: 1.451, Validation Loss: 5.821\n",
      "Epoch: 4810, Train Loss: 1.636, Validation Loss: 5.846\n",
      "Epoch: 4811, Train Loss: 1.529, Validation Loss: 5.845\n",
      "Epoch: 4812, Train Loss: 1.599, Validation Loss: 5.880\n",
      "Epoch: 4813, Train Loss: 1.805, Validation Loss: 5.889\n",
      "Epoch: 4814, Train Loss: 1.921, Validation Loss: 5.878\n",
      "Epoch: 4815, Train Loss: 1.594, Validation Loss: 5.948\n",
      "Epoch: 4816, Train Loss: 1.348, Validation Loss: 5.969\n",
      "Epoch: 4817, Train Loss: 1.664, Validation Loss: 5.951\n",
      "Epoch: 4818, Train Loss: 1.907, Validation Loss: 5.971\n",
      "Epoch: 4819, Train Loss: 1.591, Validation Loss: 5.898\n",
      "Epoch: 4820, Train Loss: 1.638, Validation Loss: 5.921\n",
      "Epoch: 4821, Train Loss: 1.501, Validation Loss: 5.865\n",
      "Epoch: 4822, Train Loss: 1.940, Validation Loss: 5.928\n",
      "Epoch: 4823, Train Loss: 1.664, Validation Loss: 5.825\n",
      "Epoch: 4824, Train Loss: 1.711, Validation Loss: 5.839\n",
      "Epoch: 4825, Train Loss: 1.448, Validation Loss: 5.844\n",
      "Epoch: 4826, Train Loss: 1.506, Validation Loss: 5.876\n",
      "Epoch: 4827, Train Loss: 1.830, Validation Loss: 5.859\n",
      "Epoch: 4828, Train Loss: 1.545, Validation Loss: 5.867\n",
      "Epoch: 4829, Train Loss: 1.628, Validation Loss: 5.898\n",
      "Epoch: 4830, Train Loss: 1.586, Validation Loss: 5.900\n",
      "Epoch: 4831, Train Loss: 1.508, Validation Loss: 5.877\n",
      "Epoch: 4832, Train Loss: 1.592, Validation Loss: 5.918\n",
      "Epoch: 4833, Train Loss: 1.837, Validation Loss: 5.890\n",
      "Epoch: 4834, Train Loss: 1.604, Validation Loss: 5.919\n",
      "Epoch: 4835, Train Loss: 1.615, Validation Loss: 5.950\n",
      "Epoch: 4836, Train Loss: 1.819, Validation Loss: 5.973\n",
      "Epoch: 4837, Train Loss: 1.717, Validation Loss: 5.899\n",
      "Epoch: 4838, Train Loss: 1.440, Validation Loss: 5.851\n",
      "Epoch: 4839, Train Loss: 1.868, Validation Loss: 5.833\n",
      "Epoch: 4840, Train Loss: 1.521, Validation Loss: 5.850\n",
      "Epoch: 4841, Train Loss: 1.517, Validation Loss: 5.835\n",
      "Epoch: 4842, Train Loss: 1.665, Validation Loss: 5.819\n",
      "Epoch: 4843, Train Loss: 1.849, Validation Loss: 5.945\n",
      "Epoch: 4844, Train Loss: 1.579, Validation Loss: 5.890\n",
      "Epoch: 4845, Train Loss: 2.015, Validation Loss: 5.889\n",
      "Epoch: 4846, Train Loss: 1.855, Validation Loss: 5.890\n",
      "Epoch: 4847, Train Loss: 1.593, Validation Loss: 5.888\n",
      "Epoch: 4848, Train Loss: 1.978, Validation Loss: 5.887\n",
      "Epoch: 4849, Train Loss: 1.766, Validation Loss: 5.888\n",
      "Epoch: 4850, Train Loss: 1.602, Validation Loss: 5.865\n",
      "Epoch: 4851, Train Loss: 1.838, Validation Loss: 5.878\n",
      "Epoch: 4852, Train Loss: 1.773, Validation Loss: 5.833\n",
      "Epoch: 4853, Train Loss: 1.849, Validation Loss: 5.890\n",
      "Epoch: 4854, Train Loss: 2.073, Validation Loss: 5.901\n",
      "Epoch: 4855, Train Loss: 1.574, Validation Loss: 5.893\n",
      "Epoch: 4856, Train Loss: 1.739, Validation Loss: 5.852\n",
      "Epoch: 4857, Train Loss: 1.643, Validation Loss: 5.859\n",
      "Epoch: 4858, Train Loss: 1.637, Validation Loss: 5.874\n",
      "Epoch: 4859, Train Loss: 1.616, Validation Loss: 5.866\n",
      "Epoch: 4860, Train Loss: 1.490, Validation Loss: 5.878\n",
      "Epoch: 4861, Train Loss: 1.658, Validation Loss: 5.906\n",
      "Epoch: 4862, Train Loss: 1.553, Validation Loss: 5.899\n",
      "Epoch: 4863, Train Loss: 1.732, Validation Loss: 5.923\n",
      "Epoch: 4864, Train Loss: 1.732, Validation Loss: 5.913\n",
      "Epoch: 4865, Train Loss: 1.968, Validation Loss: 5.957\n",
      "Epoch: 4866, Train Loss: 1.426, Validation Loss: 5.971\n",
      "Epoch: 4867, Train Loss: 1.544, Validation Loss: 5.906\n",
      "Epoch: 4868, Train Loss: 1.871, Validation Loss: 5.938\n",
      "Epoch: 4869, Train Loss: 1.705, Validation Loss: 5.972\n",
      "Epoch: 4870, Train Loss: 1.591, Validation Loss: 5.940\n",
      "Epoch: 4871, Train Loss: 1.887, Validation Loss: 5.969\n",
      "Epoch: 4872, Train Loss: 1.521, Validation Loss: 5.977\n",
      "Epoch: 4873, Train Loss: 1.885, Validation Loss: 6.008\n",
      "Epoch: 4874, Train Loss: 1.692, Validation Loss: 5.912\n",
      "Epoch: 4875, Train Loss: 1.868, Validation Loss: 5.904\n",
      "Epoch: 4876, Train Loss: 1.257, Validation Loss: 5.881\n",
      "Epoch: 4877, Train Loss: 1.527, Validation Loss: 5.920\n",
      "Epoch: 4878, Train Loss: 1.565, Validation Loss: 5.885\n",
      "Epoch: 4879, Train Loss: 1.650, Validation Loss: 5.906\n",
      "Epoch: 4880, Train Loss: 1.620, Validation Loss: 5.865\n",
      "Epoch: 4881, Train Loss: 1.887, Validation Loss: 5.885\n",
      "Epoch: 4882, Train Loss: 1.584, Validation Loss: 5.902\n",
      "Epoch: 4883, Train Loss: 1.507, Validation Loss: 5.868\n",
      "Epoch: 4884, Train Loss: 1.535, Validation Loss: 5.847\n",
      "Epoch: 4885, Train Loss: 1.519, Validation Loss: 5.886\n",
      "Epoch: 4886, Train Loss: 1.790, Validation Loss: 5.911\n",
      "Epoch: 4887, Train Loss: 1.841, Validation Loss: 5.894\n",
      "Epoch: 4888, Train Loss: 1.728, Validation Loss: 5.922\n",
      "Epoch: 4889, Train Loss: 1.601, Validation Loss: 5.946\n",
      "Epoch: 4890, Train Loss: 1.455, Validation Loss: 5.942\n",
      "Epoch: 4891, Train Loss: 1.752, Validation Loss: 5.957\n",
      "Epoch: 4892, Train Loss: 1.300, Validation Loss: 5.922\n",
      "Epoch: 4893, Train Loss: 1.594, Validation Loss: 5.916\n",
      "Epoch: 4894, Train Loss: 1.860, Validation Loss: 5.903\n",
      "Epoch: 4895, Train Loss: 2.069, Validation Loss: 5.942\n",
      "Epoch: 4896, Train Loss: 1.736, Validation Loss: 5.969\n",
      "Epoch: 4897, Train Loss: 1.383, Validation Loss: 5.929\n",
      "Epoch: 4898, Train Loss: 1.838, Validation Loss: 5.866\n",
      "Epoch: 4899, Train Loss: 1.722, Validation Loss: 5.881\n",
      "Epoch: 4900, Train Loss: 1.732, Validation Loss: 5.853\n",
      "Epoch: 4901, Train Loss: 1.843, Validation Loss: 5.858\n",
      "Epoch: 4902, Train Loss: 1.559, Validation Loss: 5.844\n",
      "Epoch: 4903, Train Loss: 1.677, Validation Loss: 5.880\n",
      "Epoch: 4904, Train Loss: 1.971, Validation Loss: 5.895\n",
      "Epoch: 4905, Train Loss: 2.081, Validation Loss: 5.931\n",
      "Epoch: 4906, Train Loss: 1.868, Validation Loss: 5.934\n",
      "Epoch: 4907, Train Loss: 1.589, Validation Loss: 5.950\n",
      "Epoch: 4908, Train Loss: 1.558, Validation Loss: 5.943\n",
      "Epoch: 4909, Train Loss: 1.729, Validation Loss: 5.907\n",
      "Epoch: 4910, Train Loss: 1.718, Validation Loss: 5.865\n",
      "Epoch: 4911, Train Loss: 1.550, Validation Loss: 5.851\n",
      "Epoch: 4912, Train Loss: 1.678, Validation Loss: 5.856\n",
      "Epoch: 4913, Train Loss: 1.533, Validation Loss: 5.837\n",
      "Epoch: 4914, Train Loss: 2.041, Validation Loss: 5.852\n",
      "Epoch: 4915, Train Loss: 1.786, Validation Loss: 5.846\n",
      "Epoch: 4916, Train Loss: 1.643, Validation Loss: 5.846\n",
      "Epoch: 4917, Train Loss: 1.534, Validation Loss: 5.856\n",
      "Epoch: 4918, Train Loss: 1.670, Validation Loss: 5.887\n",
      "Epoch: 4919, Train Loss: 1.676, Validation Loss: 5.892\n",
      "Epoch: 4920, Train Loss: 1.658, Validation Loss: 5.904\n",
      "Epoch: 4921, Train Loss: 1.770, Validation Loss: 5.928\n",
      "Epoch: 4922, Train Loss: 1.662, Validation Loss: 5.900\n",
      "Epoch: 4923, Train Loss: 1.689, Validation Loss: 5.904\n",
      "Epoch: 4924, Train Loss: 1.385, Validation Loss: 5.875\n",
      "Epoch: 4925, Train Loss: 1.677, Validation Loss: 5.887\n",
      "Epoch: 4926, Train Loss: 1.788, Validation Loss: 5.829\n",
      "Epoch: 4927, Train Loss: 1.794, Validation Loss: 5.862\n",
      "Epoch: 4928, Train Loss: 1.743, Validation Loss: 5.855\n",
      "Epoch: 4929, Train Loss: 1.636, Validation Loss: 5.807\n",
      "Epoch: 4930, Train Loss: 1.620, Validation Loss: 5.804\n",
      "Epoch: 4931, Train Loss: 1.655, Validation Loss: 5.833\n",
      "Epoch: 4932, Train Loss: 1.598, Validation Loss: 5.853\n",
      "Epoch: 4933, Train Loss: 1.490, Validation Loss: 5.798\n",
      "Epoch: 4934, Train Loss: 1.912, Validation Loss: 5.833\n",
      "Epoch: 4935, Train Loss: 1.857, Validation Loss: 5.845\n",
      "Epoch: 4936, Train Loss: 1.889, Validation Loss: 5.819\n",
      "Epoch: 4937, Train Loss: 1.692, Validation Loss: 5.862\n",
      "Epoch: 4938, Train Loss: 1.743, Validation Loss: 5.836\n",
      "Epoch: 4939, Train Loss: 1.625, Validation Loss: 5.854\n",
      "Epoch: 4940, Train Loss: 1.631, Validation Loss: 5.817\n",
      "Epoch: 4941, Train Loss: 1.688, Validation Loss: 5.795\n",
      "Epoch: 4942, Train Loss: 1.663, Validation Loss: 5.804\n",
      "Epoch: 4943, Train Loss: 1.763, Validation Loss: 5.842\n",
      "Epoch: 4944, Train Loss: 1.504, Validation Loss: 5.822\n",
      "Epoch: 4945, Train Loss: 1.993, Validation Loss: 5.872\n",
      "Epoch: 4946, Train Loss: 1.663, Validation Loss: 5.853\n",
      "Epoch: 4947, Train Loss: 1.753, Validation Loss: 5.877\n",
      "Epoch: 4948, Train Loss: 1.578, Validation Loss: 5.861\n",
      "Epoch: 4949, Train Loss: 1.823, Validation Loss: 5.828\n",
      "Epoch: 4950, Train Loss: 1.737, Validation Loss: 5.822\n",
      "Epoch: 4951, Train Loss: 1.844, Validation Loss: 5.867\n",
      "Epoch: 4952, Train Loss: 1.742, Validation Loss: 5.926\n",
      "Epoch: 4953, Train Loss: 1.763, Validation Loss: 5.878\n",
      "Epoch: 4954, Train Loss: 1.794, Validation Loss: 5.907\n",
      "Epoch: 4955, Train Loss: 1.534, Validation Loss: 5.834\n",
      "Epoch: 4956, Train Loss: 1.527, Validation Loss: 5.799\n",
      "Epoch: 4957, Train Loss: 1.738, Validation Loss: 5.864\n",
      "Epoch: 4958, Train Loss: 1.788, Validation Loss: 5.853\n",
      "Epoch: 4959, Train Loss: 1.854, Validation Loss: 5.893\n",
      "Epoch: 4960, Train Loss: 1.525, Validation Loss: 5.881\n",
      "Epoch: 4961, Train Loss: 1.739, Validation Loss: 5.812\n",
      "Epoch: 4962, Train Loss: 1.427, Validation Loss: 5.813\n",
      "Epoch: 4963, Train Loss: 1.595, Validation Loss: 5.833\n",
      "Epoch: 4964, Train Loss: 1.631, Validation Loss: 5.836\n",
      "Epoch: 4965, Train Loss: 2.089, Validation Loss: 5.849\n",
      "Epoch: 4966, Train Loss: 1.386, Validation Loss: 5.849\n",
      "Epoch: 4967, Train Loss: 1.609, Validation Loss: 5.850\n",
      "Epoch: 4968, Train Loss: 1.748, Validation Loss: 5.903\n",
      "Epoch: 4969, Train Loss: 1.694, Validation Loss: 5.846\n",
      "Epoch: 4970, Train Loss: 1.446, Validation Loss: 5.846\n",
      "Epoch: 4971, Train Loss: 1.621, Validation Loss: 5.822\n",
      "Epoch: 4972, Train Loss: 1.849, Validation Loss: 5.838\n",
      "Epoch: 4973, Train Loss: 1.795, Validation Loss: 5.858\n",
      "Epoch: 4974, Train Loss: 1.366, Validation Loss: 5.856\n",
      "Epoch: 4975, Train Loss: 1.806, Validation Loss: 5.836\n",
      "Epoch: 4976, Train Loss: 1.397, Validation Loss: 5.821\n",
      "Epoch: 4977, Train Loss: 1.592, Validation Loss: 5.844\n",
      "Epoch: 4978, Train Loss: 1.771, Validation Loss: 5.808\n",
      "Epoch: 4979, Train Loss: 1.634, Validation Loss: 5.824\n",
      "Epoch: 4980, Train Loss: 1.659, Validation Loss: 5.838\n",
      "Epoch: 4981, Train Loss: 1.790, Validation Loss: 5.858\n",
      "Epoch: 4982, Train Loss: 1.461, Validation Loss: 5.829\n",
      "Epoch: 4983, Train Loss: 1.807, Validation Loss: 5.846\n",
      "Epoch: 4984, Train Loss: 1.812, Validation Loss: 5.823\n",
      "Epoch: 4985, Train Loss: 1.990, Validation Loss: 5.863\n",
      "Epoch: 4986, Train Loss: 1.791, Validation Loss: 5.825\n",
      "Epoch: 4987, Train Loss: 1.615, Validation Loss: 5.827\n",
      "Epoch: 4988, Train Loss: 1.349, Validation Loss: 5.831\n",
      "Epoch: 4989, Train Loss: 1.607, Validation Loss: 5.853\n",
      "Epoch: 4990, Train Loss: 1.658, Validation Loss: 5.861\n",
      "Epoch: 4991, Train Loss: 1.546, Validation Loss: 5.855\n",
      "Epoch: 4992, Train Loss: 1.515, Validation Loss: 5.866\n",
      "Epoch: 4993, Train Loss: 1.876, Validation Loss: 5.884\n",
      "Epoch: 4994, Train Loss: 1.479, Validation Loss: 5.892\n",
      "Epoch: 4995, Train Loss: 1.683, Validation Loss: 5.903\n",
      "Epoch: 4996, Train Loss: 1.629, Validation Loss: 5.849\n",
      "Epoch: 4997, Train Loss: 1.519, Validation Loss: 5.837\n",
      "Epoch: 4998, Train Loss: 1.771, Validation Loss: 5.852\n",
      "Epoch: 4999, Train Loss: 1.703, Validation Loss: 5.831\n",
      "Epoch: 5000, Train Loss: 2.105, Validation Loss: 5.816\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "for i in range(epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        X_batch, y_batch = resample(X_train, y_train, n_samples=batch_size)\n",
    "        X.value, y.value = X_batch, y_batch\n",
    "        \n",
    "        forward_and_backward(graph)\n",
    "        sgd_update(trainables, lr)\n",
    "        train_loss += graph[-1].value\n",
    "        \n",
    "    train_loss = train_loss / steps_per_epoch\n",
    "    losses['train'].append(train_loss)\n",
    "    \n",
    "    X.value, y.value = X_validation, y_validation\n",
    "    forward_and_backward(graph, training=False)\n",
    "    val_loss = graph[-1].value\n",
    "    losses['validation'].append(val_loss)\n",
    "    \n",
    "    #if (i+1) % batch_size == 0:\n",
    "    print(\"Epoch: {}, Train Loss: {:.3f}, Validation Loss: {:.3f}\".format(i+1, train_loss, val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10f095d68>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e784e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(losses['train']))\n",
    "ax.plot(x, losses['train'], label='Train')\n",
    "ax.plot(x, losses['validation'], label='Validation')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10f420b00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f47a1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "feed_dict[X] = X_test\n",
    "feed_dict[y] = y_test\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "forward_and_backward(graph, training=False)\n",
    "prediction = graph[-2].value\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(y_test))\n",
    "ax.plot(x, y_test, label='Data', color='g')\n",
    "ax.plot(x, prediction, label='Prediction', color='r')\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
